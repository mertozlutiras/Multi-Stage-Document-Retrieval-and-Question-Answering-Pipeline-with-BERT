{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFdIzvCjAuZV"
   },
   "source": [
    "Document Retrieval Pipeline\n",
    "- access to the drive will be granted, if needed, just send uns an email, then you can access all the data files\n",
    "- we worked a lot with datafiles as the demand of resources was very high and even colab pro crashed frequently \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhYxMGlKfj0-",
    "outputId": "ba73787f-2493-4885-9be7-ecf965e3f779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 4.0MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 28.7MB/s \n",
      "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 40.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4p-tJ7aAqLK",
    "outputId": "6ebbbff3-8682-4497-cc2e-6b39ac3b3b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import nltk\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import spatial\n",
    "\n",
    "#removing stopwords using the nltk library\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#lemmatization\n",
    "from nltk.stem import wordnet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#bert/transformers and neural networs\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, AutoTokenizer, RobertaModel, AutoModel, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvphEOcx_Y1h",
    "outputId": "418ad92e-bff3-462e-8533-47d9f3d4ae6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9acnyVfQNlcU"
   },
   "outputs": [],
   "source": [
    "#unzip the data if you want to create all dictionaries (if they are not saved anywhere)\n",
    "!unzip ./gdrive/MyDrive/Information_Retrieval_Project/evaluation/wikipedia.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bZDEuJrPNovA"
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('./gdrive/MyDrive/Information_Retrieval_Project/qa/wikipedia-train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pdNCZTM_F_d"
   },
   "source": [
    "## Helper Method definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "U6QzmPaRNrFi"
   },
   "outputs": [],
   "source": [
    "def create_text_dict():\n",
    "  \"\"\" Returns a dictionary containing key: title; value: doc_text\"\"\"\n",
    "  text_dict = dict()\n",
    "  text = \"\"\n",
    "  for filename in os.listdir(\"./wikipedia/\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "      with open(\"./wikipedia/{}\".format(filename)) as f:\n",
    "        text = f.read()\n",
    "      text_dict[filename.lower()] = text\n",
    "  return text_dict\n",
    "\n",
    "def full_text(text):\n",
    "  \"\"\" As we \n",
    "      ----------\n",
    "      text: document text\n",
    "  \"\"\"\n",
    "  text = re.sub(\"\\?\", \"_\", text.lower())\n",
    "  text = re.sub(\"\\:\", \"_\", text)\n",
    "  text = re.sub('\\\"', \"_\", text)\n",
    "  text = re.sub('\\*', \"_\", text)\n",
    "\n",
    "  return text\n",
    "\n",
    "def create_question_df(train_df, id_title_dict, text_dict):\n",
    "  \"\"\" Creates a dataframe containing questionID, question, list of rel. docs per question\n",
    "      ----------\n",
    "      train_df: the wikipedia.train json as dataframe\n",
    "      id_title_dict: dictionary that maps each doc title to an id\n",
    "      text_dict: dictionary that contains document titles as keys and texts as values\n",
    "  \"\"\"\n",
    "  questionID = list()\n",
    "  text_questions = list()\n",
    "  rel_docs_list = list()\n",
    "\n",
    "  title_id_dict = {title: id for id, title in id_title_dict.items()}\n",
    " \n",
    "  for ele in train_df['Data']:\n",
    "    rel_docs_set = list()\n",
    "    questionID.append(ele['QuestionId'])\n",
    "    text_questions.append(ele['Question'])\n",
    "    for rel_doc in ele['EntityPages']:\n",
    "      title = full_text(rel_doc['Filename'])\n",
    "      if title_id_dict[title] not in rel_docs_set:\n",
    "        rel_docs_set.append(title_id_dict[title])\n",
    "    rel_docs_list.append(rel_docs_set)\n",
    "\n",
    "\n",
    "  data = {'questionID': questionID,\n",
    "          'questions': text_questions,\n",
    "          'rel_docs': rel_docs_list\n",
    "  }\n",
    "  return pd.DataFrame(data, columns=data.keys())\n",
    "\n",
    "def create_question_dict(df):\n",
    "  \"\"\" Creates a dictionary containing key: questionID; value: question \n",
    "      ----------\n",
    "      df: dataframe retrieved from wikipedia_train.json\n",
    "  \"\"\"\n",
    "  question_dict = dict()\n",
    "  for ele in df['Data']:\n",
    "    question_dict[ele['QuestionId']] = ele['Question']\n",
    "  return question_dict\n",
    "\n",
    "def create_id_title_dict(text_dict):\n",
    "  \"\"\" Creates a dictionary that maps each document title to an integer\n",
    "      ----------\n",
    "      text_dict: dictionary with key: title; value: document text\n",
    "  \"\"\"\n",
    "  return {i: title for i, title in enumerate(text_dict.keys())}\n",
    "\n",
    "def print_dict(any_dict, n=3):\n",
    "  \"\"\" Prints the first n key/value-pairs of any dictionary\"\"\"\n",
    "  i = 0 \n",
    "  for key, value in any_dict.items():\n",
    "    print(\"key: \", key)\n",
    "    print(\"value: \", value)\n",
    "    i += 1\n",
    "    if i == n:\n",
    "      break\n",
    "\n",
    "def load_all_dictionaries():\n",
    "  \"\"\" Loads all saved dictionaries in order to reduce effort and computation time\n",
    "      of creating each of these dictionaries again\n",
    "  \"\"\"\n",
    "  with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/prep_texts.json') as json_file:\n",
    "    prep_texts = json.load(json_file)\n",
    "  with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/prep_questions.json') as json_file:\n",
    "    prep_questions = json.load(json_file)\n",
    "  with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/title_fulltext.json') as json_file:\n",
    "    full_texts = json.load(json_file)\n",
    "  with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/id_title.json') as json_file:\n",
    "    id_title = json.load(json_file)\n",
    "  with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/question_dict.json') as json_file:\n",
    "    question_dict = json.load(json_file)\n",
    "  return prep_texts, prep_questions, full_texts, id_title, question_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAIYqYsuCMTX"
   },
   "source": [
    "Text Processing and tokenization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1ddxhU6pRQ2Q"
   },
   "outputs": [],
   "source": [
    "def tokenize_dict(doc_dict):\n",
    "  \"\"\" Converts the text of a doc_dict to tokens\n",
    "      ----------\n",
    "      doc_dict: dictionary with key: title; value: document text\n",
    "  \"\"\"\n",
    "  text_tokens = dict()\n",
    "  for title in doc_dict.keys():\n",
    "    text_tokens[title] =  re.findall(\"[\\w']+\", doc_dict[title])\n",
    "  return text_tokens\n",
    "\n",
    "def tokenize_query(query):\n",
    "  \"\"\" Tokenizes a query\n",
    "      ----------\n",
    "      query: question-text\n",
    "  \"\"\"\n",
    "  return re.findall(\"[\\w']+\", query)\n",
    "\n",
    "def get_all_tokens(doc_dict):\n",
    "  \"\"\" returns all tokens within the document dictionary; removes duplicate tokens\n",
    "      ----------\n",
    "      doc_dict: dictionary with key: title; value: document text\n",
    "  \"\"\"\n",
    "  tokens = set([token for tokengroup in doc_dict.values() for token in tokengroup])\n",
    "  return tokens\n",
    "\n",
    "def get_all_query_tokens(query_dict):\n",
    "  \"\"\" returns the tokens of all queries of the passed query dictionary; removes duplicate tokens\n",
    "      ----------\n",
    "      query_dict: dictionary with key: questionID; value: tokenized question\n",
    "  \"\"\"\n",
    "  q_tokens = set()\n",
    "\n",
    "  for query_rel_tuple in query_dict.values():\n",
    "    for token in query_rel_tuple[0]:\n",
    "      q_tokens.add(token)\n",
    "  return q_tokens\n",
    "\n",
    " \n",
    "def get_query_test_set(query_dict, n=0.7):\n",
    "  \"\"\" samples the query dictionary using fractions train: n; test: 1-n\n",
    "      ----------\n",
    "      query_dict: dictionary with key: questionID; value: tokenized question\n",
    "  \"\"\"\n",
    "  s = pd.Series(query_dict)\n",
    "  training_data , test_data  = [i.to_dict() for i in train_test_split(s, train_size=0.7)]\n",
    "  return training_data, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7Lnwo2uV1bVz"
   },
   "outputs": [],
   "source": [
    "def lowercase_text(text):\n",
    "  \"\"\" Lowercases all words within a string\n",
    "      ----------\n",
    "      text: string\n",
    "  \"\"\"\n",
    "  return text.lower()\n",
    "\n",
    "def rem_punct(text):\n",
    "  \"\"\" Removes all punctuation from a string\"\"\"\n",
    "\n",
    "  translator = str.maketrans('', '', string.punctuation)\n",
    "  return text.translate(translator)\n",
    "\n",
    "def rem_stopwords(text):\n",
    "  \"\"\" Removes all stopwords from a string\"\"\"\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  word_tokens = word_tokenize(text)\n",
    "  filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "  return filtered_text\n",
    "\n",
    "def s_words(tokenized_text, stemmer): \n",
    "  \"\"\" Stems all tokens using the passed stemmer\n",
    "      ----------\n",
    "      tokenized_text: list of tokens of a text (string)\n",
    "  \"\"\"\n",
    "  stems = [stemmer.stem(word) for word in tokenized_text]\n",
    "  return stems\n",
    "\n",
    "def lemmatize_word(tokenized_text, lemma):\n",
    "  \"\"\" lemmatizes all tokens in a list of tokens\n",
    "      ----------\n",
    "      tokenized_text: list of tokens of a text (string)\n",
    "  \"\"\"\n",
    "  lemmas = [lemma.lemmatize(word, pos='v') for word in tokenized_text]\n",
    "  return lemmas\n",
    "\n",
    "def preprocess_text(text_dict, id_title_dict, norm_type='stemming'):\n",
    "  \"\"\" method that calls stemming/lemmatization for a dictionary containing the texts\n",
    "      returns a dictionary with key: id; value: list of preprocessed tokens of that text\n",
    "      ----------\n",
    "      text_dict: dictionary with key: title; value: document text\n",
    "      id_title_dict: dictionary which maps each doc_title to an integer\n",
    "      norm_type: decides if stemming or lemmatization is used\n",
    "  \"\"\"\n",
    "  if norm_type == 'stemming':\n",
    "    stemmer = PorterStemmer()\n",
    "    return {i: s_words(rem_stopwords(lowercase_text(rem_punct(text_dict[title]))), stemmer) for i, title in id_title_dict.items()}#, \n",
    "  else:\n",
    "    lemma = wordnet.WordNetLemmatizer() \n",
    "    return {i: lemmatize_word(rem_stopwords(lowercase_text(rem_punct(text_dict[title]))), lemma) for i, title in id_title_dict.items()}\n",
    "    \n",
    "\n",
    "def preprocess_questions(question_df, norm_type='stemming'):\n",
    "  \"\"\" method that calls stemming/lemmatization for a dictionary containing the texts\n",
    "      returns a dictionary with key: id; value: tutple(list of question tokens, list of rel doc ids)\n",
    "      ----------\n",
    "      question_df: dataframe containing questionID, question, list of rel docs\n",
    "  \"\"\"\n",
    "  if norm_type == 'stemming': \n",
    "    stemmer = PorterStemmer()\n",
    "    return {row[1]['questionID']: (s_words(rem_stopwords(lowercase_text(rem_punct(row[1]['questions']))), stemmer), row[1]['rel_docs']) for row in question_df.iterrows()}\n",
    "  else:\n",
    "    lemma = wordnet.WordNetLemmatizer()\n",
    "    return {row[1]['questionID']: (lemmatize_word(rem_stopwords(lowercase_text(rem_punct(row[1]['questions']))), lemma), row[1]['rel_docs']) for row in question_df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrfpoGVLDHl4"
   },
   "source": [
    "\n",
    "## Initialization and save *dictionaries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKpDVwlCcJYI"
   },
   "outputs": [],
   "source": [
    "#reates: \n",
    "#text_dict -> title: full_text\n",
    "#id_title_dict -> id: title\n",
    "#question_df -> questionID, question, list of rel docs\n",
    "#question_dict -> questionID, question\n",
    "text_dict = create_text_dict()\n",
    "id_title_dict = create_id_title_dict(text_dict)\n",
    "question_df = create_question_df(df, id_title_dict, text_dict)\n",
    "question_dict = create_question_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zdo7kitLGXa9"
   },
   "outputs": [],
   "source": [
    "#create prep_text_dict -> doc_id: tokenized text\n",
    "prep_text_dict = preprocess_text(text_dict, id_title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5mi4PxcolOL"
   },
   "outputs": [],
   "source": [
    "#create prep_question_dict -> questionID: (tokenized question, list of rel docs)\n",
    "prep_question_dict = preprocess_questions(question_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ68HEq5loDu"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/prep_texts.json', \"w\") as outfile: \n",
    "  json.dump(prep_text_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NciT9T3LpXf1"
   },
   "outputs": [],
   "source": [
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/prep_questions.json', \"w\") as outfile: \n",
    "  json.dump(prep_question_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gf2RuNiNqnua"
   },
   "outputs": [],
   "source": [
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/title_fulltext.json', \"w\") as outfile:\n",
    "  json.dump(text_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdTdF9W3ptdP"
   },
   "outputs": [],
   "source": [
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/id_title.json', \"w\") as outfile:\n",
    "  json.dump(id_title_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxBqcPCUMu1B"
   },
   "outputs": [],
   "source": [
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/question_dict.json', \"w\") as outfile:\n",
    "  json.dump(question_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HK1vJlDq1AQ-"
   },
   "source": [
    "## Load dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZsTWo22y8qQ"
   },
   "outputs": [],
   "source": [
    "prep_text_dict, prep_question_dict, text_dict, id_title_dict, question_dict = load_all_dictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7MDEOwTq_PH",
    "outputId": "399927aa-ca2a-4422-a9b7-e727e4bdee1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "england.txt\n",
      "England is a country that is part of the United Kingdom.   It shares land borders with Scotland to the north and Wales to the west. The Irish Sea lies northwest of England and the Celtic Sea lies to t\n",
      "\n",
      "\n",
      "judi_dench.txt\n",
      "Dame Judith Olivia \"Judi\" Dench,  (born 9 December 1934)  is an English actress and author.  Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years she perfor\n",
      "\n",
      "\n",
      "nation_state.txt\n",
      "A nation state is a type of state that conjoins the political entity of a state to the cultural entity of a nation, from which it aims to derive its political legitimacy to rule and potentially its st\n",
      "\n",
      "\n",
      "angola.txt\n",
      "Angola, officially the Republic of Angola (; Kikongo, Kimbundu and Umbundu: Repubilika ya Ngola), is a country in Southern Africa. It is the seventh-largest country in Africa, and is bordered by Namib\n",
      "\n",
      "\n",
      "angolan_civil_war.txt\n",
      "The Angolan Civil War () was a major civil conflict in Angola, beginning in 1975 and continuing, with some interludes, until 2002. The war began immediately after Angola became independent from Portug\n",
      "\n",
      "\n",
      "david_soul.txt\n",
      "David Soul (born August 28, 1943) is an American-British actor and singer. He is known for his role as Detective Kenneth \"Hutch\" Hutchinson in the ABC television series Starsky & Hutch from 1975 to 19\n",
      "tc_3 [['england', 'dame', 'judi', 'dench', 'born'], [5240, 4605]]\n",
      "tc_8 [['countri', 'angola', 'achiev', 'independ', '1975'], [61783, 578, 10361]]\n",
      "tc_9 [['citi', 'david', 'soul', 'come'], [70942]]\n",
      "qw_1376 [['end', 'war', '1812', 'usa', 'held', 'canadian', 'territori', 'near', 'detroit', 'british', 'held', 'part', 'eastern', 'state'], [24611]]\n"
     ]
    }
   ],
   "source": [
    "print(id_title_dict['5240'])\n",
    "print(text_dict[id_title_dict['5240']][:200])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(id_title_dict['4605'])\n",
    "print(text_dict[id_title_dict['4605']][:200])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(id_title_dict['61783'])\n",
    "print(text_dict[id_title_dict['61783']][:200])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(id_title_dict['578'])\n",
    "print(text_dict[id_title_dict['578']][:200])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(id_title_dict['10361'])\n",
    "print(text_dict[id_title_dict['10361']][:200])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(id_title_dict['70942'])\n",
    "print(text_dict[id_title_dict['70942']][:200])\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for k, v in prep_question_dict.items():\n",
    "  if i < 3:\n",
    "    print(k, v)\n",
    "    i+=1\n",
    "  if i == 3:\n",
    "    if k == 'qw_1376':\n",
    "      print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqTlK62M1Jln"
   },
   "source": [
    "## compute inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBImF67fS64S"
   },
   "source": [
    "### Create new train/test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaeXJX0YRirs",
    "outputId": "718ab765-2f4a-4a14-93e7-d8b116393912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original lenght:  61888\n",
      "test data length:  18567\n"
     ]
    }
   ],
   "source": [
    "#split up the data into a train and test dictionary; also remove duplicate query tokens\n",
    "prep_question_train, prep_question_test =get_query_test_set(prep_question_dict, n=0.7)\n",
    "query_train_tokens = get_all_query_tokens(prep_question_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VdA5BPgeVEG"
   },
   "outputs": [],
   "source": [
    "#save the train_dict\n",
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/train_prep_question_70.json', \"w\") as outfile:\n",
    "  json.dump(prep_question_train, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukk6gbRRedGn"
   },
   "outputs": [],
   "source": [
    "#save the test_dict\n",
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/test_prep_question_30.json', \"w\") as outfile:\n",
    "  json.dump(prep_question_test, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uakf-dGRSZLx"
   },
   "outputs": [],
   "source": [
    "#load if usage of test set is wanted\n",
    "query_test_tokens = get_all_query_tokens(prep_question_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glH-um0mSdwU"
   },
   "outputs": [],
   "source": [
    "#load if usage of train set is wanted\n",
    "query_test_tokens = get_all_query_tokens(prep_question_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGvJy8F6VqW8"
   },
   "outputs": [],
   "source": [
    "print(len(query_test_tokens))\n",
    "print(len(query_train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2lTpdtdS_6D"
   },
   "source": [
    "### Load train/test-dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtiFJoi-SvgK"
   },
   "outputs": [],
   "source": [
    "#load the train_dict\n",
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/train_prep_question_70.json') as json_file:\n",
    "  prep_question_train = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "55dTlhSL_7K5"
   },
   "outputs": [],
   "source": [
    "#load the test_dict\n",
    "with open('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/test_prep_question_30.json') as json_file:\n",
    "  prep_question_test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMXf6l-_UK-Z"
   },
   "outputs": [],
   "source": [
    "#create set of query tokens form train set\n",
    "query_train_tokens = get_all_query_tokens(prep_question_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4J_KF_ZUSIN"
   },
   "outputs": [],
   "source": [
    "#create set of query tokens form test set\n",
    "query_test_tokens = get_all_query_tokens(prep_question_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUVm11eUkta0",
    "outputId": "e01c9ae3-b903-4921-d2d5-4ca9ae1eb46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21289\n",
      "33375\n"
     ]
    }
   ],
   "source": [
    "print(len(query_test_tokens))\n",
    "print(len(query_train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXNep4y8Vc5q"
   },
   "source": [
    "### Initialize inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-5mbH2yRsZ8"
   },
   "outputs": [],
   "source": [
    "def compute_inverted_index(query_tokens, prep_text_dict):\n",
    "  \"\"\" computes an inverted index that maps query_id to the documents it appears in\n",
    "      also counts num of appearences\n",
    "      ----------\n",
    "      query_tokens: set of tokens in the query\n",
    "      prep_text_dict: dictionary -> text_id : tokenized text\n",
    "  \"\"\"\n",
    "  inverted_index = dict()\n",
    "  for q_token in query_tokens:\n",
    "    inverted_index[q_token] = dict()\n",
    "  for doc, doc_text in prep_text_dict.items():\n",
    "    for token in doc_text:\n",
    "      if token in inverted_index.keys():\n",
    "        if doc in inverted_index[token].keys():\n",
    "          inverted_index[token][doc] += 1\n",
    "        else:\n",
    "          inverted_index[token][doc] = 1\n",
    "  return inverted_index\n",
    "\n",
    "def show_inv_n(inverted_index, n=3):\n",
    "  k = 0\n",
    "  for token, occurences in inverted_index.items():\n",
    "    print(\"token: \", token)\n",
    "    print(\"occurences: \", occurences)\n",
    "    k += 1\n",
    "    if k == n:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJKDZjxcG_YR"
   },
   "outputs": [],
   "source": [
    "#create an inverted index for the train set\n",
    "inv_train = compute_inverted_index(query_train_tokens, prep_text_dict)\n",
    "show_inv_n(inv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ew-uW3A9HZ8S",
    "outputId": "688374cc-c5cd-42a4-bc1e-273fe6fe2ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:  lablach\n",
      "occurences:  {'16779': 1, '18208': 1, '20192': 5, '23723': 1, '36632': 1, '40635': 2, '41405': 1, '63608': 1, '69749': 1}\n",
      "token:  tenburi\n",
      "occurences:  {'4330': 1, '10486': 2, '16022': 2, '20700': 1, '21923': 1, '23031': 10, '31634': 5, '35154': 2, '47531': 1, '48618': 2, '49974': 1, '58729': 2, '63377': 1, '63420': 1, '68720': 26}\n",
      "token:  carrier\n",
      "occurences:  {'30': 1, '40': 1, '56': 1, '117': 1, '137': 1, '142': 4, '185': 1, '208': 1, '239': 1, '257': 1, '280': 1, '417': 10, '418': 1, '430': 190, '441': 1, '536': 1, '539': 1, '560': 1, '611': 3, '674': 4, '686': 1, '735': 1, '750': 18, '764': 1, '774': 1, '814': 1, '902': 2, '919': 1, '921': 2, '943': 1, '954': 1, '1002': 3, '1032': 2, '1037': 1, '1164': 11, '1172': 3, '1199': 1, '1200': 1, '1243': 1, '1245': 1, '1300': 1, '1343': 1, '1380': 1, '1392': 1, '1433': 1, '1469': 3, '1501': 1, '1504': 1, '1545': 15, '1587': 1, '1593': 1, '1612': 2, '1668': 1, '1678': 1, '1703': 1, '1735': 1, '1746': 31, '1751': 8, '1835': 1, '1851': 1, '1863': 3, '1902': 1, '1918': 4, '1930': 1, '1940': 1, '2074': 2, '2077': 1, '2098': 1, '2108': 1, '2128': 1, '2147': 1, '2182': 1, '2184': 1, '2197': 1, '2235': 1, '2238': 1, '2242': 1, '2299': 2, '2328': 1, '2345': 1, '2354': 2, '2404': 2, '2434': 3, '2441': 1, '2501': 3, '2553': 1, '2594': 3, '2598': 1, '2605': 1, '2617': 7, '2650': 1, '2671': 1, '2715': 5, '2752': 2, '2770': 2, '2798': 1, '2801': 1, '2812': 2, '2813': 2, '2815': 3, '2823': 2, '2829': 1, '2838': 1, '2850': 2, '2852': 3, '2853': 1, '2873': 2, '2916': 1, '2917': 1, '2927': 15, '2951': 14, '2996': 1, '3055': 1, '3063': 1, '3078': 1, '3087': 1, '3089': 1, '3103': 1, '3165': 1, '3181': 3, '3182': 1, '3229': 1, '3266': 1, '3293': 2, '3304': 25, '3329': 1, '3366': 11, '3398': 10, '3460': 3, '3469': 1, '3491': 1, '3492': 1, '3576': 12, '3599': 1, '3632': 1, '3683': 1, '3685': 6, '3689': 11, '3694': 2, '3714': 1, '3761': 1, '3769': 2, '3785': 1, '3822': 2, '3836': 1, '3848': 1, '3850': 1, '3867': 1, '3889': 1, '3918': 1, '3949': 5, '3953': 15, '4029': 1, '4074': 2, '4139': 1, '4152': 1, '4166': 1, '4199': 18, '4215': 2, '4242': 1, '4275': 1, '4283': 1, '4301': 2, '4335': 1, '4357': 10, '4362': 4, '4366': 3, '4373': 2, '4384': 1, '4388': 1, '4402': 1, '4422': 6, '4461': 1, '4486': 1, '4496': 1, '4509': 11, '4528': 1, '4544': 1, '4602': 2, '4613': 3, '4666': 1, '4687': 1, '4709': 1, '4710': 1, '4803': 1, '4838': 2, '4892': 1, '4896': 1, '4915': 1, '4924': 5, '4958': 1, '4986': 2, '4997': 7, '5040': 1, '5084': 1, '5086': 1, '5173': 1, '5208': 9, '5266': 1, '5278': 4, '5288': 1, '5294': 3, '5305': 1, '5368': 15, '5395': 21, '5398': 1, '5399': 1, '5412': 1, '5423': 1, '5480': 6, '5481': 1, '5518': 1, '5526': 1, '5548': 1, '5560': 1, '5567': 3, '5602': 2, '5633': 1, '5651': 1, '5676': 17, '5702': 2, '5704': 3, '5733': 4, '5743': 1, '5769': 1, '5776': 1, '5814': 18, '5840': 5, '5847': 1, '5887': 1, '5898': 1, '5979': 1, '6087': 2, '6113': 1, '6202': 8, '6223': 1, '6224': 3, '6241': 2, '6288': 1, '6317': 11, '6332': 1, '6338': 1, '6357': 33, '6364': 4, '6395': 1, '6433': 6, '6455': 1, '6487': 1, '6499': 1, '6541': 1, '6577': 2, '6607': 1, '6625': 29, '6628': 1, '6678': 4, '6694': 2, '6780': 1, '6787': 2, '6798': 2, '6807': 1, '6810': 6, '6816': 1, '6819': 4, '6824': 2, '6850': 1, '6853': 1, '6859': 1, '6896': 3, '6930': 1, '6952': 18, '6980': 1, '6997': 1, '7001': 2, '7003': 3, '7024': 4, '7048': 1, '7054': 1, '7056': 2, '7073': 1, '7078': 5, '7090': 1, '7113': 54, '7127': 1, '7145': 1, '7172': 2, '7196': 2, '7251': 2, '7269': 1, '7275': 2, '7298': 1, '7310': 1, '7312': 1, '7322': 1, '7341': 1, '7418': 1, '7436': 1, '7442': 3, '7447': 1, '7450': 2, '7503': 2, '7535': 1, '7587': 1, '7602': 1, '7646': 1, '7670': 4, '7684': 7, '7689': 1, '7707': 2, '7771': 1, '7774': 5, '7780': 3, '7801': 6, '7812': 1, '7815': 3, '7818': 1, '7867': 2, '7906': 9, '7917': 1, '8006': 3, '8075': 3, '8097': 1, '8110': 27, '8117': 2, '8221': 1, '8222': 1, '8283': 1, '8315': 1, '8351': 1, '8431': 1, '8433': 2, '8486': 1, '8532': 7, '8539': 2, '8669': 3, '8675': 1, '8715': 1, '8719': 1, '8753': 3, '8770': 6, '8780': 1, '8817': 1, '8854': 3, '8873': 1, '8901': 1, '8951': 1, '8952': 4, '9057': 1, '9215': 1, '9285': 1, '9300': 2, '9305': 2, '9335': 1, '9340': 1, '9377': 1, '9459': 1, '9494': 2, '9539': 1, '9544': 1, '9551': 4, '9577': 8, '9604': 8, '9609': 1, '9616': 1, '9622': 1, '9658': 1, '9659': 8, '9665': 4, '9672': 1, '9677': 2, '9697': 1, '9776': 1, '9796': 1, '9798': 6, '9830': 5, '9835': 47, '9887': 4, '9969': 1, '9988': 1, '10010': 1, '10023': 2, '10025': 2, '10029': 1, '10061': 1, '10071': 1, '10103': 1, '10111': 1, '10193': 1, '10206': 1, '10210': 1, '10244': 2, '10259': 1, '10272': 1, '10373': 3, '10378': 13, '10417': 4, '10472': 1, '10508': 1, '10525': 1, '10528': 1, '10585': 1, '10611': 1, '10613': 1, '10638': 3, '10694': 1, '10708': 3, '10717': 6, '10752': 1, '10839': 1, '10867': 1, '10901': 2, '10965': 1, '11042': 1, '11074': 1, '11078': 2, '11082': 1, '11096': 1, '11123': 1, '11137': 1, '11168': 1, '11184': 5, '11271': 1, '11281': 1, '11307': 1, '11324': 6, '11325': 1, '11365': 1, '11376': 3, '11466': 4, '11471': 3, '11516': 1, '11546': 4, '11570': 7, '11596': 4, '11603': 1, '11674': 2, '11682': 1, '11699': 1, '11717': 2, '11785': 3, '11827': 1, '11875': 2, '11908': 5, '11929': 4, '11949': 1, '11960': 2, '12009': 2, '12013': 1, '12074': 1, '12081': 1, '12089': 1, '12132': 1, '12143': 3, '12178': 1, '12216': 4, '12224': 1, '12256': 1, '12264': 1, '12296': 1, '12315': 6, '12369': 2, '12384': 4, '12386': 1, '12406': 1, '12411': 1, '12419': 1, '12426': 25, '12429': 2, '12431': 1, '12492': 2, '12509': 4, '12530': 2, '12532': 3, '12537': 1, '12592': 4, '12601': 3, '12613': 2, '12706': 33, '12765': 4, '12772': 1, '12877': 8, '12996': 1, '12998': 2, '13008': 1, '13013': 2, '13094': 1, '13104': 1, '13135': 1, '13228': 1, '13241': 2, '13275': 1, '13305': 1, '13313': 4, '13328': 4, '13356': 1, '13365': 1, '13385': 5, '13519': 1, '13639': 1, '13721': 1, '13767': 2, '13806': 1, '13833': 2, '13843': 4, '13844': 2, '13850': 1, '13860': 1, '13911': 1, '13941': 1, '14033': 1, '14055': 5, '14070': 1, '14090': 1, '14110': 1, '14115': 1, '14151': 2, '14158': 2, '14177': 1, '14184': 4, '14191': 10, '14313': 11, '14361': 1, '14378': 1, '14392': 2, '14433': 1, '14449': 1, '14469': 1, '14516': 1, '14541': 2, '14545': 3, '14569': 1, '14597': 2, '14605': 1, '14614': 1, '14624': 1, '14649': 26, '14659': 1, '14688': 1, '14703': 4, '14740': 1, '14762': 1, '14796': 5, '14821': 12, '14852': 6, '14936': 2, '14980': 1, '14981': 2, '14991': 11, '15000': 8, '15004': 1, '15017': 17, '15090': 2, '15095': 5, '15096': 1, '15161': 2, '15203': 1, '15213': 1, '15306': 1, '15317': 1, '15322': 15, '15370': 1, '15373': 1, '15408': 1, '15453': 1, '15481': 1, '15514': 1, '15531': 1, '15562': 1, '15565': 1, '15580': 1, '15597': 1, '15639': 3, '15643': 1, '15678': 1, '15684': 1, '15729': 1, '15732': 1, '15853': 2, '15855': 1, '15867': 10, '15885': 1, '15911': 1, '15941': 3, '15968': 1, '15974': 1, '15995': 1, '16017': 1, '16024': 1, '16066': 1, '16105': 1, '16151': 6, '16207': 3, '16222': 2, '16231': 1, '16266': 2, '16294': 2, '16338': 1, '16350': 1, '16456': 4, '16469': 1, '16495': 4, '16497': 2, '16555': 1, '16569': 1, '16591': 2, '16619': 1, '16622': 3, '16661': 3, '16703': 1, '16720': 2, '16759': 1, '16778': 1, '16783': 1, '16895': 14, '16917': 1, '16926': 13, '16928': 1, '16929': 4, '16937': 1, '16943': 1, '16988': 59, '17019': 34, '17058': 1, '17059': 1, '17115': 6, '17184': 1, '17194': 1, '17240': 7, '17304': 1, '17306': 1, '17333': 2, '17352': 2, '17363': 1, '17380': 1, '17387': 1, '17412': 1, '17423': 1, '17445': 1, '17451': 1, '17486': 1, '17498': 2, '17504': 1, '17560': 1, '17569': 5, '17609': 1, '17611': 1, '17631': 11, '17665': 4, '17672': 1, '17698': 3, '17720': 1, '17736': 1, '17779': 1, '17795': 1, '17829': 33, '17846': 3, '17848': 3, '17878': 1, '17888': 1, '17889': 1, '17892': 1, '17900': 1, '17948': 1, '17967': 3, '18035': 1, '18082': 3, '18087': 39, '18109': 2, '18145': 2, '18186': 1, '18226': 1, '18238': 1, '18329': 8, '18340': 1, '18349': 1, '18370': 1, '18377': 4, '18381': 2, '18416': 1, '18424': 1, '18446': 1, '18457': 1, '18472': 1, '18524': 2, '18532': 1, '18595': 1, '18639': 1, '18647': 13, '18660': 1, '18687': 1, '18703': 1, '18733': 1, '18734': 1, '18767': 1, '18808': 4, '18881': 1, '18884': 1, '18904': 1, '18911': 1, '18943': 5, '18969': 1, '18987': 2, '18991': 5, '19013': 1, '19048': 6, '19051': 1, '19055': 6, '19082': 2, '19087': 2, '19170': 1, '19185': 1, '19226': 2, '19231': 2, '19288': 1, '19300': 3, '19382': 1, '19393': 1, '19411': 2, '19413': 2, '19436': 2, '19438': 2, '19464': 2, '19497': 1, '19504': 1, '19594': 2, '19603': 2, '19655': 3, '19701': 1, '19729': 1, '19747': 1, '19774': 14, '19791': 3, '19800': 2, '19832': 3, '19902': 3, '19945': 2, '19959': 11, '19982': 1, '20008': 1, '20021': 9, '20023': 1, '20088': 4, '20140': 1, '20166': 1, '20179': 3, '20189': 1, '20222': 1, '20244': 7, '20380': 5, '20395': 2, '20443': 1, '20481': 1, '20543': 1, '20609': 1, '20626': 1, '20658': 1, '20675': 6, '20746': 1, '20761': 1, '20769': 3, '20788': 1, '20792': 1, '20804': 1, '20826': 53, '20875': 4, '20882': 2, '20890': 19, '20951': 2, '20966': 6, '20982': 6, '21009': 2, '21017': 22, '21048': 1, '21097': 1, '21111': 1, '21112': 1, '21143': 1, '21166': 13, '21183': 1, '21276': 3, '21279': 1, '21316': 5, '21321': 1, '21327': 1, '21365': 1, '21393': 5, '21402': 2, '21486': 1, '21544': 1, '21566': 7, '21586': 2, '21734': 1, '21778': 2, '21813': 1, '21861': 1, '21876': 1, '21883': 1, '21894': 17, '21901': 4, '21931': 1, '21944': 3, '21997': 1, '21999': 1, '22010': 1, '22030': 3, '22079': 1, '22152': 1, '22187': 2, '22195': 2, '22218': 1, '22224': 1, '22256': 1, '22270': 1, '22274': 2, '22313': 1, '22363': 1, '22451': 3, '22494': 1, '22499': 1, '22505': 5, '22549': 1, '22593': 1, '22597': 1, '22607': 1, '22646': 1, '22659': 3, '22664': 1, '22683': 1, '22718': 4, '22741': 2, '22764': 1, '22769': 1, '22780': 2, '22796': 1, '22823': 1, '22887': 4, '22894': 7, '22895': 17, '22914': 1, '22923': 1, '23050': 1, '23052': 1, '23075': 1, '23099': 2, '23101': 2, '23105': 1, '23136': 1, '23150': 1, '23166': 1, '23171': 6, '23188': 1, '23214': 1, '23224': 2, '23238': 1, '23251': 1, '23252': 1, '23265': 1, '23288': 2, '23290': 1, '23303': 1, '23387': 2, '23452': 2, '23480': 1, '23629': 1, '23653': 1, '23673': 1, '23682': 1, '23734': 1, '23752': 1, '23754': 34, '23778': 1, '23803': 7, '23805': 7, '23811': 1, '23824': 1, '23828': 2, '23830': 1, '23858': 1, '23862': 7, '23887': 2, '23901': 1, '23914': 2, '23986': 1, '23988': 1, '24003': 1, '24012': 2, '24017': 1, '24018': 7, '24045': 1, '24046': 1, '24047': 1, '24053': 4, '24136': 1, '24148': 2, '24153': 1, '24202': 1, '24246': 1, '24309': 1, '24338': 1, '24363': 1, '24399': 1, '24420': 1, '24437': 3, '24445': 3, '24523': 1, '24524': 2, '24596': 1, '24600': 5, '24612': 1, '24632': 1, '24659': 1, '24663': 7, '24670': 6, '24676': 1, '24693': 1, '24712': 1, '24737': 2, '24761': 1, '24801': 1, '24849': 1, '24904': 2, '24936': 3, '25000': 1, '25087': 1, '25110': 1, '25125': 26, '25205': 1, '25241': 1, '25259': 1, '25272': 29, '25288': 1, '25318': 1, '25342': 4, '25356': 1, '25375': 1, '25451': 2, '25455': 2, '25482': 1, '25488': 7, '25509': 1, '25520': 2, '25534': 1, '25548': 1, '25632': 1, '25652': 17, '25667': 1, '25672': 170, '25695': 1, '25700': 1, '25751': 1, '25775': 1, '25810': 1, '25829': 6, '25832': 1, '25888': 19, '25942': 3, '25959': 5, '25961': 5, '25985': 1, '26039': 2, '26066': 1, '26073': 6, '26145': 1, '26177': 3, '26224': 1, '26228': 2, '26230': 1, '26232': 1, '26293': 1, '26342': 2, '26373': 1, '26379': 4, '26385': 3, '26397': 1, '26406': 1, '26560': 1, '26562': 1, '26589': 1, '26678': 1, '26696': 6, '26710': 6, '26772': 4, '26786': 1, '26793': 2, '26802': 1, '26823': 1, '26873': 5, '26912': 1, '26931': 1, '26938': 1, '26978': 4, '27014': 2, '27041': 1, '27060': 2, '27080': 1, '27082': 1, '27101': 1, '27128': 1, '27152': 3, '27236': 1, '27268': 1, '27279': 1, '27310': 1, '27323': 2, '27405': 1, '27444': 8, '27487': 8, '27494': 1, '27495': 3, '27511': 1, '27532': 2, '27644': 2, '27648': 1, '27726': 2, '27771': 1, '27797': 1, '27815': 2, '27816': 1, '27828': 1, '27842': 1, '27902': 1, '27915': 2, '27960': 17, '27964': 1, '28002': 2, '28036': 4, '28051': 2, '28076': 1, '28142': 2, '28146': 1, '28181': 1, '28225': 1, '28229': 1, '28232': 1, '28301': 9, '28344': 1, '28346': 4, '28354': 1, '28376': 1, '28393': 1, '28423': 2, '28464': 1, '28488': 1, '28515': 1, '28528': 3, '28557': 15, '28569': 1, '28672': 1, '28676': 1, '28716': 4, '28735': 1, '28838': 2, '28842': 1, '28877': 53, '28889': 4, '28989': 9, '29019': 1, '29166': 1, '29171': 1, '29192': 1, '29211': 1, '29213': 3, '29239': 1, '29259': 1, '29339': 1, '29340': 1, '29362': 1, '29384': 1, '29395': 1, '29435': 1, '29448': 1, '29501': 3, '29503': 5, '29520': 1, '29521': 2, '29539': 1, '29548': 1, '29595': 9, '29695': 1, '29701': 1, '29732': 1, '29742': 1, '29781': 1, '29826': 1, '29881': 1, '29971': 1, '29989': 1, '30067': 5, '30068': 1, '30120': 1, '30143': 1, '30156': 1, '30174': 1, '30205': 1, '30214': 1, '30215': 7, '30233': 1, '30257': 1, '30258': 1, '30267': 2, '30282': 1, '30325': 1, '30327': 3, '30336': 1, '30415': 12, '30427': 1, '30435': 1, '30456': 1, '30489': 9, '30721': 1, '30775': 1, '30777': 1, '30780': 1, '30784': 1, '30813': 1, '30841': 1, '30849': 1, '30892': 1, '30918': 1, '30941': 1, '30959': 6, '30983': 4, '31020': 3, '31037': 52, '31042': 1, '31053': 1, '31054': 1, '31061': 1, '31076': 16, '31088': 2, '31176': 1, '31184': 1, '31206': 1, '31213': 1, '31230': 1, '31259': 1, '31333': 1, '31359': 1, '31376': 1, '31384': 1, '31419': 24, '31422': 2, '31449': 1, '31451': 1, '31491': 1, '31501': 2, '31516': 1, '31548': 1, '31554': 9, '31556': 1, '31587': 1, '31596': 3, '31602': 1, '31622': 1, '31625': 1, '31628': 1, '31641': 1, '31647': 1, '31683': 1, '31704': 3, '31733': 10, '31778': 4, '31791': 8, '31811': 1, '31870': 1, '31878': 1, '31914': 1, '31922': 6, '31993': 1, '32098': 2, '32114': 1, '32150': 1, '32206': 1, '32228': 17, '32244': 1, '32267': 1, '32284': 1, '32313': 1, '32347': 1, '32354': 6, '32356': 3, '32418': 1, '32455': 5, '32479': 1, '32526': 1, '32551': 24, '32554': 1, '32571': 37, '32594': 1, '32607': 1, '32632': 3, '32652': 6, '32660': 6, '32756': 3, '32774': 11, '32784': 1, '32796': 1, '32856': 1, '32929': 57, '32934': 1, '33009': 1, '33054': 1, '33089': 1, '33123': 2, '33127': 3, '33155': 1, '33176': 1, '33179': 1, '33207': 1, '33223': 1, '33233': 1, '33285': 1, '33303': 2, '33368': 1, '33390': 1, '33392': 1, '33434': 2, '33446': 1, '33456': 1, '33483': 2, '33657': 1, '33686': 1, '33695': 1, '33779': 1, '33795': 2, '33803': 1, '33836': 1, '33837': 1, '33910': 4, '33915': 3, '33956': 1, '33960': 1, '33975': 2, '34011': 1, '34025': 1, '34044': 1, '34051': 1, '34054': 1, '34088': 1, '34132': 64, '34148': 1, '34167': 75, '34202': 1, '34237': 1, '34247': 21, '34259': 5, '34281': 1, '34371': 4, '34418': 3, '34456': 1, '34467': 1, '34494': 1, '34510': 7, '34536': 4, '34539': 1, '34541': 2, '34568': 3, '34591': 1, '34605': 2, '34637': 2, '34643': 2, '34654': 1, '34685': 1, '34693': 1, '34733': 1, '34761': 1, '34794': 1, '34839': 8, '34844': 1, '34849': 1, '34902': 2, '34917': 2, '34933': 1, '34934': 4, '34982': 1, '35042': 3, '35068': 1, '35093': 2, '35103': 1, '35142': 1, '35161': 2, '35189': 1, '35191': 5, '35200': 2, '35208': 2, '35209': 3, '35237': 4, '35351': 1, '35352': 2, '35359': 1, '35364': 1, '35413': 1, '35470': 1, '35537': 2, '35542': 4, '35555': 1, '35556': 4, '35578': 1, '35606': 2, '35654': 5, '35695': 2, '35713': 1, '35747': 2, '35759': 6, '35796': 1, '35802': 3, '35934': 1, '35953': 6, '35955': 3, '35970': 1, '36092': 1, '36105': 2, '36106': 16, '36149': 5, '36163': 1, '36201': 45, '36202': 1, '36238': 2, '36259': 6, '36295': 16, '36348': 1, '36349': 4, '36360': 2, '36399': 1, '36413': 1, '36433': 2, '36435': 1, '36438': 1, '36443': 2, '36448': 2, '36456': 4, '36469': 1, '36486': 24, '36500': 1, '36534': 1, '36586': 2, '36617': 1, '36641': 6, '36648': 1, '36735': 2, '36742': 1, '36762': 1, '36786': 4, '36817': 1, '36834': 1, '36840': 1, '36842': 1, '36944': 3, '36989': 1, '37051': 2, '37173': 1, '37221': 1, '37225': 1, '37332': 12, '37360': 2, '37382': 1, '37394': 1, '37412': 1, '37441': 1, '37442': 1, '37470': 6, '37484': 6, '37514': 4, '37531': 1, '37568': 1, '37601': 3, '37608': 15, '37649': 3, '37678': 2, '37682': 15, '37702': 1, '37786': 3, '37809': 1, '37832': 1, '37863': 1, '37896': 4, '37899': 4, '37911': 30, '37916': 1, '37957': 1, '38005': 2, '38067': 2, '38069': 1, '38106': 1, '38125': 3, '38130': 1, '38205': 1, '38221': 1, '38300': 2, '38332': 1, '38342': 1, '38385': 1, '38390': 1, '38479': 1, '38481': 2, '38524': 1, '38582': 1, '38587': 1, '38615': 1, '38640': 1, '38734': 1, '38749': 1, '38787': 3, '38845': 2, '38859': 12, '38869': 7, '38902': 18, '38937': 1, '39001': 1, '39016': 2, '39032': 1, '39054': 13, '39055': 1, '39074': 1, '39103': 1, '39112': 1, '39120': 1, '39156': 2, '39168': 22, '39227': 1, '39238': 5, '39277': 7, '39335': 3, '39349': 2, '39398': 1, '39419': 1, '39423': 1, '39425': 1, '39435': 2, '39465': 2, '39511': 1, '39635': 1, '39646': 1, '39695': 1, '39699': 1, '39795': 1, '39837': 1, '39847': 3, '39850': 1, '39898': 6, '40033': 2, '40056': 3, '40107': 2, '40112': 7, '40190': 2, '40196': 1, '40197': 5, '40234': 1, '40242': 1, '40257': 1, '40278': 2, '40323': 3, '40361': 1, '40370': 1, '40374': 1, '40389': 1, '40397': 17, '40475': 3, '40485': 2, '40488': 1, '40511': 1, '40542': 9, '40557': 1, '40564': 1, '40581': 1, '40648': 1, '40655': 3, '40668': 1, '40672': 8, '40701': 1, '40801': 2, '40935': 5, '40998': 1, '41036': 1, '41108': 1, '41111': 13, '41208': 1, '41252': 4, '41337': 6, '41378': 1, '41390': 2, '41407': 3, '41434': 1, '41470': 1, '41501': 3, '41526': 5, '41768': 2, '41783': 1, '41816': 1, '41829': 2, '41872': 2, '41934': 1, '42004': 1, '42094': 1, '42137': 2, '42162': 1, '42237': 1, '42259': 7, '42279': 1, '42287': 1, '42292': 2, '42297': 1, '42317': 2, '42332': 5, '42359': 2, '42365': 2, '42367': 1, '42375': 1, '42505': 1, '42539': 1, '42558': 3, '42566': 1, '42585': 1, '42594': 1, '42619': 1, '42634': 1, '42728': 1, '42730': 1, '42735': 1, '42799': 2, '42801': 1, '42804': 1, '42879': 2, '42924': 2, '42930': 1, '42943': 2, '42967': 5, '42973': 1, '43017': 1, '43111': 1, '43115': 1, '43118': 1, '43135': 1, '43151': 1, '43160': 1, '43167': 1, '43177': 1, '43186': 4, '43193': 6, '43210': 1, '43287': 1, '43318': 1, '43327': 2, '43358': 3, '43375': 1, '43401': 2, '43431': 22, '43458': 1, '43463': 1, '43469': 2, '43514': 1, '43520': 3, '43546': 2, '43633': 1, '43649': 1, '43650': 12, '43704': 1, '43785': 1, '43867': 1, '43870': 1, '43957': 1, '43968': 8, '44024': 1, '44047': 1, '44077': 7, '44125': 1, '44139': 1, '44149': 1, '44150': 1, '44196': 3, '44214': 2, '44308': 1, '44329': 3, '44337': 1, '44350': 1, '44354': 1, '44355': 1, '44393': 1, '44424': 1, '44443': 1, '44584': 7, '44711': 1, '44723': 1, '44725': 1, '44728': 1, '44729': 1, '44735': 3, '44740': 8, '44744': 1, '44812': 1, '44853': 4, '44863': 1, '44878': 3, '44886': 1, '44896': 1, '44934': 1, '45002': 1, '45150': 1, '45152': 1, '45191': 1, '45192': 2, '45203': 1, '45209': 3, '45231': 1, '45254': 1, '45262': 1, '45296': 1, '45298': 2, '45389': 1, '45391': 1, '45421': 1, '45424': 5, '45435': 1, '45455': 5, '45460': 2, '45493': 2, '45524': 1, '45556': 1, '45632': 2, '45656': 1, '45664': 2, '45683': 1, '45689': 1, '45741': 2, '45781': 20, '45808': 8, '45889': 3, '45973': 10, '46003': 1, '46030': 1, '46049': 5, '46060': 1, '46080': 2, '46088': 1, '46097': 2, '46099': 2, '46109': 1, '46117': 1, '46137': 2, '46190': 1, '46225': 3, '46251': 1, '46367': 1, '46443': 1, '46514': 5, '46516': 1, '46519': 1, '46521': 2, '46540': 2, '46550': 2, '46588': 1, '46599': 1, '46602': 1, '46603': 3, '46606': 1, '46654': 1, '46669': 5, '46683': 3, '46692': 1, '46752': 1, '46762': 3, '46764': 16, '46818': 1, '46822': 23, '46827': 1, '46866': 2, '46998': 1, '47000': 1, '47031': 1, '47088': 2, '47099': 6, '47154': 2, '47172': 2, '47220': 3, '47239': 1, '47325': 1, '47346': 2, '47388': 1, '47430': 6, '47433': 1, '47442': 7, '47445': 1, '47479': 5, '47483': 26, '47489': 4, '47507': 1, '47535': 1, '47588': 1, '47595': 1, '47608': 1, '47635': 1, '47639': 6, '47640': 9, '47650': 2, '47687': 2, '47701': 1, '47730': 1, '47735': 1, '47775': 2, '47788': 2, '47855': 1, '47870': 1, '47946': 2, '48018': 1, '48063': 1, '48088': 1, '48107': 1, '48121': 1, '48155': 2, '48156': 2, '48175': 5, '48210': 17, '48216': 1, '48261': 1, '48280': 2, '48285': 8, '48338': 1, '48372': 1, '48400': 1, '48463': 2, '48489': 1, '48588': 1, '48606': 1, '48611': 16, '48642': 1, '48712': 1, '48721': 1, '48731': 1, '48745': 2, '48788': 1, '48840': 5, '48854': 1, '48870': 8, '48879': 1, '48887': 1, '48888': 1, '48889': 2, '48900': 2, '48903': 1, '48952': 1, '48979': 1, '48988': 1, '48990': 1, '48992': 1, '48994': 1, '49021': 1, '49062': 1, '49070': 3, '49109': 1, '49122': 19, '49137': 4, '49147': 1, '49160': 1, '49176': 11, '49243': 9, '49246': 1, '49255': 5, '49336': 1, '49339': 9, '49370': 1, '49433': 1, '49528': 3, '49565': 3, '49567': 3, '49568': 1, '49606': 15, '49646': 8, '49785': 1, '49809': 2, '49815': 1, '49835': 1, '49840': 1, '49843': 2, '49860': 1, '49917': 1, '49925': 1, '49929': 1, '49931': 1, '49938': 2, '49940': 2, '49970': 1, '49984': 1, '50103': 1, '50138': 1, '50150': 1, '50232': 1, '50244': 6, '50252': 1, '50338': 4, '50351': 1, '50367': 1, '50378': 3, '50389': 1, '50395': 1, '50404': 5, '50438': 2, '50441': 1, '50518': 2, '50533': 2, '50613': 2, '50616': 2, '50620': 1, '50660': 2, '50661': 3, '50686': 1, '50710': 1, '50726': 4, '50731': 1, '50733': 1, '50744': 1, '50786': 2, '50834': 1, '50870': 1, '50951': 3, '50953': 4, '50961': 3, '50974': 1, '50977': 1, '51001': 3, '51009': 1, '51013': 2, '51049': 1, '51100': 5, '51107': 1, '51229': 1, '51270': 1, '51379': 5, '51422': 5, '51456': 1, '51463': 5, '51477': 1, '51480': 1, '51487': 1, '51508': 1, '51523': 1, '51576': 5, '51609': 1, '51711': 17, '51746': 2, '51807': 2, '51820': 1, '51832': 1, '51899': 1, '51919': 2, '51924': 3, '51944': 1, '51965': 11, '52017': 1, '52058': 1, '52067': 1, '52105': 19, '52149': 3, '52171': 1, '52187': 1, '52224': 2, '52297': 1, '52321': 1, '52394': 4, '52421': 1, '52423': 2, '52424': 1, '52464': 1, '52465': 2, '52525': 3, '52542': 2, '52547': 18, '52566': 1, '52587': 1, '52589': 1, '52613': 1, '52614': 1, '52621': 1, '52662': 1, '52705': 1, '52746': 11, '52752': 1, '52827': 1, '52831': 1, '52839': 1, '52846': 2, '52856': 1, '52858': 17, '52872': 4, '52874': 1, '52917': 3, '52987': 3, '53004': 4, '53007': 1, '53014': 1, '53049': 2, '53092': 1, '53109': 1, '53179': 1, '53220': 3, '53240': 1, '53241': 1, '53303': 1, '53307': 1, '53310': 3, '53321': 1, '53452': 1, '53473': 1, '53548': 2, '53553': 1, '53558': 7, '53629': 1, '53695': 3, '53698': 1, '53762': 1, '53774': 1, '53805': 1, '53821': 1, '53879': 1, '53937': 1, '54052': 2, '54164': 3, '54175': 1, '54229': 1, '54240': 1, '54255': 2, '54258': 1, '54346': 2, '54352': 2, '54380': 1, '54393': 1, '54399': 2, '54401': 1, '54459': 27, '54462': 112, '54485': 1, '54523': 2, '54545': 1, '54586': 20, '54598': 1, '54601': 4, '54625': 1, '54668': 2, '54678': 4, '54722': 1, '54786': 1, '54798': 1, '54817': 1, '54857': 3, '54910': 1, '54920': 2, '54943': 1, '54962': 1, '54967': 3, '55019': 1, '55035': 1, '55087': 1, '55101': 2, '55103': 1, '55113': 3, '55114': 1, '55116': 17, '55169': 2, '55191': 1, '55253': 1, '55290': 3, '55325': 1, '55326': 1, '55342': 3, '55355': 1, '55358': 2, '55451': 1, '55474': 2, '55498': 3, '55512': 1, '55559': 3, '55579': 2, '55585': 7, '55645': 2, '55676': 2, '55691': 1, '55695': 1, '55712': 1, '55761': 1, '55768': 1, '55814': 23, '55849': 1, '55864': 2, '55881': 1, '55922': 2, '55963': 1, '56015': 1, '56043': 3, '56053': 4, '56056': 1, '56073': 1, '56076': 12, '56090': 1, '56110': 1, '56128': 3, '56173': 9, '56175': 4, '56208': 7, '56210': 8, '56231': 2, '56232': 6, '56236': 2, '56249': 1, '56279': 1, '56319': 7, '56370': 1, '56378': 1, '56420': 8, '56430': 1, '56436': 1, '56444': 7, '56451': 1, '56477': 1, '56530': 2, '56549': 3, '56560': 1, '56668': 1, '56676': 1, '56742': 2, '56744': 1, '56786': 1, '56799': 1, '56835': 1, '56836': 1, '56893': 1, '56943': 2, '56973': 1, '57023': 2, '57054': 2, '57124': 2, '57138': 1, '57198': 2, '57252': 1, '57287': 4, '57371': 2, '57386': 2, '57388': 3, '57392': 1, '57397': 1, '57421': 2, '57470': 16, '57505': 1, '57536': 8, '57560': 1, '57574': 1, '57601': 1, '57628': 1, '57668': 11, '57674': 3, '57682': 1, '57690': 1, '57702': 1, '57708': 7, '57721': 1, '57818': 11, '57824': 2, '57917': 1, '57958': 15, '57977': 7, '58048': 1, '58137': 4, '58144': 8, '58150': 1, '58176': 7, '58245': 2, '58270': 1, '58275': 1, '58281': 2, '58282': 1, '58337': 2, '58382': 3, '58398': 18, '58409': 1, '58429': 1, '58534': 1, '58542': 1, '58559': 1, '58565': 1, '58567': 1, '58586': 1, '58661': 22, '58693': 4, '58790': 1, '58808': 2, '58812': 3, '58832': 1, '58854': 3, '58859': 1, '58888': 1, '58915': 1, '58932': 4, '58937': 1, '58943': 7, '58978': 25, '59019': 5, '59021': 1, '59103': 1, '59114': 1, '59118': 1, '59141': 4, '59147': 1, '59181': 4, '59262': 7, '59272': 2, '59279': 1, '59303': 1, '59317': 1, '59332': 10, '59333': 1, '59336': 1, '59354': 1, '59394': 1, '59397': 1, '59405': 1, '59409': 1, '59439': 1, '59440': 1, '59549': 1, '59591': 1, '59602': 1, '59611': 1, '59688': 1, '59690': 1, '59739': 1, '59881': 2, '59995': 1, '60032': 1, '60062': 1, '60103': 11, '60112': 17, '60130': 1, '60146': 1, '60206': 1, '60210': 1, '60217': 1, '60222': 6, '60250': 10, '60268': 1, '60283': 3, '60297': 4, '60352': 1, '60412': 1, '60415': 1, '60419': 1, '60421': 1, '60436': 7, '60439': 2, '60450': 1, '60475': 2, '60485': 4, '60529': 2, '60599': 1, '60632': 2, '60660': 1, '60668': 1, '60743': 6, '60767': 1, '60843': 3, '60895': 1, '60916': 1, '60921': 6, '60922': 1, '60927': 1, '60941': 7, '60951': 1, '60995': 1, '60996': 2, '61009': 2, '61045': 8, '61053': 1, '61100': 8, '61118': 1, '61130': 2, '61132': 1, '61155': 3, '61160': 1, '61167': 1, '61181': 15, '61208': 1, '61248': 2, '61274': 1, '61307': 1, '61335': 1, '61347': 1, '61384': 1, '61412': 1, '61501': 1, '61505': 11, '61509': 3, '61523': 2, '61541': 9, '61569': 2, '61599': 6, '61619': 1, '61678': 1, '61727': 1, '61742': 4, '61766': 7, '61768': 1, '61812': 1, '61859': 14, '61960': 1, '62000': 1, '62034': 1, '62057': 1, '62087': 1, '62132': 3, '62139': 2, '62190': 1, '62213': 6, '62230': 1, '62236': 2, '62245': 1, '62310': 1, '62323': 1, '62324': 2, '62354': 3, '62395': 8, '62405': 4, '62445': 4, '62456': 1, '62463': 2, '62513': 1, '62531': 10, '62561': 3, '62562': 9, '62625': 1, '62693': 1, '62736': 1, '62749': 1, '62768': 4, '62781': 16, '62788': 3, '62793': 2, '62834': 2, '62854': 1, '62860': 6, '62935': 12, '62954': 1, '62986': 1, '63045': 1, '63052': 1, '63141': 1, '63149': 1, '63165': 7, '63182': 6, '63249': 3, '63274': 1, '63313': 11, '63315': 1, '63355': 1, '63372': 1, '63387': 100, '63404': 9, '63406': 2, '63426': 5, '63430': 1, '63437': 1, '63519': 3, '63521': 1, '63534': 1, '63543': 1, '63595': 2, '63621': 1, '63649': 1, '63668': 1, '63698': 1, '63703': 2, '63706': 1, '63721': 1, '63736': 10, '63744': 2, '63760': 1, '63777': 1, '63818': 1, '63840': 1, '63887': 2, '63900': 1, '63906': 1, '63927': 1, '63942': 1, '63971': 1, '63978': 1, '63981': 12, '64012': 1, '64072': 1, '64084': 1, '64089': 1, '64190': 1, '64207': 3, '64225': 2, '64237': 15, '64244': 3, '64251': 1, '64338': 1, '64360': 1, '64365': 1, '64407': 1, '64413': 39, '64423': 9, '64452': 1, '64573': 2, '64596': 1, '64717': 1, '64720': 4, '64725': 1, '64745': 1, '64767': 1, '64782': 19, '64798': 1, '64830': 1, '64875': 1, '64918': 1, '64940': 1, '64947': 4, '64951': 1, '64958': 5, '64966': 1, '64991': 12, '65029': 2, '65031': 1, '65040': 1, '65056': 2, '65072': 1, '65098': 2, '65131': 2, '65144': 1, '65167': 1, '65168': 1, '65236': 2, '65240': 4, '65262': 1, '65353': 1, '65381': 1, '65398': 1, '65402': 1, '65419': 1, '65514': 23, '65616': 1, '65637': 1, '65661': 1, '65676': 1, '65701': 3, '65707': 147, '65758': 2, '65761': 3, '65774': 1, '65826': 1, '65948': 3, '65954': 1, '66003': 3, '66027': 1, '66126': 1, '66172': 1, '66340': 1, '66369': 4, '66397': 1, '66413': 1, '66473': 1, '66489': 3, '66533': 1, '66617': 1, '66649': 1, '66656': 1, '66664': 1, '66679': 2, '66684': 2, '66685': 10, '66690': 1, '66698': 1, '66745': 2, '66774': 1, '66786': 2, '66810': 1, '66858': 1, '66878': 2, '66908': 1, '66914': 1, '66932': 1, '66938': 1, '66958': 1, '67017': 3, '67021': 2, '67024': 1, '67028': 1, '67045': 2, '67104': 4, '67208': 63, '67233': 4, '67275': 1, '67310': 1, '67311': 2, '67334': 3, '67374': 3, '67407': 1, '67482': 5, '67535': 4, '67544': 1, '67690': 1, '67726': 1, '67745': 1, '67762': 4, '67768': 7, '67779': 1, '67787': 3, '67810': 1, '67832': 2, '67860': 1, '67863': 1, '67885': 2, '67893': 6, '67922': 1, '67989': 2, '67992': 24, '67995': 23, '67996': 1, '67998': 1, '68020': 1, '68041': 1, '68045': 2, '68125': 1, '68126': 1, '68132': 1, '68164': 1, '68205': 6, '68226': 1, '68255': 1, '68299': 2, '68300': 3, '68417': 2, '68441': 2, '68501': 1, '68530': 1, '68540': 1, '68544': 1, '68596': 1, '68609': 1, '68611': 1, '68632': 1, '68663': 1, '68670': 1, '68675': 11, '68722': 1, '68740': 1, '68755': 1, '68831': 6, '68838': 7, '68843': 2, '68912': 2, '68914': 1, '68937': 1, '68966': 1, '68968': 1, '69009': 2, '69051': 2, '69093': 1, '69099': 1, '69107': 1, '69163': 2, '69209': 1, '69214': 1, '69266': 2, '69293': 3, '69303': 2, '69338': 2, '69444': 6, '69469': 1, '69475': 2, '69482': 3, '69496': 1, '69500': 1, '69510': 1, '69524': 3, '69531': 3, '69580': 20, '69608': 1, '69627': 1, '69682': 1, '69697': 1, '69705': 2, '69812': 1, '69898': 2, '69915': 1, '69951': 2, '70009': 1, '70037': 2, '70079': 11, '70086': 5, '70092': 1, '70116': 1, '70117': 1, '70151': 2, '70223': 31, '70238': 8, '70263': 2, '70266': 1, '70267': 2, '70281': 1, '70293': 1, '70314': 78, '70327': 1, '70334': 4, '70349': 3, '70351': 1, '70363': 1, '70433': 1, '70462': 2, '70470': 1, '70472': 5, '70527': 1, '70549': 2, '70569': 1, '70576': 1, '70597': 2, '70601': 2, '70625': 1, '70682': 1, '70693': 1, '70762': 2, '70767': 2, '70845': 1, '70862': 1, '70908': 1, '70956': 1, '71010': 4, '71038': 2, '71064': 2, '71091': 1, '71157': 1, '71168': 1, '71179': 1, '71202': 1, '71226': 1, '71241': 3, '71282': 2, '71291': 1, '71327': 1, '71330': 1, '71340': 2, '71392': 1, '71555': 1, '71598': 8, '71705': 1, '71734': 3, '71736': 1, '71767': 1, '71792': 1, '71833': 2, '71851': 1, '71855': 1, '71860': 6, '71973': 2, '71989': 2, '72053': 2, '72065': 1, '72069': 5, '72074': 1, '72078': 1, '72152': 1, '72153': 1, '72234': 4, '72263': 1, '72264': 1, '72304': 3, '72319': 1, '72328': 9, '72342': 1, '72378': 2, '72421': 1, '72436': 1, '72459': 4, '72485': 1, '72517': 2, '72542': 2, '72586': 1, '72601': 1, '72605': 2, '72634': 11, '72738': 4, '72770': 12, '72775': 1, '72828': 1, '72831': 2, '72847': 1, '72884': 1, '72895': 1, '72942': 1, '72951': 1, '72953': 3, '72961': 1, '72987': 2, '73047': 12, '73058': 2, '73081': 1, '73089': 1, '73094': 1, '73141': 1, '73165': 1, '73181': 3, '73184': 3, '73188': 3, '73216': 4, '73217': 1, '73224': 8, '73225': 3, '73318': 1, '73324': 3, '73333': 5, '73349': 2, '73361': 1, '73369': 3, '73389': 1, '73477': 1, '73478': 1, '73482': 1, '73559': 1, '73623': 3, '73660': 9, '73667': 2, '73683': 1, '73693': 4, '73725': 1, '73726': 1, '73801': 1, '73853': 1, '73855': 1, '73885': 1, '73897': 5, '73928': 1, '73929': 1}\n"
     ]
    }
   ],
   "source": [
    "#create an inverted index for the test set\n",
    "inv_test = compute_inverted_index(query_test_tokens, prep_text_dict)\n",
    "show_inv_n(inv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zF2DcCM91Q-B"
   },
   "source": [
    "## BM25 and Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6-eVc7RtUbtb",
    "outputId": "ab1c5a9a-8e02-4200-d3b5-f535bc31e214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  bt_2498  38272  36.827641\n",
       "1  bt_2498  37863  33.743715\n",
       "2  bt_2498  66197  18.765094\n",
       "3  bt_2498   9159  18.676479\n",
       "4  bt_2498  54312  16.850490"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>66418</td>\n",
       "      <td>23.463165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>33171</td>\n",
       "      <td>20.685483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>69856</td>\n",
       "      <td>20.309743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>6390</td>\n",
       "      <td>19.888042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_741</td>\n",
       "      <td>5130</td>\n",
       "      <td>19.395687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score\n",
       "0  sfq_741  66418  23.463165\n",
       "1  sfq_741  33171  20.685483\n",
       "2  sfq_741  69856  20.309743\n",
       "3  sfq_741   6390  19.888042\n",
       "4  sfq_741   5130  19.395687"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>62422</td>\n",
       "      <td>13.850858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>47455</td>\n",
       "      <td>12.881140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>1728</td>\n",
       "      <td>12.524259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>57834</td>\n",
       "      <td>12.521499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_23151</td>\n",
       "      <td>19585</td>\n",
       "      <td>12.485555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question    doc      score\n",
       "0  sfq_23151  62422  13.850858\n",
       "1  sfq_23151  47455  12.881140\n",
       "2  sfq_23151   1728  12.524259\n",
       "3  sfq_23151  57834  12.521499\n",
       "4  sfq_23151  19585  12.485555"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "import gc\n",
    "\n",
    "\n",
    "#implemeetn the BIM without relevance judgement\n",
    "def compute_BIM_scores(inverted_index, text_files, prob_type=''):\n",
    "  \"\"\" Method that is called by the compute_BIM method below\n",
    "      ----------\n",
    "      inverted_index: inverted index containing all the question tokens as keys\n",
    "      and the corresponding list of documents they appear in; also contains frequency of occurences in each doc\n",
    "      text_files: dictionary with key: doc_id; value: preprocessed text tokens\n",
    "      prob_type: the method which is used for relevance score computation\n",
    "  \"\"\"\n",
    "  final_scores = dict()\n",
    "  total_num_docs = len(text_files)\n",
    "  total_doc_length = 0\n",
    "  for i, doc in enumerate(text_files.values()):\n",
    "    total_doc_length += len(doc)\n",
    "  avg_doc_length = total_doc_length / total_num_docs\n",
    "\n",
    "  for token in inverted_index.keys():\n",
    "    for doc in inverted_index[token]:\n",
    "      if doc not in final_scores.keys():\n",
    "        final_scores[doc] = 0\n",
    "      wt = math.log(0.5 * (total_num_docs/len(inverted_index[token])))\n",
    "\n",
    "      if prob_type == 'two_poisson':\n",
    "        final = wt * ((inverted_index[token][doc]*(2.5))/(inverted_index[token][doc]+1.5))\n",
    "      elif prob_type == 'BM11':\n",
    "        doc_length = len(text_files[doc])\n",
    "        final = wt * ((inverted_index[token][doc]*(2.5))/(inverted_index[token][doc]+1.5 * (doc_length / avg_doc_length)))\n",
    "      elif prob_type == 'BM25':\n",
    "        b = 0.5\n",
    "        doc_length = len(text_files[doc])\n",
    "        final = wt * ((inverted_index[token][doc]*(2.5))/(inverted_index[token][doc]+1.5 * (doc_length / avg_doc_length) * b + 1.5*(1-0.75)))\n",
    "      elif prob_type == 'BM25+':\n",
    "        b = 0.5\n",
    "        delta = 1\n",
    "        doc_length = len(text_files[doc])\n",
    "        final = wt * ((inverted_index[token][doc]*(2.5))/(inverted_index[token][doc]+1.5 * (doc_length / avg_doc_length) * b + 1.5*(1-0.75))+delta)\n",
    "      else:\n",
    "        final = wt\n",
    "      final_scores[doc] += final\n",
    "  return final_scores\n",
    "\n",
    "def compute_BIM(prep_question_dict, inverted_index, method='BM25+'):\n",
    "  \"\"\" Main BM-Method; Uses the prerocessed question dictionary and the inverted index\n",
    "      containing to that question tokens to compute the scores and return a dataframe\n",
    "      which contains the ranked documents based on that computed relevance score;\n",
    "      Each result dataframe is stored in a list, which is then, for RAM-reasons,\n",
    "      saved in google drive as a concatenated dataframe after each 10000 questions. \n",
    "      ----------\n",
    "      prep_question_dict: dict with key: question_id; value: tuple(question tokens, rel doc list)\n",
    "      inverted index: inverted index of the query tokens considering all document\n",
    "      method: type of relevance score\n",
    "  \"\"\"\n",
    "  final_dfs = list()\n",
    "  i = 0\n",
    "  for questionID, rel_tuple in prep_question_dict.items():\n",
    "    question_inverted_index = dict()\n",
    "    for token in rel_tuple[0]:\n",
    "      question_inverted_index[token] = inverted_index[token]\n",
    "    final_results = compute_BIM_scores(question_inverted_index, prep_text_dict, prob_type=method)\n",
    "    ordered = {k: v for k, v in sorted(final_results.items(), key=lambda item: item[1], reverse=True)}\n",
    "    df = pd.DataFrame(ordered.items(), columns=['doc', 'score'])[:50]\n",
    "    df.insert(0,'question',questionID)\n",
    "    final_dfs.append(df) \n",
    "    if i % 500 == 1:\n",
    "      print(i)\n",
    "      display(final_dfs[0].head())\n",
    "      gc.collect()\n",
    "    if (i%10000 == 5000):\n",
    "      final_df = pd.concat(final_dfs)\n",
    "      final_df.to_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm11_test_{}.csv'.format(i), sep='\\t')\n",
    "      del final_df\n",
    "      final_dfs = list()\n",
    "    i += 1\n",
    "  final_df = pd.concat(final_dfs)\n",
    "  final_df.to_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm11_test_{}.csv'.format(\"last\"), sep='\\t')\n",
    "\n",
    "compute_BIM(prep_question_test, inv_test, method='BM11')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGZXzDvSZwjW"
   },
   "outputs": [],
   "source": [
    "#compute BIM for train\n",
    "compute_BIM(prep_question_train, inv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jm7Zlc3taAhs"
   },
   "outputs": [],
   "source": [
    "#compute BIM for test\n",
    "compute_BIM(prep_question_test, inv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DYp2ntx574d"
   },
   "source": [
    "# Evaluation BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUnDZdRf63jG"
   },
   "source": [
    "## Precision Method definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jBc19_jo5-gD"
   },
   "outputs": [],
   "source": [
    "#methods used for evaluation\n",
    "\n",
    "def assign_labels(row, question_dict):\n",
    "  \"\"\" Returns 1 if doc id in the row is in the list of relevant documents of the \n",
    "      question_dict (doc is actually relevant) and 0 if not\n",
    "      ----------\n",
    "      results_df_list: list of result dataframes\n",
    "      question_dict: dict with key: question_id; value: tuple(question tokens, rel doc list)\n",
    "  \"\"\"\n",
    "  if int(row['doc']) in question_dict[row['question']][1]:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def add_labels(results_df_list, question_dict):\n",
    "  \"\"\" Adds a new column to all result dataframes in the list. Column contains 1\n",
    "      if document is actually relevant to a question and 0 if not.\n",
    "      ----------\n",
    "      results_df_list: list of result dataframes\n",
    "      question_dict: dict with key: question_id; value: tuple(question tokens, rel doc list)\n",
    "  \"\"\"\n",
    "  for result_df in results_df_list:\n",
    "    result_df['label'] = result_df.apply(lambda row: assign_labels(row, question_dict), axis=1)\n",
    "\n",
    "def fraction_found(results_df_list, question_dict):\n",
    "  found = 0 \n",
    "  for result_df in results_df_list:\n",
    "    found += result_df['label'].sum()\n",
    "  \n",
    "  num_relevant = 0\n",
    "  for q_rel_tuple in questions_dict.values():\n",
    "    num_relevant += sum(q_rel_tuple[1])\n",
    "\n",
    "  return found, num_relevant, found / num_relevant\n",
    "\n",
    "def PK(result_df, k=5):   \n",
    "  \"\"\" Computes the precision @k for a single query\n",
    "      ----------\n",
    "      result_df: dataframe containing scores for document considering one query\n",
    "  \"\"\"\n",
    "  return result_df.iloc[0:k]['label'].sum() / k\n",
    "\n",
    "def APK(result_df, k=5):\n",
    "  \"\"\" Computes the Average precision @k for a single query\n",
    "      ----------\n",
    "      result_df: dataframe containing scores for document considering one query\n",
    "  \"\"\"\n",
    "  apk = 0\n",
    "  count = 0 \n",
    "  for i, row in enumerate(result_df.iterrows()):\n",
    "    if row[1]['label'] == 1:\n",
    "      count += 1\n",
    "      apk += result_df.iloc[0:i+1]['label'].sum() / (i+1)\n",
    "    # just remove this to get AP without k\n",
    "    if i == k-1:\n",
    "      break\n",
    "  if count == 0:\n",
    "    return count\n",
    "  return apk / count\n",
    "\n",
    "def RPrec(result_df, question_dict):\n",
    "  \"\"\" Computes the R-Precision for a single query\n",
    "      ----------\n",
    "      result_df: dataframe containing scores for document considering one query\n",
    "      question_dict: dict with key: question_id; value: tuple(question tokens, rel doc list)\n",
    "  \"\"\"\n",
    "  return PK(result_df, len(question_dict[result_df.iloc[1]['question']][1]))\n",
    "\n",
    "def ARPrec(result_df, question_dict):\n",
    "  \"\"\" Computes the Average R-Precision for a single query\n",
    "      ----------\n",
    "      result_df: dataframe containing scores for document considering one query\n",
    "      question_dict: dict with key: question_id; value: tuple(question tokens, rel doc list)\n",
    "  \"\"\"\n",
    "  return APK(result_df, len(question_dict[result_df.iloc[1]['question']][1]))\n",
    "\n",
    "def meanPrecisions(result_df_list, question_dict, k=5, PType='P@K'):\n",
    "  \"\"\" Computes the Mean of the different precision types considering PType\n",
    "      ----------\n",
    "      result_dfllist: list of dataframes containing scores for document considering one query\n",
    "      question_dict: dict with key: question_id; value: tuple(question tokens, rel doc list)\n",
    "      k: parameter k for P@K and AP@K\n",
    "      PType: type of precision to compute\n",
    "  \"\"\"\n",
    "  mean = 0\n",
    "  for df in result_df_list:\n",
    "    if PType == 'P@K':\n",
    "      mean += PK(df, k)\n",
    "    elif PType == 'AP@K':\n",
    "      mean += APK(df, k)\n",
    "    elif PType == 'R-Precision':\n",
    "      mean += RPrec(df, question_dict)\n",
    "    elif PType == 'AR-Precision':\n",
    "      mean += ARPrec(df, question_dict)\n",
    "    else:\n",
    "      print(\"No valid evaluation matrix chosen; use one of P@K', 'AP@K', 'R-Precision' or 'AR-Precision' as input values for the PType\")\n",
    "      break\n",
    "  return mean/len(result_df_list)\n",
    "\n",
    "\n",
    "def add_missed_docs(result_df_list, prep_question_dict): \n",
    "  \"\"\" this method takes a list of result dataframes with the corresponding labels as input\n",
    "      each dataframe gets converted into a dataframe where relevant and non-relevant docs are equally distributed\n",
    "      ----------\n",
    "      result_dfllist: list of dataframes containing scores for document considering one query\n",
    "      prep_question_dict: dict with key: question_id; value: tokenized question\n",
    "  \"\"\"\n",
    "  results_df_list = list()\n",
    "  for i, result_df in enumerate(result_df_list):\n",
    "    rel_docs_list = prep_question_dict[result_df.iloc[0]['question']][1]\n",
    "    result_df = pd.concat([result_df.loc[result_df['label'] == 0][0:len(rel_docs_list)], result_df.loc[result_df['label'] == 1]])   \n",
    "    if result_df['label'].sum() < len(rel_docs_list):\n",
    "      for doc in rel_docs_list:\n",
    "        if doc not in list(result_df['doc']):\n",
    "          result_df.loc[len(result_df)] = [result_df.iloc[0]['question']] + [doc] + [0] + [1]\n",
    "    result_df.reset_index()\n",
    "    results_df_list.append(result_df)\n",
    "  return results_df_list\n",
    "\n",
    "def create_train_df(result_df_list, prep_question_dict):\n",
    "  \"\"\" creates train dataframe as described in the report using the add_missed_docs function\n",
    "      ----------\n",
    "      result_dfllist: list of dataframes containing scores for document considering one query\n",
    "      prep_question_dict: dict with key: question_id; value: tokenized question\n",
    "  \"\"\"\n",
    "  results_df_list = add_missed_docs(result_df_list, prep_question_dict)\n",
    "  train_df = pd.concat(results_df_list)\n",
    "  train_df = train_df.reset_index(drop=True)\n",
    "  return train_df\n",
    "\n",
    "def add_full_question(row, question_dict):\n",
    "  \"\"\" adds a full question text a dataframe using the questin_dict\n",
    "      ----------\n",
    "      question_dict: question_id -> full question\n",
    "  \"\"\"\n",
    "  return question_dict[row['question']]\n",
    "\n",
    "def add_full_doc(row, text_dict, id_doc_dict):\n",
    "  \"\"\" adds a full doc text a dataframe using the questin_dict\n",
    "      ----------\n",
    "      text_dict: title -> full text\n",
    "      id_doc_dict: id -> title\n",
    "  \"\"\"\n",
    "  return text_dict[id_doc_dict[str(row['doc'])]]\n",
    "\n",
    "def add_full_question_texts(train_df, question_dict):\n",
    "  \"\"\" adds a full question text a dataframe using the questin_dict\"\"\"\n",
    "\n",
    "  train_df['full_question'] = train_df.apply(lambda row: add_full_question(row, question_dict), axis=1)\n",
    "\n",
    "def add_full_doc_texts(train_df, question_dict, id_doc_dict):\n",
    "  \"\"\" adds a full doc text a dataframe using the questin_dict\"\"\"\n",
    "\n",
    "  train_df['full_doc'] = train_df.apply(lambda row: add_full_doc(row, text_dict, id_doc_dict), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp_j6c1O8T3n"
   },
   "source": [
    "## Loading the test dataset result frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCA91xz-8c23"
   },
   "source": [
    "\n",
    "\n",
    "*   For compuatational reasons we use the test-split (30% of the questions) in order to compute the different precision scores and compare the models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEyFOHb9vBAv"
   },
   "outputs": [],
   "source": [
    "#load the result dataframes of the testset bm25\n",
    "df_list = list()\n",
    "df_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25_test_5000.csv', sep='\\t'))\n",
    "df_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25_test_15000.csv', sep='\\t'))\n",
    "df_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25_test_last.csv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tzOjxAmWZz8r"
   },
   "outputs": [],
   "source": [
    "#load the result dataframes of the testset bm25+\n",
    "df_list2 = list()\n",
    "df_list2.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25+_test_5000.csv', sep='\\t'))\n",
    "df_list2.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25+_test_15000.csv', sep='\\t'))\n",
    "df_list2.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25+_test_last.csv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4A5B1t4vnY26"
   },
   "outputs": [],
   "source": [
    "#load results of bm11 \n",
    "df_list3 = list()\n",
    "df_list3.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm11_test_5000.csv', sep='\\t'))\n",
    "df_list3.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm11_test_15000.csv', sep='\\t'))\n",
    "df_list3.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm11_test_last.csv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "y1BvJoGKfNS-",
    "outputId": "178575ad-387d-460c-f9c4-4157473f485c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>52.852304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>48.663329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>40.346682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>51957</td>\n",
       "      <td>26.050616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>25.920588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>1767</td>\n",
       "      <td>25.446150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37204</td>\n",
       "      <td>24.281814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>53659</td>\n",
       "      <td>23.736476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>21554</td>\n",
       "      <td>23.016751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>22446</td>\n",
       "      <td>22.802304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>2381</td>\n",
       "      <td>22.621602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>71549</td>\n",
       "      <td>22.454322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>41597</td>\n",
       "      <td>22.352824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>22.260214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>64516</td>\n",
       "      <td>22.226961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>12311</td>\n",
       "      <td>22.220011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>4180</td>\n",
       "      <td>22.046372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9566</td>\n",
       "      <td>21.948514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>6532</td>\n",
       "      <td>21.422165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>44816</td>\n",
       "      <td>20.902739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>3624</td>\n",
       "      <td>20.481703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>12644</td>\n",
       "      <td>20.020692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>69377</td>\n",
       "      <td>19.969823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>2276</td>\n",
       "      <td>19.964339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>11859</td>\n",
       "      <td>19.653880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>43298</td>\n",
       "      <td>19.625761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>502</td>\n",
       "      <td>19.535223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>53189</td>\n",
       "      <td>19.514404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>67648</td>\n",
       "      <td>19.374716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>59284</td>\n",
       "      <td>19.329793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question    doc      score\n",
       "0   bt_2498  38272  52.852304\n",
       "1   bt_2498  37863  48.663329\n",
       "2   bt_2498  66197  40.346682\n",
       "3   bt_2498  51957  26.050616\n",
       "4   bt_2498   9159  25.920588\n",
       "5   bt_2498   1767  25.446150\n",
       "6   bt_2498  37204  24.281814\n",
       "7   bt_2498  53659  23.736476\n",
       "8   bt_2498  21554  23.016751\n",
       "9   bt_2498  22446  22.802304\n",
       "10  bt_2498   2381  22.621602\n",
       "11  bt_2498  71549  22.454322\n",
       "12  bt_2498  41597  22.352824\n",
       "13  bt_2498  54312  22.260214\n",
       "14  bt_2498  64516  22.226961\n",
       "15  bt_2498  12311  22.220011\n",
       "16  bt_2498   4180  22.046372\n",
       "17  bt_2498   9566  21.948514\n",
       "18  bt_2498   6532  21.422165\n",
       "19  bt_2498  44816  20.902739\n",
       "20  bt_2498   3624  20.481703\n",
       "21  bt_2498  12644  20.020692\n",
       "22  bt_2498  69377  19.969823\n",
       "23  bt_2498   2276  19.964339\n",
       "24  bt_2498  11859  19.653880\n",
       "25  bt_2498  43298  19.625761\n",
       "26  bt_2498    502  19.535223\n",
       "27  bt_2498  53189  19.514404\n",
       "28  bt_2498  67648  19.374716\n",
       "29  bt_2498  59284  19.329793"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#concate the dataframes into one large dataframe\n",
    "df_results = pd.concat(df_list)\n",
    "del df_results['Unnamed: 0']\n",
    "display(df_results.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "id": "QcVorfrtnP_N",
    "outputId": "16b2bbdf-db66-4f57-b2c9-572f42b5fa81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>34.686048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>30.497073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>22.180426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>17.600086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>51957</td>\n",
       "      <td>16.204863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37204</td>\n",
       "      <td>14.693858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>6532</td>\n",
       "      <td>14.544418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>13.939712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>4180</td>\n",
       "      <td>13.725870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>22446</td>\n",
       "      <td>13.701241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9566</td>\n",
       "      <td>13.628012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>71549</td>\n",
       "      <td>13.533744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>1767</td>\n",
       "      <td>13.020643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>49769</td>\n",
       "      <td>12.996472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>67648</td>\n",
       "      <td>12.836133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>16102</td>\n",
       "      <td>12.831425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>64516</td>\n",
       "      <td>12.381208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>27866</td>\n",
       "      <td>12.278666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>53189</td>\n",
       "      <td>12.245276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>23029</td>\n",
       "      <td>12.185505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>41597</td>\n",
       "      <td>12.121432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>13423</td>\n",
       "      <td>11.992405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>2276</td>\n",
       "      <td>11.825809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>12311</td>\n",
       "      <td>11.713549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>2381</td>\n",
       "      <td>11.645520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>35678</td>\n",
       "      <td>11.426183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>502</td>\n",
       "      <td>11.410836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>40853</td>\n",
       "      <td>11.404493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>30380</td>\n",
       "      <td>11.378342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>46913</td>\n",
       "      <td>11.344066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question    doc      score\n",
       "0   bt_2498  38272  34.686048\n",
       "1   bt_2498  37863  30.497073\n",
       "2   bt_2498  66197  22.180426\n",
       "3   bt_2498   9159  17.600086\n",
       "4   bt_2498  51957  16.204863\n",
       "5   bt_2498  37204  14.693858\n",
       "6   bt_2498   6532  14.544418\n",
       "7   bt_2498  54312  13.939712\n",
       "8   bt_2498   4180  13.725870\n",
       "9   bt_2498  22446  13.701241\n",
       "10  bt_2498   9566  13.628012\n",
       "11  bt_2498  71549  13.533744\n",
       "12  bt_2498   1767  13.020643\n",
       "13  bt_2498  49769  12.996472\n",
       "14  bt_2498  67648  12.836133\n",
       "15  bt_2498  16102  12.831425\n",
       "16  bt_2498  64516  12.381208\n",
       "17  bt_2498  27866  12.278666\n",
       "18  bt_2498  53189  12.245276\n",
       "19  bt_2498  23029  12.185505\n",
       "20  bt_2498  41597  12.121432\n",
       "21  bt_2498  13423  11.992405\n",
       "22  bt_2498   2276  11.825809\n",
       "23  bt_2498  12311  11.713549\n",
       "24  bt_2498   2381  11.645520\n",
       "25  bt_2498  35678  11.426183\n",
       "26  bt_2498    502  11.410836\n",
       "27  bt_2498  40853  11.404493\n",
       "28  bt_2498  30380  11.378342\n",
       "29  bt_2498  46913  11.344066"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results2 = pd.concat(df_list2)\n",
    "del df_results2['Unnamed: 0']\n",
    "display(df_results2.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "id": "YGJMeagInpRS",
    "outputId": "35084981-dde4-4c10-96cf-12eee227ca56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>38272</td>\n",
       "      <td>36.827641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37863</td>\n",
       "      <td>33.743715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>66197</td>\n",
       "      <td>18.765094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9159</td>\n",
       "      <td>18.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>54312</td>\n",
       "      <td>16.850490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>4180</td>\n",
       "      <td>16.238850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>9566</td>\n",
       "      <td>15.967551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>40853</td>\n",
       "      <td>14.571041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>6532</td>\n",
       "      <td>14.454412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>22446</td>\n",
       "      <td>14.389599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>51957</td>\n",
       "      <td>14.303257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>37204</td>\n",
       "      <td>13.335017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>65319</td>\n",
       "      <td>12.782891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>48868</td>\n",
       "      <td>12.694613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>36814</td>\n",
       "      <td>12.625180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>16102</td>\n",
       "      <td>12.621071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>49769</td>\n",
       "      <td>12.389708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>53189</td>\n",
       "      <td>12.382665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>67648</td>\n",
       "      <td>12.371242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>27866</td>\n",
       "      <td>12.116801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>6469</td>\n",
       "      <td>11.952666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>46913</td>\n",
       "      <td>11.721944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>30177</td>\n",
       "      <td>11.584726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>23712</td>\n",
       "      <td>11.550123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>13292</td>\n",
       "      <td>11.495064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>63542</td>\n",
       "      <td>11.399684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>23029</td>\n",
       "      <td>11.354919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>19400</td>\n",
       "      <td>11.305126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>23813</td>\n",
       "      <td>11.238961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bt_2498</td>\n",
       "      <td>72557</td>\n",
       "      <td>11.153189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question    doc      score\n",
       "0   bt_2498  38272  36.827641\n",
       "1   bt_2498  37863  33.743715\n",
       "2   bt_2498  66197  18.765094\n",
       "3   bt_2498   9159  18.676479\n",
       "4   bt_2498  54312  16.850490\n",
       "5   bt_2498   4180  16.238850\n",
       "6   bt_2498   9566  15.967551\n",
       "7   bt_2498  40853  14.571041\n",
       "8   bt_2498   6532  14.454412\n",
       "9   bt_2498  22446  14.389599\n",
       "10  bt_2498  51957  14.303257\n",
       "11  bt_2498  37204  13.335017\n",
       "12  bt_2498  65319  12.782891\n",
       "13  bt_2498  48868  12.694613\n",
       "14  bt_2498  36814  12.625180\n",
       "15  bt_2498  16102  12.621071\n",
       "16  bt_2498  49769  12.389708\n",
       "17  bt_2498  53189  12.382665\n",
       "18  bt_2498  67648  12.371242\n",
       "19  bt_2498  27866  12.116801\n",
       "20  bt_2498   6469  11.952666\n",
       "21  bt_2498  46913  11.721944\n",
       "22  bt_2498  30177  11.584726\n",
       "23  bt_2498  23712  11.550123\n",
       "24  bt_2498  13292  11.495064\n",
       "25  bt_2498  63542  11.399684\n",
       "26  bt_2498  23029  11.354919\n",
       "27  bt_2498  19400  11.305126\n",
       "28  bt_2498  23813  11.238961\n",
       "29  bt_2498  72557  11.153189"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results3 = pd.concat(df_list3)\n",
    "del df_results3['Unnamed: 0']\n",
    "display(df_results3.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjlPK8P2fyD9"
   },
   "outputs": [],
   "source": [
    "#split the dataframes according to the question\n",
    "df_result_list = list()\n",
    "for question, df_question in df_results.groupby('question'):\n",
    "    df_result_list.append(df_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jvm4l0SnuNL"
   },
   "outputs": [],
   "source": [
    "#split the dataframes according to the question\n",
    "df_result_list2 = list()\n",
    "for question, df_question in df_results2.groupby('question'):\n",
    "    df_result_list2.append(df_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86MKeMfTnuua"
   },
   "outputs": [],
   "source": [
    "#split the dataframes according to the question\n",
    "df_result_list3 = list()\n",
    "for question, df_question in df_results3.groupby('question'):\n",
    "    df_result_list3.append(df_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "Ay3uTKkRfOkA",
    "outputId": "d0b29728-aeb1-4523-fe6b-49483578de2c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-43d7b2ea7250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#add a label columnn to the result dataframes in order to evaluate them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madd_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_result_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_question_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prep_question_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#add a label columnn to the result dataframes in order to evaluate them\n",
    "add_labels(df_result_list, prep_question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7jX0qcwoNl0"
   },
   "outputs": [],
   "source": [
    "#add a label columnn to the result dataframes in order to evaluate them\n",
    "add_labels(df_result_list2, prep_question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGNckvr7oNu7"
   },
   "outputs": [],
   "source": [
    "#add a label columnn to the result dataframes in order to evaluate them\n",
    "add_labels(df_result_list3, prep_question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZobM03CB7f_f"
   },
   "outputs": [],
   "source": [
    "#print some result dataframes\n",
    "#for reranking: 50, 52, 8\n",
    "#for here: 1002,104\n",
    "display(df_result_list[104])\n",
    "display(df_result_list[1002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GWideDTtEXM",
    "outputId": "256a5dd4-6ee5-403f-c048-8cdf5eef5a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "P@K:  1.0\n",
      "AP@K:  1.0\n",
      "2\n",
      "P@K:  0.5\n",
      "AP@K:  1.0\n",
      "3\n",
      "P@K:  0.3333333333333333\n",
      "AP@K:  1.0\n",
      "4\n",
      "P@K:  0.5\n",
      "AP@K:  0.75\n",
      "5\n",
      "P@K:  0.4\n",
      "AP@K:  0.75\n",
      "6\n",
      "P@K:  0.3333333333333333\n",
      "AP@K:  0.75\n",
      "7\n",
      "P@K:  0.2857142857142857\n",
      "AP@K:  0.75\n",
      "\n",
      "RPrec:  0.5\n",
      "ARPrec:  1.0\n"
     ]
    }
   ],
   "source": [
    "#compute P@K, AP@K, R-Precision and Average R-Precision based on one dataframe for different values of K\n",
    "for i in range(1,8):\n",
    "  print(i)\n",
    "  print(\"P@K: \",PK(df_result_list[1002],i))\n",
    "  print(\"AP@K: \", APK(df_result_list[1002],i))\n",
    "print()\n",
    "print(\"RPrec: \",RPrec(df_result_list[1002], prep_question_test))\n",
    "print(\"ARPrec: \", ARPrec(df_result_list[1002], prep_question_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBM3_46JoSUM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6Rqk0SdATWe",
    "outputId": "71b89133-4d18-4624-b78f-fb0b3bc79254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPK: k= 1 :  0.4898475790380783\n",
      "MAPK: k=1:  0.4898475790380783\n",
      "MPK: k= 2 :  0.36010125491463346\n",
      "MAPK: k=2:  0.5599450638229116\n",
      "MPK: k= 3 :  0.28451912892047587\n",
      "MAPK: k=3:  0.5769689951706483\n",
      "MPK: k= 4 :  0.23465018581354016\n",
      "MAPK: k=4:  0.5817744145826274\n",
      "MPK: k= 5 :  0.2001400333925513\n",
      "MAPK: k=5:  0.5828943825066073\n",
      "MPK: k= 6 :  0.17462882174465755\n",
      "MAPK: k=6:  0.5821485102003033\n",
      "MPK: k= 7 :  0.15512160592143098\n",
      "MAPK: k=7:  0.5811305003500871\n",
      "MRP:  0.4182936788769691\n",
      "MARP:  0.5290221804112454\n"
     ]
    }
   ],
   "source": [
    "#compute mean scores for the list of the two inspected dataframes\n",
    "test_list = [df_result_list[1002], df_result_list[104]]\n",
    "for i in range(1, 8):\n",
    "  MPK = meanPrecisions(df_result_list, prep_question_test, k=i, PType='P@K')\n",
    "  print(\"MPK: k=\",i,\": \",MPK)\n",
    "  MAPK = meanPrecisions(df_result_list, prep_question_test, k=i, PType='AP@K')\n",
    "  print(\"MAPK: k={}: \".format(i),MAPK)\n",
    "MRPrecision = meanPrecisions(df_result_list, prep_question_test, k=5, PType='R-Precision')\n",
    "print(\"MRP: \", MRPrecision)\n",
    "MARPrecision = meanPrecisions(df_result_list, prep_question_test, k=5, PType='AR-Precision')\n",
    "print(\"MARP: \", MARPrecision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufWRittYodYU",
    "outputId": "d86bd053-42eb-4f0e-bfb7-5fe26c91533b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPK: k= 1 :  0.5194700274680886\n",
      "MAPK: k=1:  0.5194700274680886\n",
      "MPK: k= 2 :  0.3790326924112673\n",
      "MAPK: k=2:  0.5906985511929768\n",
      "MPK: k= 3 :  0.297463241234433\n",
      "MAPK: k=3:  0.6061336421249255\n",
      "MPK: k= 4 :  0.24527387300048473\n",
      "MAPK: k=4:  0.6107774845454673\n",
      "MPK: k= 5 :  0.2082188829643704\n",
      "MAPK: k=5:  0.6107121805114327\n",
      "MPK: k= 6 :  0.1810829249025886\n",
      "MAPK: k=6:  0.6102258786497039\n",
      "MPK: k= 7 :  0.16060752948782298\n",
      "MAPK: k=7:  0.6091144084786081\n",
      "MRP:  0.44262430328030317\n",
      "MARP:  0.5575267837867328\n"
     ]
    }
   ],
   "source": [
    "#compute mean scores for the list of the two inspected dataframes\n",
    "test_list = [df_result_list[1002], df_result_list[104]]\n",
    "for i in range(1, 8):\n",
    "  MPK = meanPrecisions(df_result_list2, prep_question_test, k=i, PType='P@K')\n",
    "  print(\"MPK: k=\",i,\": \",MPK)\n",
    "  MAPK = meanPrecisions(df_result_list2, prep_question_test, k=i, PType='AP@K')\n",
    "  print(\"MAPK: k={}: \".format(i),MAPK)\n",
    "MRPrecision = meanPrecisions(df_result_list2, prep_question_test, k=5, PType='R-Precision')\n",
    "print(\"MRP: \", MRPrecision)\n",
    "MARPrecision = meanPrecisions(df_result_list2, prep_question_test, k=5, PType='AR-Precision')\n",
    "print(\"MARP: \", MARPrecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcC9_Ekdodzc",
    "outputId": "15cd4878-c759-4cc3-b0ee-ec80b633d655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPK: k= 1 :  0.46728065923412504\n",
      "MAPK: k=1:  0.46728065923412504\n",
      "MPK: k= 2 :  0.34453600473959173\n",
      "MAPK: k=2:  0.5385899714547315\n",
      "MPK: k= 3 :  0.2757042063876706\n",
      "MAPK: k=3:  0.5576156621963738\n",
      "MPK: k= 4 :  0.2291565681047019\n",
      "MAPK: k=4:  0.5633307002268102\n",
      "MPK: k= 5 :  0.1963052727957942\n",
      "MAPK: k=5:  0.565394322663275\n",
      "MPK: k= 6 :  0.17184610689214172\n",
      "MAPK: k=6:  0.564869122636943\n",
      "MPK: k= 7 :  0.15281336318662406\n",
      "MAPK: k=7:  0.5643499005318388\n",
      "MRP:  0.39992508598502824\n",
      "MARP:  0.5082911554366562\n"
     ]
    }
   ],
   "source": [
    "#compute mean scores for the list of the two inspected dataframes\n",
    "test_list = [df_result_list[1002], df_result_list[104]]\n",
    "for i in range(1, 8):\n",
    "  MPK = meanPrecisions(df_result_list3, prep_question_test, k=i, PType='P@K')\n",
    "  print(\"MPK: k=\",i,\": \",MPK)\n",
    "  MAPK = meanPrecisions(df_result_list3, prep_question_test, k=i, PType='AP@K')\n",
    "  print(\"MAPK: k={}: \".format(i),MAPK)\n",
    "MRPrecision = meanPrecisions(df_result_list3, prep_question_test, k=5, PType='R-Precision')\n",
    "print(\"MRP: \", MRPrecision)\n",
    "MARPrecision = meanPrecisions(df_result_list3, prep_question_test, k=5, PType='AR-Precision')\n",
    "print(\"MARP: \", MARPrecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16da7lzKt4kz",
    "outputId": "7b6df576-4bdd-45fd-a335-c2be095b3314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2001400333925513\n",
      "0.5828943825066073\n",
      "0.4182936788769691\n",
      "0.5290221804112454\n"
     ]
    }
   ],
   "source": [
    "#compute mean scores for the whole test set\n",
    "MPK = meanPrecisions(df_result_list, prep_question_test, k=5, PType='P@K')\n",
    "MAPK = meanPrecisions(df_result_list, prep_question_test, k=5, PType='AP@K')\n",
    "MRPrecision = meanPrecisions(df_result_list, prep_question_test, k=5, PType='R-Precision')\n",
    "MARPrecision = meanPrecisions(df_result_list, prep_question_test, k=5, PType='AR-Precision')\n",
    "\n",
    "print(MPK)\n",
    "print(MAPK)\n",
    "print(MRPrecision)\n",
    "print(MARPrecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8pTEVcC5hbt"
   },
   "source": [
    "# monoBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64uT2VyqZpsI"
   },
   "source": [
    "## Dataset/Loader and Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vmrEB5BeZvkN"
   },
   "outputs": [],
   "source": [
    "# 1 - Dataset for monoBERT is prepared\n",
    "# monoBERT_dataset class and its properties are defined\n",
    "class monoBERT_dataset(Dataset):\n",
    "  def __init__(self):\n",
    "    csv_path = \"./gdrive/MyDrive/Information_Retrieval_Project/monoBERT/monoBERT_train.csv\"\n",
    "    self.dataset = pd.read_csv(csv_path, sep='\\t')\n",
    "\n",
    "  def __len__(self): \n",
    "    return len(self.dataset)\n",
    "  \n",
    "  def __getitem__(self, itemID):\n",
    "    row = self.dataset.iloc[itemID]\n",
    "    return row['full_question'], row['full_doc'], row['label']\n",
    "\n",
    "# 2 - Dataloader is prepared to iterate over batches \n",
    "# Get a dataloader for monoBERT\n",
    "# Batch size = 16 (max amount the gpu can handle); shuffle = true\n",
    "def get_dataloader_monoBERT():\n",
    "  monoBERT_data = monoBERT_dataset()\n",
    "  dataloader = DataLoader(dataset=monoBERT_data, batch_size=16, shuffle=True, num_workers=1)\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DlJgXchFaHM0"
   },
   "outputs": [],
   "source": [
    "# weights initialization for the linear model using xavier initialization function\n",
    "# more stable and faster training\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        torch.nn.init.zero_(m.bias)\n",
    "\n",
    "#monobert model with pretrained distilroberta-base and a linear model for the output\n",
    "#takes the [CLS]-embedding of the BERT model for as input of the linear model\n",
    "class monoBERT(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(monoBERT, self).__init__()\n",
    "    self.bert = AutoModel.from_pretrained('distilroberta-base')\n",
    "    self.decision = nn.Sequential(\n",
    "            nn.Linear(768, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "    weights_init(self.decision)\n",
    "  def forward(self, ids, mask):\n",
    "    outputs = self.bert(\n",
    "               ids, \n",
    "               attention_mask=mask)\n",
    "    \n",
    "    sequence_output = outputs.last_hidden_state\n",
    "    x = sequence_output[:,0,:].contiguous().view(-1,768)\n",
    "\n",
    "    decision_output = self.decision(x) ## extract the 1st token's embeddings\n",
    "    return decision_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YkYzCaOPZXlc"
   },
   "outputs": [],
   "source": [
    "# Tokenizer for monoBERT\n",
    "def tokenize_monoBERT(question, text, tokenizer):\n",
    "  # creates: [CLS] question [SEP] Doc [SEP], max 512 tokens\n",
    "  tokenized_input = tokenizer(question, text, return_tensors='pt', max_length=512, padding=True, truncation='only_second')\n",
    "  return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LmI8gbDmZdDQ"
   },
   "outputs": [],
   "source": [
    "#Get a monoBERT model and tokenizer\n",
    "def get_monoBERT_and_tokenizer():\n",
    "  return monoBERT(), AutoTokenizer.from_pretrained('distilroberta-base', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9x0W36Hrijtk"
   },
   "outputs": [],
   "source": [
    "def load_monoBERT(path):\n",
    "  model = monoBERT()\n",
    "  model.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "  model.eval()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuZ21194e2sq"
   },
   "source": [
    "## Training Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4A4KNe9Db3u"
   },
   "source": [
    "\n",
    "\n",
    "*   Execute these cells if you want to train the model\n",
    "*   First the results of bm25 on the training set are loaded \n",
    "*   Then the dataset is prepared by first adding labels to the result dataframes and then creating a dataframe which contains all relevant documents from the training json and the same number of irrelevant documents for each query\n",
    "* These irrelevant documents are the top n irrelavant documents from the bm25  output dataframes, to make the training as specific and difficult for monoBERT as possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDkvH4bT5kmI"
   },
   "outputs": [],
   "source": [
    "df_list = list()\n",
    "df_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25_train_10000.csv', sep='\\t'))\n",
    "df_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25_train_22000.csv', sep='\\t'))\n",
    "df_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25_train_34000.csv', sep='\\t'))\n",
    "df_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25_train_last.csv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "id": "OKuZjwxOG6LC",
    "outputId": "de7d669f-dd2b-4574-c901-61d82aec4827"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>19446</td>\n",
       "      <td>35.506735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>73063</td>\n",
       "      <td>26.827606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>11848</td>\n",
       "      <td>25.706211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>45493</td>\n",
       "      <td>24.775058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>62422</td>\n",
       "      <td>24.552775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>17754</td>\n",
       "      <td>23.573254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>65288</td>\n",
       "      <td>22.296650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>26802</td>\n",
       "      <td>22.122978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>64876</td>\n",
       "      <td>21.665808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sfq_24649</td>\n",
       "      <td>42152</td>\n",
       "      <td>21.625962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>49457</td>\n",
       "      <td>23.984038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>51976</td>\n",
       "      <td>22.958184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>64533</td>\n",
       "      <td>22.659862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>26942</td>\n",
       "      <td>22.518153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>52940</td>\n",
       "      <td>22.214013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>53569</td>\n",
       "      <td>21.594653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>16367</td>\n",
       "      <td>21.418087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>64883</td>\n",
       "      <td>21.181395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>33866</td>\n",
       "      <td>21.140560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tc_2975</td>\n",
       "      <td>25766</td>\n",
       "      <td>21.024266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>66725</td>\n",
       "      <td>39.858441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>56605</td>\n",
       "      <td>38.710930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>30683</td>\n",
       "      <td>34.765065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>47740</td>\n",
       "      <td>34.455178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>62963</td>\n",
       "      <td>30.370899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>73063</td>\n",
       "      <td>28.198107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>4103</td>\n",
       "      <td>27.872113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>2473</td>\n",
       "      <td>27.640479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>57941</td>\n",
       "      <td>24.221924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qw_9103</td>\n",
       "      <td>69436</td>\n",
       "      <td>23.321414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     question    doc      score\n",
       "0   sfq_24649  19446  35.506735\n",
       "1   sfq_24649  73063  26.827606\n",
       "2   sfq_24649  11848  25.706211\n",
       "3   sfq_24649  45493  24.775058\n",
       "4   sfq_24649  62422  24.552775\n",
       "5   sfq_24649  17754  23.573254\n",
       "6   sfq_24649  65288  22.296650\n",
       "7   sfq_24649  26802  22.122978\n",
       "8   sfq_24649  64876  21.665808\n",
       "9   sfq_24649  42152  21.625962\n",
       "10    tc_2975  49457  23.984038\n",
       "11    tc_2975  51976  22.958184\n",
       "12    tc_2975  64533  22.659862\n",
       "13    tc_2975  26942  22.518153\n",
       "14    tc_2975  52940  22.214013\n",
       "15    tc_2975  53569  21.594653\n",
       "16    tc_2975  16367  21.418087\n",
       "17    tc_2975  64883  21.181395\n",
       "18    tc_2975  33866  21.140560\n",
       "19    tc_2975  25766  21.024266\n",
       "20    qw_9103  66725  39.858441\n",
       "21    qw_9103  56605  38.710930\n",
       "22    qw_9103  30683  34.765065\n",
       "23    qw_9103  47740  34.455178\n",
       "24    qw_9103  62963  30.370899\n",
       "25    qw_9103  73063  28.198107\n",
       "26    qw_9103   4103  27.872113\n",
       "27    qw_9103   2473  27.640479\n",
       "28    qw_9103  57941  24.221924\n",
       "29    qw_9103  69436  23.321414"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#concate the dataframes into one large dataframe\n",
    "df_train = pd.concat(df_list)\n",
    "del df_train['Unnamed: 0']\n",
    "display(df_train.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhx1IBwGG-rY"
   },
   "outputs": [],
   "source": [
    "#split the dataframes according to the question\n",
    "df_train_list = list()\n",
    "for question, df_question in df_train.groupby('question'):\n",
    "    df_train_list.append(df_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7Sx39OCHBP5"
   },
   "outputs": [],
   "source": [
    "#add a label columnn to the result dataframes in order to evaluate them\n",
    "add_labels(df_train_list, prep_question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx01UxJClnct"
   },
   "outputs": [],
   "source": [
    "train_df = create_train_df(df_train_list, prep_question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "tIkP6xzJwj_F",
    "outputId": "b94ca32f-f1bb-40e9-f50d-a748d33fd822"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>27062</td>\n",
       "      <td>26.281998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>72724</td>\n",
       "      <td>31.566161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>71300</td>\n",
       "      <td>51.199494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>5640</td>\n",
       "      <td>46.079267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>72730</td>\n",
       "      <td>41.535001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>11920</td>\n",
       "      <td>37.791938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bb_1011</td>\n",
       "      <td>37131</td>\n",
       "      <td>71.760624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bb_1011</td>\n",
       "      <td>62787</td>\n",
       "      <td>86.785895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bb_1014</td>\n",
       "      <td>11682</td>\n",
       "      <td>58.728495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb_1014</td>\n",
       "      <td>16945</td>\n",
       "      <td>92.952497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bb_1015</td>\n",
       "      <td>23622</td>\n",
       "      <td>39.059623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bb_1015</td>\n",
       "      <td>3157</td>\n",
       "      <td>46.218944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bb_1016</td>\n",
       "      <td>26354</td>\n",
       "      <td>56.967734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bb_1016</td>\n",
       "      <td>12291</td>\n",
       "      <td>45.671256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bb_1018</td>\n",
       "      <td>49532</td>\n",
       "      <td>49.307073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bb_1018</td>\n",
       "      <td>70931</td>\n",
       "      <td>48.298522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bb_1018</td>\n",
       "      <td>63827</td>\n",
       "      <td>51.055153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bb_1018</td>\n",
       "      <td>16402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bb_1022</td>\n",
       "      <td>34842</td>\n",
       "      <td>62.353183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bb_1022</td>\n",
       "      <td>16947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question    doc      score  label\n",
       "0     bb_10  27062  26.281998      0\n",
       "1     bb_10  72724  31.566161      1\n",
       "2   bb_1000  71300  51.199494      0\n",
       "3   bb_1000   5640  46.079267      0\n",
       "4   bb_1000  72730  41.535001      1\n",
       "5   bb_1000  11920  37.791938      1\n",
       "6   bb_1011  37131  71.760624      0\n",
       "7   bb_1011  62787  86.785895      1\n",
       "8   bb_1014  11682  58.728495      0\n",
       "9   bb_1014  16945  92.952497      1\n",
       "10  bb_1015  23622  39.059623      0\n",
       "11  bb_1015   3157  46.218944      1\n",
       "12  bb_1016  26354  56.967734      0\n",
       "13  bb_1016  12291  45.671256      1\n",
       "14  bb_1018  49532  49.307073      0\n",
       "15  bb_1018  70931  48.298522      0\n",
       "16  bb_1018  63827  51.055153      1\n",
       "17  bb_1018  16402   0.000000      1\n",
       "18  bb_1022  34842  62.353183      0\n",
       "19  bb_1022  16947   0.000000      1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154535\n"
     ]
    }
   ],
   "source": [
    "display(train_df.head(20))\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "Elqte7IUb5-7",
    "outputId": "838d38ab-5d7c-47c5-f37c-0dfb33a15641"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>27062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>72724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>71300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>5640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>72730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc  label\n",
       "0    bb_10  27062      0\n",
       "1    bb_10  72724      1\n",
       "2  bb_1000  71300      0\n",
       "3  bb_1000   5640      0\n",
       "4  bb_1000  72730      1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#remove the bm25-scoring\n",
    "del train_df['score']\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "wY64yKWmc63j",
    "outputId": "ce655f2c-6ffd-4436-8b0b-890b349ac6e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>27062</td>\n",
       "      <td>0</td>\n",
       "      <td>In the US TV comedy show Everybody Loves Raymo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>72724</td>\n",
       "      <td>1</td>\n",
       "      <td>In the US TV comedy show Everybody Loves Raymo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>71300</td>\n",
       "      <td>0</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>5640</td>\n",
       "      <td>0</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>72730</td>\n",
       "      <td>1</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc  label                                      full_question\n",
       "0    bb_10  27062      0  In the US TV comedy show Everybody Loves Raymo...\n",
       "1    bb_10  72724      1  In the US TV comedy show Everybody Loves Raymo...\n",
       "2  bb_1000  71300      0  An adaptation of which classic 1905 story by E...\n",
       "3  bb_1000   5640      0  An adaptation of which classic 1905 story by E...\n",
       "4  bb_1000  72730      1  An adaptation of which classic 1905 story by E..."
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add full_questions to the dataframe\n",
    "add_full_question_texts(train_df, question_dict)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "5wdJ4Y2GdGiu",
    "outputId": "1e83b457-3f8f-4519-8498-05fbd2e88e53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>27062</td>\n",
       "      <td>0</td>\n",
       "      <td>In the US TV comedy show Everybody Loves Raymo...</td>\n",
       "      <td>Becker is an American sitcom that ran from 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_10</td>\n",
       "      <td>72724</td>\n",
       "      <td>1</td>\n",
       "      <td>In the US TV comedy show Everybody Loves Raymo...</td>\n",
       "      <td>Everybody Loves Raymond is an American televis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>71300</td>\n",
       "      <td>0</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "      <td>The Railway Children is a children's book by E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>5640</td>\n",
       "      <td>0</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "      <td>John Barrymore (born John Sidney Blyth; Februa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1000</td>\n",
       "      <td>72730</td>\n",
       "      <td>1</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "      <td>Edith Nesbit (married name Edith Bland; 15 Aug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question  ...                                           full_doc\n",
       "0    bb_10  ...  Becker is an American sitcom that ran from 199...\n",
       "1    bb_10  ...  Everybody Loves Raymond is an American televis...\n",
       "2  bb_1000  ...  The Railway Children is a children's book by E...\n",
       "3  bb_1000  ...  John Barrymore (born John Sidney Blyth; Februa...\n",
       "4  bb_1000  ...  Edith Nesbit (married name Edith Bland; 15 Aug...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add full_texts to the dataframe\n",
    "add_full_doc_texts(train_df, text_dict, id_title_dict)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeC1U80AeY5n"
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('./gdrive/MyDrive/Information_Retrieval_Project/monoBERT/monoBERT_train.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSkZIwUKZtMg"
   },
   "source": [
    "## Model initilization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1FkIJtvaocL"
   },
   "outputs": [],
   "source": [
    "#initialize the dataloader\n",
    "loader = get_dataloader_monoBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGSQe4qLiUm1"
   },
   "outputs": [],
   "source": [
    "#or initialize from checkpoint\n",
    "model = load_monoBERT('./gdrive/MyDrive/Information_Retrieval_Project/monoBERT/monoBERT_lr_0.0001_DROPOUT_Adam_epoch_3.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3i7zi1SaihE",
    "outputId": "13a40bf6-d488-4e48-fbfb-1ad1d40a703c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#initialize model and tokenizer; work on GPU (cuda)\n",
    "_, tokenizer = get_monoBERT_and_tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7pws0xt9QcJ",
    "outputId": "f9fa11c5-e526-445e-c935-c19d7be551be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = monoBERTCNN()\n",
    "model.to('cuda')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPkk8o2LatBY"
   },
   "outputs": [],
   "source": [
    "# Criterion and Optimizer are defined for training\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJbKkc8zfAaS"
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "epochs = 100\n",
    "\n",
    "for j, epoch in enumerate(range(epochs)):\n",
    "  avg_loss = 0 \n",
    "  print(\"EPOCH\")\n",
    "  for i, batch in enumerate(loader):\n",
    "    question = batch[0]\n",
    "    paragraph = batch[1] ## assuming that data loader returns a tuple of data and its targets\n",
    "    target = batch[2].to('cuda')\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()   \n",
    "    encoding = tokenize_monoBERT(question, paragraph, tokenizer)\n",
    "\n",
    "    #get token_ids and attention_mask from encoding\n",
    "    input_ids = encoding['input_ids'].to('cuda')\n",
    "    attention_mask = encoding['attention_mask'].to('cuda')\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    outputs = outputs.flatten()\n",
    "    loss = criterion(outputs, target.to(torch.float32))\n",
    "    avg_loss += loss\n",
    "\n",
    "    if i % 10 == 5:\n",
    "      print(\"Batch_loss: \", loss)\n",
    "      print(\"Item:{} - avg_loss: {}\".format(i*16,avg_loss/i))\n",
    "\n",
    "    if i == 5000:\n",
    "      print(\"Save the weights\")\n",
    "      torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "      }, \"./gdrive/MyDrive/Information_Retrieval_Project/monoBERT/monoBERT_lr_0.0001_DROPOUT_Adam_epoch_{}.tar\".format(epoch))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_fxftEi0woi"
   },
   "source": [
    "## Prediction Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ld_XCqR8EqpW"
   },
   "source": [
    "### Prepare the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9LAcNgEjHWY"
   },
   "source": [
    "\n",
    "\n",
    "*   The test data can already be loaded in the section \"loading the test dataset result frames of \"Evaluation BM25\"\n",
    "*   However, if test data is not created there already, you can simply execute this block here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AMiGkO03naa_"
   },
   "outputs": [],
   "source": [
    "_, prep_question_dict, text_dict, id_title_dict, question_dict = load_all_dictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0tjKaOGL0yre"
   },
   "outputs": [],
   "source": [
    "#load the testset\n",
    "test_list = list()\n",
    "test_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25+_test_5000.csv', sep='\\t'))\n",
    "test_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25+_test_15000.csv', sep='\\t'))\n",
    "test_list.append(pd.read_csv('./gdrive/MyDrive/Information_Retrieval_Project/bm25_outputs/bm25+_test_last.csv', sep='\\t'))\n",
    "\n",
    "df_test = pd.concat(test_list)\n",
    "\n",
    "del df_test['Unnamed: 0']\n",
    "df_test.reset_index(inplace=True)\n",
    "del df_test['index']\n",
    "\n",
    "#split the dataframes according to the question\n",
    "df_test_list = list()\n",
    "for question, df_question in df_test.groupby('question'):\n",
    "  #del df_question['level_0']\n",
    "  df_question.reset_index(inplace=True)\n",
    "  del df_question['index']\n",
    "  df_test_list.append(df_question)\n",
    "\n",
    "add_labels(df_test_list, prep_question_dict)\n",
    "\n",
    "test_df = pd.concat(df_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "mTy-RxdolmIw",
    "outputId": "7d5140cf-b23b-444f-9ff6-9a45db860d65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_0</td>\n",
       "      <td>25823</td>\n",
       "      <td>18.015410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_0</td>\n",
       "      <td>44424</td>\n",
       "      <td>17.880314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_0</td>\n",
       "      <td>1345</td>\n",
       "      <td>17.324262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_0</td>\n",
       "      <td>50244</td>\n",
       "      <td>16.947543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_0</td>\n",
       "      <td>20092</td>\n",
       "      <td>16.911382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question    doc      score  label\n",
       "0     bb_0  25823  18.015410      1\n",
       "1     bb_0  44424  17.880314      0\n",
       "2     bb_0   1345  17.324262      0\n",
       "3     bb_0  50244  16.947543      0\n",
       "4     bb_0  20092  16.911382      0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-MgBsZIjiBn"
   },
   "outputs": [],
   "source": [
    "#write the test_df to the drive\n",
    "test_df.to_csv('./gdrive/MyDrive/Information_Retrieval_Project/monoBERT/monoBERT_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FwE7YP_jqTM"
   },
   "source": [
    "### Prediction Methods for monoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "P0Mkb37vDCiC"
   },
   "outputs": [],
   "source": [
    "def predict_single_query(test_df, question_id, question_dict, id_title_dict, text_dict, model, tokenizer):\n",
    "  \"\"\" scores the documents given a query\n",
    "      ----------\n",
    "      test_df: dataframe containing the bm25+ outputs\n",
    "      question_id: id of question we want to predict for\n",
    "  \"\"\"\n",
    "  temp_df = test_df[test_df['question'] == question_id]\n",
    "  add_full_question_texts(temp_df, question_dict)\n",
    "  add_full_doc_texts(temp_df, text_dict, id_title_dict)\n",
    "  \n",
    "  text_list = list(temp_df['full_doc'])\n",
    "  question_list = list(temp_df['full_question'])\n",
    "  \n",
    "  encoding = tokenize_monoBERT(question_list, text_list, tokenizer)\n",
    "\n",
    "\n",
    "  outputs = model(encoding['input_ids'], encoding['attention_mask'])\n",
    " \n",
    "  temp_df['score'] = outputs.cpu().detach().numpy()\n",
    "  \n",
    "  return temp_df.sort_values(by=['score'], ascending=False)\n",
    "\n",
    "def predict_multiple_queries(test_df, question_id_list, question_dict, id_title_dict, text_dict, model, tokenizer):\n",
    "  \"\"\" scores the documents given a list of questions; returns a list of dataframes with ranked documents\n",
    "      ----------\n",
    "  \"\"\"\n",
    "  result_df_list = list()\n",
    "  for i, question_id in enumerate(question_id_list):\n",
    "    result_df_list.append(predict_single_query(test_df, question_id, question_dict, id_title_dict, text_dict, model, tokenizer)[0:10])\n",
    "    print(i)\n",
    "\n",
    "  return result_df_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PANMjAK1kL0J"
   },
   "source": [
    "### Single query prediction workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392,
     "referenced_widgets": [
      "3e0c25b4d7b04c2d8191d4124c367a5f",
      "b159100d944348c78fdc36b8f16be12c",
      "ea990de26a164481bc765f0e40abbc50",
      "5b9ce03bcd974e258db06a44d694fc40",
      "ecdd6e27940e47a2a01b2b466a1177d8",
      "4d5fd0ca1a7942ccb8009403cc823d22",
      "41ab387cdaff4f038261b3f85e9355bf",
      "c984e45490224458b3f3fef0049c994a",
      "c9e682ab03e84ddd80fbdb1f684049e7",
      "ca0def8c27b64971a843b6dd58498838",
      "e3da69bca30a452d90c54cfd02ac92e2",
      "1aef7dfcd17b40f69f3feceb0f5759ff",
      "f8a2f9d4e04d4acb87a3766c31b6ac1e",
      "a539328b2681470981654b562f4c90ad",
      "27920eb5dc2c435d989248bc218dce10",
      "c3bf9956f8c94f05b45173085fb50272",
      "868a0285280a44faa3aee4e65b44ae56",
      "9528fee6a0274ae6b9a612713b330cf0",
      "8b41697e64a74750878290b6aea66bb1",
      "f3a186e9567849e59ea539a91f0c2748",
      "3d769057db0e4e9ba9e99cf11fcf9d06",
      "4af7df11ca27409c84b3fd05e2d80b0c",
      "140820e5d1964f32b7a5e527887b9f17",
      "36d9cd91683344d58c7f4723148e0317",
      "7bc4bcdcc68f408fa880d56513469d9e",
      "0dc14bd7e9224c318d6cab6d4c79528d",
      "72eecb5c27304be5a9011e56723a857d",
      "d7d9501551f845e8bedcc20729eabb5c",
      "3a5de4010a84493f9e582a125114b55e",
      "59eeda1f0d324da1aba459951a7453cf",
      "7d01fc7f4fa340fdb7f5f0c67a186f0b",
      "a916913ea81c4fc5bf54ebb4cc03341b",
      "172d9e49e6a643f3be2900a4ff3907bc",
      "07fadfbf86c74e86858d3ce5dd7a45a5",
      "ede5e11dff9949d9a8eafad5b7f7d92c",
      "03d8a040dd3940a7acf0f56b0ba268ce",
      "3499a5f52a5e4255a9665e7d04801e5a",
      "43ad62528cf1438a9d9c1e585e4ca4ab",
      "873b9b5892a44d1389bdd7ebf218c3ea",
      "9732f147c6a64e48920aa4e348c264f5"
     ]
    },
    "id": "gq_VdhJMIU-b",
    "outputId": "7bb00b60-ea89-4bd4-bccb-b6842d576373"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0c25b4d7b04c2d8191d4124c367a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=480.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e682ab03e84ddd80fbdb1f684049e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=331070498.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868a0285280a44faa3aee4e65b44ae56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc4bcdcc68f408fa880d56513469d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172d9e49e6a643f3be2900a4ff3907bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#load the model from checkpoint and the tokenizer\n",
    "_, tokenizer = get_monoBERT_and_tokenizer()\n",
    "model = load_monoBERT('./gdrive/MyDrive/Information_Retrieval_Project/monoBERT/monoBERT_lr_0.0001_DROPOUT_Adam_epoch_3.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgDE8vuRIz_k",
    "outputId": "34b0bbca-9ddc-4f09-8f4c-d91dc4f7ef83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qw_318']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#predict \n",
    "print(test_df.sample()['question'].values)\n",
    "#interesting: qz_1854\n",
    "output = predict_single_query(test_df, str(test_df.sample()['question'].values[0]), question_dict, id_title_dict, text_dict, model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JStogfu4JCSH"
   },
   "outputs": [],
   "source": [
    "#output for the whole test set\n",
    "result_df_list = predict_multiple_queries(test_df, test['question'].values, question_dict, id_title_dict, text_dict, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "TwbnUt3cc04C"
   },
   "outputs": [],
   "source": [
    "#create a sample for testing to reduce computation time\n",
    "test_df_sample = test_df[7500:8500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hAwS9m0SU96z",
    "outputId": "6d04132f-75c4-4913-d01b-1ed20008296e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>54626</td>\n",
       "      <td>38.652683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>10401</td>\n",
       "      <td>34.972892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>17688</td>\n",
       "      <td>31.368855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>15327</td>\n",
       "      <td>30.926645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>51834</td>\n",
       "      <td>30.469387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>3477</td>\n",
       "      <td>29.725855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>23251</td>\n",
       "      <td>29.566124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>71215</td>\n",
       "      <td>29.386205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>57302</td>\n",
       "      <td>29.314381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>55929</td>\n",
       "      <td>29.289317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>31025</td>\n",
       "      <td>29.196324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>10068</td>\n",
       "      <td>29.147147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>6113</td>\n",
       "      <td>29.114461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>141</td>\n",
       "      <td>28.773901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>10603</td>\n",
       "      <td>28.688124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>6964</td>\n",
       "      <td>28.134132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>10304</td>\n",
       "      <td>27.991534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>73791</td>\n",
       "      <td>27.892926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>9019</td>\n",
       "      <td>27.751978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>35175</td>\n",
       "      <td>27.734984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>44538</td>\n",
       "      <td>27.430439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>10807</td>\n",
       "      <td>27.030834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>66404</td>\n",
       "      <td>26.850076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>62591</td>\n",
       "      <td>26.718976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>10511</td>\n",
       "      <td>26.475300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>10289</td>\n",
       "      <td>26.256248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>7032</td>\n",
       "      <td>26.250520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>22477</td>\n",
       "      <td>26.088515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>35205</td>\n",
       "      <td>26.065209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>67796</td>\n",
       "      <td>25.928803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>49157</td>\n",
       "      <td>25.849457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>39801</td>\n",
       "      <td>25.748576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>18075</td>\n",
       "      <td>25.641064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>1858</td>\n",
       "      <td>25.614519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>50582</td>\n",
       "      <td>25.559850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>22978</td>\n",
       "      <td>25.473036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>1079</td>\n",
       "      <td>25.385938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>6777</td>\n",
       "      <td>25.376417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>50579</td>\n",
       "      <td>25.300858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>25643</td>\n",
       "      <td>25.156291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>17462</td>\n",
       "      <td>25.040961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>60491</td>\n",
       "      <td>25.023268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>19377</td>\n",
       "      <td>25.002841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>28322</td>\n",
       "      <td>24.954396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>40065</td>\n",
       "      <td>24.926036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>41341</td>\n",
       "      <td>24.805762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>71970</td>\n",
       "      <td>24.800968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>20264</td>\n",
       "      <td>24.603359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>40895</td>\n",
       "      <td>24.516298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bb_1772</td>\n",
       "      <td>68995</td>\n",
       "      <td>24.397430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question    doc      score  label\n",
       "0   bb_1772  54626  38.652683      0\n",
       "1   bb_1772  10401  34.972892      0\n",
       "2   bb_1772  17688  31.368855      0\n",
       "3   bb_1772  15327  30.926645      0\n",
       "4   bb_1772  51834  30.469387      0\n",
       "5   bb_1772   3477  29.725855      0\n",
       "6   bb_1772  23251  29.566124      0\n",
       "7   bb_1772  71215  29.386205      0\n",
       "8   bb_1772  57302  29.314381      0\n",
       "9   bb_1772  55929  29.289317      0\n",
       "10  bb_1772  31025  29.196324      0\n",
       "11  bb_1772  10068  29.147147      0\n",
       "12  bb_1772   6113  29.114461      0\n",
       "13  bb_1772    141  28.773901      0\n",
       "14  bb_1772  10603  28.688124      1\n",
       "15  bb_1772   6964  28.134132      0\n",
       "16  bb_1772  10304  27.991534      0\n",
       "17  bb_1772  73791  27.892926      0\n",
       "18  bb_1772   9019  27.751978      0\n",
       "19  bb_1772  35175  27.734984      0\n",
       "20  bb_1772  44538  27.430439      0\n",
       "21  bb_1772  10807  27.030834      0\n",
       "22  bb_1772  66404  26.850076      0\n",
       "23  bb_1772  62591  26.718976      0\n",
       "24  bb_1772  10511  26.475300      0\n",
       "25  bb_1772  10289  26.256248      0\n",
       "26  bb_1772   7032  26.250520      0\n",
       "27  bb_1772  22477  26.088515      0\n",
       "28  bb_1772  35205  26.065209      0\n",
       "29  bb_1772  67796  25.928803      0\n",
       "30  bb_1772  49157  25.849457      0\n",
       "31  bb_1772  39801  25.748576      0\n",
       "32  bb_1772  18075  25.641064      0\n",
       "33  bb_1772   1858  25.614519      0\n",
       "34  bb_1772  50582  25.559850      0\n",
       "35  bb_1772  22978  25.473036      0\n",
       "36  bb_1772   1079  25.385938      0\n",
       "37  bb_1772   6777  25.376417      0\n",
       "38  bb_1772  50579  25.300858      0\n",
       "39  bb_1772  25643  25.156291      0\n",
       "40  bb_1772  17462  25.040961      0\n",
       "41  bb_1772  60491  25.023268      0\n",
       "42  bb_1772  19377  25.002841      0\n",
       "43  bb_1772  28322  24.954396      0\n",
       "44  bb_1772  40065  24.926036      0\n",
       "45  bb_1772  41341  24.805762      0\n",
       "46  bb_1772  71970  24.800968      0\n",
       "47  bb_1772  20264  24.603359      0\n",
       "48  bb_1772  40895  24.516298      0\n",
       "49  bb_1772  68995  24.397430      0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_df[7350:7400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "KVsDRB23ZBEd",
    "outputId": "ac16f19b-8d6c-4c45-8c81-1b4d53497ad2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b3742a64769e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#predict for the chosen sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_multiple_queries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_title_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-4a2b7ec9af57>\u001b[0m in \u001b[0;36mpredict_multiple_queries\u001b[0;34m(test_df, question_id_list, question_dict, id_title_dict, text_dict, model, tokenizer)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mresult_df_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_id_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mresult_df_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_single_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_title_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4a2b7ec9af57>\u001b[0m in \u001b[0;36mpredict_single_query\u001b[0;34m(test_df, question_id, question_dict, id_title_dict, text_dict, model, tokenizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-04203c798c47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m     outputs = self.bert(\n\u001b[1;32m     23\u001b[0m                \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                attention_mask=mask)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m                 )\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         )\n\u001b[1;32m    438\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#predict for the chosen sample\n",
    "all_results = predict_multiple_queries(test_df, test_df_sample.drop_duplicates('question')['question'], question_dict, id_title_dict, text_dict, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KUH4av5SZBJe"
   },
   "outputs": [],
   "source": [
    "#convert the result dataframe to a list to evaluate it later on\n",
    "test_sample_list = list()\n",
    "for question, df_question in test_df_sample.groupby('question'):\n",
    "  df_question.reset_index(inplace=True)\n",
    "  del df_question['index']\n",
    "  test_sample_list.append(df_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aBKyWSDfkch",
    "outputId": "300acb56-1cfa-4ebb-ef23-34c7f6eb0cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - monoBERT:  0.7\n",
      " - monoBERT:  0.7\n",
      " - monoBERT:  0.5\n",
      " - monoBERT:  0.75\n",
      " - monoBERT:  0.4\n",
      " - monoBERT:  0.7333333333333333\n",
      " - monoBERT:  0.3375\n",
      " - monoBERT:  0.7194444444444444\n",
      " - monoBERT:  0.29000000000000004\n",
      " - monoBERT:  0.7144444444444444\n",
      " - monoBERT:  0.24166666666666664\n",
      " - monoBERT:  0.7144444444444444\n",
      " - monoBERT:  0.20714285714285707\n",
      " - monoBERT:  0.7144444444444444\n",
      " - monoBERT:  0.4916666666666666\n",
      " - monoBERT:  0.6916666666666667\n"
     ]
    }
   ],
   "source": [
    "#prediction quality for monoBERT\n",
    "\n",
    "for i in range(1, 8):\n",
    "  #MPK_bm = meanPrecisions(test_sample_list, prep_question_test, k=i, PType='P@K')\n",
    "  MPK_monoBERT = meanPrecisions(all_results, prep_question_test, k=i, PType='P@K')\n",
    "  print(\" - monoBERT: \", MPK_monoBERT)\n",
    "  #MAPK_bm = meanPrecisions(test_sample_list, prep_question_test, k=i, PType='AP@K')\n",
    "  MAPK_monoBERT = meanPrecisions(all_results, prep_question_test, k=i, PType='AP@K')\n",
    "  print(\" - monoBERT: \", MAPK_monoBERT)\n",
    "#MRPrecision_bm = meanPrecisions(test_sample_list, prep_question_test, k=5, PType='R-Precision')\n",
    "MRPrecision_monoBERT = meanPrecisions(all_results, prep_question_test, k=5, PType='R-Precision')\n",
    "print(\" - monoBERT: \", MRPrecision_monoBERT)\n",
    "#MARPrecision_bm = meanPrecisions(test_sample_list, prep_question_test, k=5, PType='AR-Precision')\n",
    "MARPrecision_monoBERT = meanPrecisions(all_results, prep_question_test, k=5, PType='AR-Precision')\n",
    "print(\" - monoBERT: \", MARPrecision_monoBERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvLBlsf4mVSz"
   },
   "source": [
    "# duoBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR9XThCBmbXV"
   },
   "source": [
    "## Dataset/Loader and Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "P-RQ_rK3mXtq"
   },
   "outputs": [],
   "source": [
    "# duoBERT and linear model\n",
    "# Our duoBERT model with linear layers defined.\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        #torch.nn.init.zero_(m.bias)\n",
    "\n",
    "class duoBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(duoBERT, self).__init__()\n",
    "      self.bert = RobertaModel.from_pretrained('distilroberta-base')\n",
    "      self.decision = nn.Sequential(\n",
    "            nn.Linear(768, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "      weights_init(self.decision)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "      outputs = self.bert(ids, attention_mask=mask)\n",
    "\n",
    "      sequence_output = outputs.last_hidden_state\n",
    "      \n",
    "      decision_output = self.decision(sequence_output[:,0,:].view(-1,768)) ## extract the 1st token's embeddings\n",
    "      return decision_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vK0NlxG9mhO1"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Dataset for duoBERT is prepared\n",
    "class duoBERT_dataset(Dataset):\n",
    "  def __init__(self):\n",
    "    #path = \"./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/duoBERT_train.csv\"\n",
    "    #self.dataset = pd.read_csv(path, sep='\\t')\n",
    "    #self.dataset.reset_index(inplace=True)\n",
    "    self.dataset = duo_train_df\n",
    "  def __len__(self): \n",
    "    return len(self.dataset)\n",
    "  \n",
    "  def __getitem__(self, itemID):\n",
    "    row = self.dataset.iloc[itemID]\n",
    "\n",
    "    question = row['full_question']\n",
    "    doc_x = row['full_doc_x']\n",
    "    doc_y = row['full_doc_y']\n",
    "\n",
    "    # Encoding the question\n",
    "    question_encoding = tokenizer(question)\n",
    "    question_inputids = question_encoding['input_ids']\n",
    "    question_attentionmask = question_encoding['attention_mask']\n",
    "\n",
    "\n",
    "    # Encoding the documents\n",
    "    num_tokens_for_docx = math.floor((512-len(question_inputids))/2)+1\n",
    "    num_tokens_for_docy = 512-len(question_inputids)-num_tokens_for_docx+2\n",
    "\n",
    "    doc_x_encoding = tokenizer(doc_x, truncation=True, padding='max_length', max_length = num_tokens_for_docx)\n",
    "    doc_x_inputids = doc_x_encoding['input_ids'][1:]\n",
    "    doc_x_attentionmask = doc_x_encoding['attention_mask'][1:]\n",
    "    doc_y_encoding = tokenizer(doc_y, truncation=True, padding='max_length', max_length = num_tokens_for_docy)\n",
    "    doc_y_inputids = doc_y_encoding['input_ids'][1:]\n",
    "    doc_y_attentionmask = doc_y_encoding['attention_mask'][1:]\n",
    "    \n",
    "    # We return the input ids for the whole input of 512 length\n",
    "    all_ids = torch.LongTensor(question_inputids + doc_x_inputids + doc_y_inputids)\n",
    "    all_attentionmask = torch.LongTensor(question_attentionmask + doc_x_attentionmask + doc_y_attentionmask)\n",
    "\n",
    "\n",
    "    return all_ids, all_attentionmask, int(row['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "c565VmJTmj8S"
   },
   "outputs": [],
   "source": [
    "# Dataloader is prepared to iterate over batches \n",
    "# Get a dataloader for duoBERT\n",
    "def get_dataloader_duoBERT():\n",
    "  duoBERT_data = duoBERT_dataset()\n",
    "  dataloader = DataLoader(dataset=duoBERT_data, batch_size=32, shuffle=True, num_workers=3)\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "rJJG3ghEmlOR"
   },
   "outputs": [],
   "source": [
    "# Get a duoBERT model and tokenizer\n",
    "def get_duoBERT_and_tokenizer():\n",
    "  return duoBERT(), AutoTokenizer.from_pretrained('distilroberta-base', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4ShMk1almmj2"
   },
   "outputs": [],
   "source": [
    "# Tokenizer for monoBERT\n",
    "def tokenize_duoBERT(question, doc_x, doc_y, tokenizer):\n",
    "# creates: [CLS] question [SEP] Doc_x [SEP] Doc_y [SEP], max 512 tokens\n",
    "  \n",
    "  # Encoding the question\n",
    "  question_encoding = tokenizer(question)\n",
    "  question_inputids = question_encoding['input_ids']\n",
    "  question_attentionmask = question_encoding['attention_mask']\n",
    "  \n",
    "  # Encoding the documents\n",
    "  num_tokens_for_docx = math.floor((512-len(question_inputids))/2)+1\n",
    "  num_tokens_for_docy = 512-len(question_inputids)-num_tokens_for_docx+2\n",
    "\n",
    "  doc_x_encoding = tokenizer(doc_x, truncation=True, padding='max_length', max_length = num_tokens_for_docx)\n",
    "  doc_x_inputids = doc_x_encoding['input_ids'][1:]\n",
    "  doc_x_attentionmask = doc_x_encoding['attention_mask'][1:]\n",
    "  doc_y_encoding = tokenizer(doc_y, truncation=True, padding='max_length', max_length = num_tokens_for_docy)\n",
    "  doc_y_inputids = doc_y_encoding['input_ids'][1:]\n",
    "  doc_y_attentionmask = doc_y_encoding['attention_mask'][1:]\n",
    "  \n",
    "  # We return the input ids for the whole input of 512 length\n",
    "  all_ids = torch.LongTensor([question_inputids + doc_x_inputids + doc_y_inputids])\n",
    "  all_attentionmask = torch.LongTensor([question_attentionmask + doc_x_attentionmask + doc_y_attentionmask])\n",
    "  all_ids\n",
    "  all_attentionmask\n",
    "  return all_ids, all_attentionmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "L3YkfvqRqLV1"
   },
   "outputs": [],
   "source": [
    "def load_duoBERT(path):\n",
    "  model = duoBERT()\n",
    "  model.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "  model.eval()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "lKG2Llw6sSqb",
    "outputId": "c8c0d945-ddfe-432f-9093-2008108b12b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'class duoBERT_cnn(nn.Module):\\n    def __init__(self):\\n      super(duoBERT_cnn, self).__init__()\\n      self.bert = RobertaModel.from_pretrained(\\'distilroberta-base\\')\\n      self.convolution1 = nn.Conv2d(6,3,(768,1),padding=True)\\n      self.convolution2 = nn.Conv2d(6,3,(768,2),padding=True)\\n      self.convolution3 = nn.Conv2d(6,3,(768,3), padding=True)\\n      self.convolution4 = nn.Conv2d(6,3,(768,4), padding=True)\\n      self.convolution5 = nn.Conv2d(6,3,(768,5),padding=True)\\n      self.maxPool = nn.MaxPool2d(kernel_size=3)\\n      self.silu = nn.SiLU()\\n      self.linear = nn.Linear(2556, 256)\\n      self.dropout = nn.Dropout(0.2)\\n      self.final = nn.Linear(256,1)\\n      #self.sigmoid = nn.Sigmoid()\\n      \\n      weights_init(self.convolution1)\\n      weights_init(self.convolution2)\\n      weights_init(self.convolution3)\\n      weights_init(self.convolution4)\\n      weights_init(self.convolution5)\\n      weights_init(self.linear)\\n      weights_init(self.final)\\n\\n    def forward(self, ids, mask):\\n      outputs = self.bert(ids, attention_mask=mask, output_hidden_states = True)\\n\\n      #print(len(outputs))  # 3\\n\\n      hidden_states = outputs[2]\\n      #print(type(hidden_states))\\n      #print(len(hidden_states))  # 13\\n\\n      emb_out = hidden_states[0]\\n      att_layers = hidden_states[1:]\\n      a = torch.stack([att_layers[1],att_layers[2],att_layers[3],att_layers[4], att_layers[5], emb_out])\\n\\n      x = a.view(-1,6,768,512)\\n      #print(\"1:\",x.shape)\\n      x1 = self.maxPool(self.silu(self.convolution1(x)))\\n      x2 = self.maxPool(self.silu(self.convolution2(x)))\\n      x3 = self.maxPool(self.silu(self.convolution3(x)))\\n      x4 = self.maxPool(self.silu(self.convolution4(x)))\\n      x5 = self.maxPool(self.silu(self.convolution5(x)))\\n     \\n      x1 = x1.view(-1, 513)\\n      x2 = x2.view(-1, 513)\\n      x3 = x3.view(-1, 510)\\n      x4 = x5.view(-1, 510)\\n      x5 = x5.view(-1, 510)\\n\\n      x = torch.cat([x1,x2,x3,x4,x5],dim=1)\\n\\n      x = self.silu(self.dropout((self.linear(x))))\\n      x = self.final(x)\\n      return x'"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doubert cnn based on the paper of Safaya et al. 2020 (self-implemented)\n",
    "#link: https://www.aclweb.org/anthology/2020.semeval-1.271.pdf\n",
    "#did not converge and needs a lot of training time \n",
    "\n",
    "'''class duoBERT_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(duoBERT_cnn, self).__init__()\n",
    "      self.bert = RobertaModel.from_pretrained('distilroberta-base')\n",
    "      self.convolution1 = nn.Conv2d(6,3,(768,1),padding=True)\n",
    "      self.convolution2 = nn.Conv2d(6,3,(768,2),padding=True)\n",
    "      self.convolution3 = nn.Conv2d(6,3,(768,3), padding=True)\n",
    "      self.convolution4 = nn.Conv2d(6,3,(768,4), padding=True)\n",
    "      self.convolution5 = nn.Conv2d(6,3,(768,5),padding=True)\n",
    "      self.maxPool = nn.MaxPool2d(kernel_size=3)\n",
    "      self.silu = nn.SiLU()\n",
    "      self.linear = nn.Linear(2556, 256)\n",
    "      self.dropout = nn.Dropout(0.2)\n",
    "      self.final = nn.Linear(256,1)\n",
    "      #self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "      weights_init(self.convolution1)\n",
    "      weights_init(self.convolution2)\n",
    "      weights_init(self.convolution3)\n",
    "      weights_init(self.convolution4)\n",
    "      weights_init(self.convolution5)\n",
    "      weights_init(self.linear)\n",
    "      weights_init(self.final)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "      outputs = self.bert(ids, attention_mask=mask, output_hidden_states = True)\n",
    "\n",
    "      #print(len(outputs))  # 3\n",
    "\n",
    "      hidden_states = outputs[2]\n",
    "      #print(type(hidden_states))\n",
    "      #print(len(hidden_states))  # 13\n",
    "\n",
    "      emb_out = hidden_states[0]\n",
    "      att_layers = hidden_states[1:]\n",
    "      a = torch.stack([att_layers[1],att_layers[2],att_layers[3],att_layers[4], att_layers[5], emb_out])\n",
    "\n",
    "      x = a.view(-1,6,768,512)\n",
    "      #print(\"1:\",x.shape)\n",
    "      x1 = self.maxPool(self.silu(self.convolution1(x)))\n",
    "      x2 = self.maxPool(self.silu(self.convolution2(x)))\n",
    "      x3 = self.maxPool(self.silu(self.convolution3(x)))\n",
    "      x4 = self.maxPool(self.silu(self.convolution4(x)))\n",
    "      x5 = self.maxPool(self.silu(self.convolution5(x)))\n",
    "     \n",
    "      x1 = x1.view(-1, 513)\n",
    "      x2 = x2.view(-1, 513)\n",
    "      x3 = x3.view(-1, 510)\n",
    "      x4 = x5.view(-1, 510)\n",
    "      x5 = x5.view(-1, 510)\n",
    "\n",
    "      x = torch.cat([x1,x2,x3,x4,x5],dim=1)\n",
    "\n",
    "      x = self.silu(self.dropout((self.linear(x))))\n",
    "      x = self.final(x)\n",
    "      return x'''\n",
    "#not used, as it did not converge properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F600kJxSmnk4"
   },
   "source": [
    "## Training preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1wMYHuJmqeb"
   },
   "outputs": [],
   "source": [
    "#load the training data\n",
    "csv_path = \"./gdrive/MyDrive/Information_Retrieval_Project/monoBERT/monoBERT_train.csv\"\n",
    "df = pd.read_csv(csv_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "KXaOXSW2pGeM",
    "outputId": "61a27da3-07a7-479c-8db2-2bf459ffb6b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bb_10</td>\n",
       "      <td>27062</td>\n",
       "      <td>0</td>\n",
       "      <td>In the US TV comedy show Everybody Loves Raymo...</td>\n",
       "      <td>Becker is an American sitcom that ran from 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bb_10</td>\n",
       "      <td>72724</td>\n",
       "      <td>1</td>\n",
       "      <td>In the US TV comedy show Everybody Loves Raymo...</td>\n",
       "      <td>Everybody Loves Raymond is an American televis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bb_1000</td>\n",
       "      <td>71300</td>\n",
       "      <td>0</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "      <td>The Railway Children is a children's book by E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bb_1000</td>\n",
       "      <td>5640</td>\n",
       "      <td>0</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "      <td>John Barrymore (born John Sidney Blyth; Februa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bb_1000</td>\n",
       "      <td>72730</td>\n",
       "      <td>1</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "      <td>Edith Nesbit (married name Edith Bland; 15 Aug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>bb_1000</td>\n",
       "      <td>11920</td>\n",
       "      <td>1</td>\n",
       "      <td>An adaptation of which classic 1905 story by E...</td>\n",
       "      <td>London Waterloo station  ( ) is a central Lond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>bb_1011</td>\n",
       "      <td>37131</td>\n",
       "      <td>0</td>\n",
       "      <td>Patricia Neal, winner of best actress Oscar fo...</td>\n",
       "      <td>Hud is a 1963 Western film directed by Martin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>bb_1011</td>\n",
       "      <td>62787</td>\n",
       "      <td>1</td>\n",
       "      <td>Patricia Neal, winner of best actress Oscar fo...</td>\n",
       "      <td>Patricia Neal (January 20, 1926 – August 8, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>bb_1014</td>\n",
       "      <td>11682</td>\n",
       "      <td>0</td>\n",
       "      <td>Welsh rugby union flanker Andy Powell was bann...</td>\n",
       "      <td>Newport (; ) is a cathedral and university cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>bb_1014</td>\n",
       "      <td>16945</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh rugby union flanker Andy Powell was bann...</td>\n",
       "      <td>Andrew \"Andy\" Powell (born 23 August 1981) is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                           full_doc\n",
       "0           0  ...  Becker is an American sitcom that ran from 199...\n",
       "1           1  ...  Everybody Loves Raymond is an American televis...\n",
       "2           2  ...  The Railway Children is a children's book by E...\n",
       "3           3  ...  John Barrymore (born John Sidney Blyth; Februa...\n",
       "4           4  ...  Edith Nesbit (married name Edith Bland; 15 Aug...\n",
       "5           5  ...  London Waterloo station  ( ) is a central Lond...\n",
       "6           6  ...  Hud is a 1963 Western film directed by Martin ...\n",
       "7           7  ...  Patricia Neal (January 20, 1926 – August 8, 20...\n",
       "8           8  ...  Newport (; ) is a cathedral and university cit...\n",
       "9           9  ...  Andrew \"Andy\" Powell (born 23 August 1981) is ...\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZSXnm0kpIOC"
   },
   "outputs": [],
   "source": [
    "#filter for relevant and irrelevant documents\n",
    "important_match = df[df[\"label\"]==1]\n",
    "unimportant_match = df[df[\"label\"]==0]\n",
    "del important_match['Unnamed: 0']\n",
    "del unimportant_match['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ftgl8DqpJfD"
   },
   "outputs": [],
   "source": [
    "display(important_match.head())\n",
    "display(unimportant_match.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYszBQ39pLEZ"
   },
   "outputs": [],
   "source": [
    "#merge both dataframes\n",
    "populated_df = important_match.merge(unimportant_match[[\"full_question\",\"doc\",\"full_doc\"]],left_index=True,how='left', on=['full_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxCVDBbypMo0"
   },
   "outputs": [],
   "source": [
    "populated_df.reset_index(inplace=True)\n",
    "populated_df = populated_df.rename(columns={'question': 'question_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1yvUs6cpN7z"
   },
   "outputs": [],
   "source": [
    "display(populated_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3jHyyVapRgH"
   },
   "outputs": [],
   "source": [
    "#reverse the dataframe to create the opposite tuple with the opposite label\n",
    "populated_reverse = pd.DataFrame(list(zip(list(populated_df['question_ID']), list(populated_df['doc_y']), [0]*len(populated_df), list(populated_df['full_question']), list(populated_df['full_doc_y']), list(populated_df['doc_x']), list(populated_df['full_doc_x']))),\n",
    "               columns =['question_ID', 'doc_x', 'label', 'full_question', 'full_doc_x', 'doc_y', 'full_doc_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTCF2j-3pdJf"
   },
   "outputs": [],
   "source": [
    "duo_train_df = pd.concat([populated_df, populated_reverse])\n",
    "#del duo_train_df['level_0']\n",
    "del duo_train_df['index']\n",
    "duo_train_df.reset_index(inplace=True)\n",
    "del duo_train_df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLOkeQnps_69"
   },
   "outputs": [],
   "source": [
    "display(populated_df.head(10))\n",
    "display(populated_reverse.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psiN3e1YpeZn"
   },
   "outputs": [],
   "source": [
    "display(duo_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8nD2LWzpgk2"
   },
   "outputs": [],
   "source": [
    "duo_train_df = duo_train_df[[\"question_ID\",\"full_question\",\"doc_x\",\"full_doc_x\",\"doc_y\",\"full_doc_y\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuIMprZssygd"
   },
   "outputs": [],
   "source": [
    "display(duo_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6xAJh_tph3r"
   },
   "outputs": [],
   "source": [
    "duo_train_df.to_csv('./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/duoBERT_train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cQi-bpCpj6k"
   },
   "source": [
    "## Model initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d5tACdipmC2"
   },
   "outputs": [],
   "source": [
    "# Get a dataloader\n",
    "loader = get_dataloader_duoBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzFMl57ppp9M"
   },
   "outputs": [],
   "source": [
    "# Criterion and Optimizer are defined for training\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vw3ND2ojwHiz",
    "outputId": "4cf8ba9e-889f-4bc9-9645-3b646e35600e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "_, tokenizer = get_duoBERT_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3sPlGxctnRa"
   },
   "outputs": [],
   "source": [
    "model = duoBERT()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HPofkBnbprRT",
    "outputId": "01a74beb-b228-4ef3-abca-238d7ae40cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
      "tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2101, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3639645278453827\n",
      "2530\n",
      "tensor([0.9895, 0.4383, 0.0074, 0.3619, 0.9908, 0.9945, 0.9919, 0.9933, 0.9813,\n",
      "        0.7000, 0.1055, 0.9774, 0.9935, 0.9911, 0.4464, 0.0107, 0.0429, 0.5564,\n",
      "        0.0292, 0.9955, 0.0133, 0.0100, 0.9866, 0.0134, 0.9163, 0.1343, 0.1184,\n",
      "        0.9857, 0.0163, 0.4138, 0.9894, 0.4018], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2084, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3620312213897705\n",
      "2560\n",
      "tensor([0.9274, 0.7946, 0.9927, 0.6809, 0.1927, 0.0165, 0.5826, 0.9939, 0.0077,\n",
      "        0.9879, 0.0348, 0.3610, 0.6738, 0.9899, 0.8996, 0.0455, 0.9945, 0.9901,\n",
      "        0.9898, 0.4322, 0.9930, 0.0074, 0.0104, 0.7413, 0.9399, 0.9919, 0.9858,\n",
      "        0.0203, 0.8608, 0.9768, 0.8143, 0.0416], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3606582581996918\n",
      "2590\n",
      "tensor([0.3608, 0.9890, 0.9953, 0.0127, 0.0060, 0.9922, 0.0244, 0.9719, 0.9931,\n",
      "        0.9844, 0.9850, 0.9898, 0.0054, 0.4526, 0.0087, 0.8563, 0.9924, 0.0703,\n",
      "        0.1450, 0.0270, 0.9916, 0.9935, 0.0225, 0.9444, 0.2228, 0.9525, 0.7801,\n",
      "        0.9854, 0.8985, 0.9863, 0.6040, 0.9915], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.359298437833786\n",
      "2620\n",
      "tensor([0.9727, 0.0763, 0.8270, 0.9907, 0.1373, 0.0185, 0.5561, 0.9862, 0.9892,\n",
      "        0.9748, 0.0177, 0.0286, 0.9487, 0.0111, 0.3720, 0.8800, 0.0397, 0.0616,\n",
      "        0.0551, 0.0145, 0.6679, 0.9677, 0.8989, 0.8857, 0.0365, 0.2245, 0.9921,\n",
      "        0.1127, 0.6345, 0.9672, 0.9846, 0.6908], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1304, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3583815395832062\n",
      "2650\n",
      "tensor([0.9948, 0.0285, 0.9963, 0.0123, 0.9955, 0.9838, 0.0235, 0.0130, 0.0668,\n",
      "        0.9855, 0.3553, 0.0285, 0.9926, 0.9944, 0.0103, 0.9957, 0.9927, 0.1300,\n",
      "        0.9932, 0.9606, 0.0115, 0.9242, 0.0922, 0.9684, 0.0149, 0.9728, 0.7408,\n",
      "        0.0128, 0.0126, 0.0351, 0.0131, 0.0818], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1282, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.35687074065208435\n",
      "2680\n",
      "tensor([0.7888, 0.4267, 0.6363, 0.9331, 0.1649, 0.0332, 0.1165, 0.6866, 0.0141,\n",
      "        0.8588, 0.9948, 0.0533, 0.9674, 0.9951, 0.2303, 0.0215, 0.9826, 0.0223,\n",
      "        0.9901, 0.6841, 0.9911, 0.9563, 0.9941, 0.0141, 0.6949, 0.0047, 0.0834,\n",
      "        0.9573, 0.1161, 0.7964, 0.0374, 0.0683], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2350, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.35535234212875366\n",
      "2710\n",
      "tensor([0.9207, 0.3569, 0.0063, 0.9463, 0.9369, 0.2672, 0.9905, 0.0146, 0.9648,\n",
      "        0.9826, 0.9892, 0.9688, 0.9025, 0.7113, 0.5493, 0.7380, 0.0096, 0.5940,\n",
      "        0.0440, 0.6173, 0.0525, 0.9881, 0.8850, 0.9681, 0.9884, 0.3005, 0.0116,\n",
      "        0.9804, 0.9816, 0.9330, 0.9017, 0.0275], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3542167842388153\n",
      "2740\n",
      "tensor([0.0063, 0.0838, 0.0072, 0.0255, 0.0227, 0.9942, 0.5709, 0.9878, 0.9804,\n",
      "        0.2847, 0.9240, 0.0144, 0.0113, 0.9329, 0.9888, 0.6695, 0.3743, 0.9934,\n",
      "        0.9297, 0.0042, 0.9707, 0.0197, 0.9721, 0.9903, 0.0077, 0.8552, 0.0353,\n",
      "        0.9834, 0.9840, 0.8263, 0.4831, 0.1554], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1664, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.35297733545303345\n",
      "2770\n",
      "tensor([0.0128, 0.0497, 0.0308, 0.2981, 0.0176, 0.4537, 0.8346, 0.9446, 0.9800,\n",
      "        0.9704, 0.1423, 0.4304, 0.0800, 0.0230, 0.0805, 0.4711, 0.8475, 0.9202,\n",
      "        0.0305, 0.2274, 0.2713, 0.0187, 0.9840, 0.0759, 0.0786, 0.9630, 0.7967,\n",
      "        0.6948, 0.0158, 0.9075, 0.3545, 0.9590], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3353, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3521004319190979\n",
      "2800\n",
      "tensor([0.0526, 0.0159, 0.0241, 0.0267, 0.6781, 0.1720, 0.0142, 0.0405, 0.0097,\n",
      "        0.0463, 0.9724, 0.8900, 0.0292, 0.0385, 0.3854, 0.2238, 0.0098, 0.7688,\n",
      "        0.0553, 0.9590, 0.9678, 0.1667, 0.9817, 0.0276, 0.0893, 0.3746, 0.0935,\n",
      "        0.0039, 0.0104, 0.1196, 0.8898, 0.9807], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3226, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.35133326053619385\n",
      "2830\n",
      "tensor([0.9729, 0.0164, 0.0107, 0.0149, 0.9790, 0.0066, 0.0156, 0.0143, 0.0728,\n",
      "        0.9934, 0.8064, 0.9920, 0.3585, 0.6674, 0.0044, 0.9783, 0.2510, 0.3519,\n",
      "        0.0186, 0.0038, 0.9809, 0.9922, 0.1437, 0.9916, 0.9942, 0.1984, 0.0212,\n",
      "        0.9850, 0.0872, 0.0291, 0.2748, 0.6814], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3499871790409088\n",
      "2860\n",
      "tensor([0.0415, 0.9817, 0.9963, 0.8326, 0.2192, 0.9764, 0.0415, 0.4631, 0.0493,\n",
      "        0.0116, 0.0113, 0.2077, 0.9571, 0.0729, 0.9846, 0.0977, 0.9836, 0.0066,\n",
      "        0.7605, 0.8676, 0.9926, 0.9959, 0.9837, 0.0457, 0.0101, 0.5612, 0.9953,\n",
      "        0.8999, 0.5445, 0.0382, 0.7915, 0.9898], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.34865784645080566\n",
      "2890\n",
      "tensor([0.9910, 0.0974, 0.3363, 0.7725, 0.0083, 0.9898, 0.0128, 0.1087, 0.5206,\n",
      "        0.0802, 0.6802, 0.9946, 0.0684, 0.2232, 0.0117, 0.0301, 0.2146, 0.9008,\n",
      "        0.0086, 0.1908, 0.1888, 0.0215, 0.2205, 0.1509, 0.8951, 0.9867, 0.9960,\n",
      "        0.9800, 0.0086, 0.9879, 0.1141, 0.9879], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2688, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.34744584560394287\n",
      "2920\n",
      "tensor([0.9785, 0.4181, 0.9855, 0.0084, 0.0084, 0.0125, 0.7198, 0.2404, 0.0349,\n",
      "        0.1705, 0.8800, 0.9875, 0.9850, 0.5876, 0.0137, 0.0120, 0.0122, 0.3795,\n",
      "        0.8616, 0.9898, 0.9926, 0.0040, 0.0068, 0.5223, 0.0141, 0.8246, 0.0407,\n",
      "        0.0273, 0.9959, 0.3544, 0.7787, 0.5724], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1678, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.34619009494781494\n",
      "2950\n",
      "tensor([0.9933, 0.0197, 0.9578, 0.2040, 0.0338, 0.0082, 0.3078, 0.9877, 0.4479,\n",
      "        0.0204, 0.0599, 0.9955, 0.9966, 0.9867, 0.9935, 0.0045, 0.1425, 0.9911,\n",
      "        0.0076, 0.3604, 0.3911, 0.9151, 0.1097, 0.0140, 0.0140, 0.0300, 0.9921,\n",
      "        0.9716, 0.7437, 0.0285, 0.8862, 0.6486], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.34504762291908264\n",
      "2980\n",
      "tensor([0.5869, 0.9912, 0.9853, 0.9946, 0.9844, 0.0050, 0.9045, 0.3671, 0.9910,\n",
      "        0.9894, 0.0544, 0.6952, 0.9947, 0.9878, 0.9906, 0.2001, 0.0113, 0.0056,\n",
      "        0.0901, 0.1445, 0.5784, 0.9852, 0.0097, 0.0063, 0.0701, 0.4093, 0.0088,\n",
      "        0.9515, 0.9434, 0.0050, 0.0081, 0.8916], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1999, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.34385302662849426\n",
      "3010\n",
      "tensor([0.9773, 0.0063, 0.1760, 0.5174, 0.0058, 0.9491, 0.0430, 0.0067, 0.9717,\n",
      "        0.3749, 0.0318, 0.9851, 0.0148, 0.8654, 0.0057, 0.0421, 0.9566, 0.2027,\n",
      "        0.9459, 0.0199, 0.1385, 0.0281, 0.0088, 0.4041, 0.8604, 0.1002, 0.9886,\n",
      "        0.3300, 0.0564, 0.8040, 0.7265, 0.1192], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1429, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3430486023426056\n",
      "3040\n",
      "tensor([0.0119, 0.7973, 0.9818, 0.5684, 0.0271, 0.0283, 0.7684, 0.1234, 0.7949,\n",
      "        0.9730, 0.9963, 0.0036, 0.0056, 0.8222, 0.2629, 0.0097, 0.6990, 0.0076,\n",
      "        0.0071, 0.9816, 0.0130, 0.0164, 0.6172, 0.0063, 0.0035, 0.9889, 0.0065,\n",
      "        0.9831, 0.9589, 0.6570, 0.9934, 0.9882], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2079, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3419724106788635\n",
      "3070\n",
      "tensor([0.8983, 0.0075, 0.9939, 0.9486, 0.0130, 0.0653, 0.5455, 0.0099, 0.0146,\n",
      "        0.0113, 0.9859, 0.9930, 0.9921, 0.9833, 0.9608, 0.0051, 0.9872, 0.2553,\n",
      "        0.0485, 0.9232, 0.1419, 0.9382, 0.9844, 0.9780, 0.4279, 0.0145, 0.9512,\n",
      "        0.0143, 0.9912, 0.9929, 0.0097, 0.0039], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1644, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3407629430294037\n",
      "3100\n",
      "tensor([0.9856, 0.7439, 0.4793, 0.6250, 0.9040, 0.9467, 0.9937, 0.1154, 0.9882,\n",
      "        0.9769, 0.9875, 0.9908, 0.0362, 0.9901, 0.0392, 0.9697, 0.9755, 0.1524,\n",
      "        0.0044, 0.0086, 0.9876, 0.9937, 0.4457, 0.1005, 0.0656, 0.0537, 0.0407,\n",
      "        0.9952, 0.9934, 0.9945, 0.4381, 0.0774], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1982, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.33954209089279175\n",
      "3130\n",
      "tensor([0.0662, 0.1196, 0.0113, 0.0974, 0.5897, 0.0379, 0.2047, 0.1289, 0.9831,\n",
      "        0.9548, 0.4987, 0.1644, 0.0563, 0.9863, 0.0496, 0.0138, 0.6841, 0.3604,\n",
      "        0.8827, 0.0150, 0.1365, 0.0393, 0.9670, 0.9810, 0.9752, 0.0080, 0.1215,\n",
      "        0.8786, 0.0364, 0.0379, 0.2351, 0.8003], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1739, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.33877119421958923\n",
      "3160\n",
      "tensor([0.9567, 0.1011, 0.9486, 0.0105, 0.0374, 0.9876, 0.9913, 0.9949, 0.9951,\n",
      "        0.0098, 0.0120, 0.2105, 0.8631, 0.1017, 0.0062, 0.0727, 0.0068, 0.6359,\n",
      "        0.9863, 0.9827, 0.0073, 0.9958, 0.0076, 0.0221, 0.7421, 0.5276, 0.0041,\n",
      "        0.9875, 0.0080, 0.9892, 0.1531, 0.0032], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1408, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.33738455176353455\n",
      "3190\n",
      "tensor([0.0056, 0.0303, 0.9512, 0.9920, 0.0120, 0.5050, 0.9876, 0.9593, 0.9923,\n",
      "        0.0099, 0.0101, 0.4006, 0.8450, 0.6752, 0.9923, 0.9699, 0.1994, 0.9830,\n",
      "        0.3688, 0.9615, 0.9815, 0.0076, 0.1490, 0.0645, 0.8938, 0.1496, 0.8072,\n",
      "        0.0081, 0.9242, 0.7895, 0.0240, 0.0303], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3474, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3362419605255127\n",
      "3220\n",
      "tensor([0.0358, 0.9872, 0.0223, 0.0078, 0.0866, 0.9303, 0.8803, 0.6597, 0.0411,\n",
      "        0.0066, 0.9926, 0.9882, 0.0053, 0.5716, 0.9918, 0.9883, 0.0235, 0.7962,\n",
      "        0.1373, 0.5812, 0.9950, 0.0680, 0.3587, 0.9884, 0.9591, 0.9368, 0.9959,\n",
      "        0.4726, 0.0135, 0.9565, 0.9297, 0.0591], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.4659, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3354025185108185\n",
      "3250\n",
      "tensor([0.0131, 0.9861, 0.8049, 0.9956, 0.0069, 0.4085, 0.9858, 0.0055, 0.0179,\n",
      "        0.9949, 0.9880, 0.9925, 0.0146, 0.1763, 0.2227, 0.9558, 0.9070, 0.9427,\n",
      "        0.3937, 0.0305, 0.9606, 0.9941, 0.0199, 0.0128, 0.0225, 0.1539, 0.8331,\n",
      "        0.7928, 0.1445, 0.9454, 0.7516, 0.0223], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3344566524028778\n",
      "3280\n",
      "tensor([0.9824, 0.9918, 0.0067, 0.4111, 0.4788, 0.0742, 0.9934, 0.0097, 0.9943,\n",
      "        0.9940, 0.9940, 0.9918, 0.5437, 0.9951, 0.9857, 0.0485, 0.0104, 0.9934,\n",
      "        0.9954, 0.0460, 0.0115, 0.9899, 0.0179, 0.7574, 0.9885, 0.1118, 0.4488,\n",
      "        0.9750, 0.3091, 0.0424, 0.0079, 0.0764], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2177, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.33329567313194275\n",
      "3310\n",
      "tensor([0.9923, 0.7445, 0.9961, 0.3433, 0.9508, 0.8548, 0.1531, 0.0149, 0.9925,\n",
      "        0.7693, 0.9774, 0.9896, 0.8458, 0.0180, 0.9917, 0.9404, 0.9927, 0.0447,\n",
      "        0.9126, 0.9892, 0.9940, 0.0067, 0.0227, 0.9933, 0.0057, 0.9911, 0.0425,\n",
      "        0.0184, 0.9316, 0.2599, 0.9909, 0.1523], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3322240710258484\n",
      "3340\n",
      "tensor([0.5128, 0.1166, 0.0495, 0.0089, 0.9671, 0.9855, 0.0198, 0.0078, 0.0224,\n",
      "        0.0059, 0.9525, 0.9942, 0.0082, 0.0113, 0.0049, 0.9521, 0.0558, 0.8160,\n",
      "        0.9837, 0.7654, 0.9739, 0.2045, 0.7146, 0.9685, 0.0090, 0.0301, 0.9866,\n",
      "        0.0204, 0.9547, 0.0128, 0.0089, 0.1710], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.4204, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.33112338185310364\n",
      "3370\n",
      "tensor([0.1871, 0.0094, 0.7705, 0.0149, 0.1019, 0.8322, 0.9912, 0.0217, 0.5940,\n",
      "        0.0099, 0.9235, 0.9783, 0.0151, 0.0126, 0.9120, 0.8056, 0.9668, 0.0340,\n",
      "        0.1685, 0.0118, 0.5708, 0.9695, 0.9700, 0.0153, 0.0141, 0.1176, 0.0044,\n",
      "        0.9938, 0.0139, 0.1071, 0.0142, 0.0244], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1435, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3302360773086548\n",
      "3400\n",
      "tensor([0.9902, 0.9677, 0.1098, 0.8120, 0.1165, 0.9237, 0.0966, 0.8988, 0.8671,\n",
      "        0.9512, 0.9936, 0.1814, 0.0081, 0.0239, 0.8617, 0.5022, 0.1908, 0.0456,\n",
      "        0.9468, 0.0041, 0.9187, 0.9879, 0.1037, 0.0642, 0.0367, 0.8751, 0.9890,\n",
      "        0.0919, 0.8021, 0.6646, 0.9612, 0.0463], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1789, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3292437195777893\n",
      "3430\n",
      "tensor([0.0166, 0.0249, 0.0239, 0.3766, 0.0526, 0.0185, 0.3384, 0.9706, 0.9847,\n",
      "        0.9942, 0.0413, 0.2574, 0.8249, 0.0033, 0.9578, 0.9835, 0.9887, 0.1970,\n",
      "        0.9529, 0.0055, 0.9911, 0.9836, 0.9771, 0.9770, 0.9748, 0.6113, 0.8017,\n",
      "        0.9422, 0.0334, 0.9865, 0.9743, 0.9085], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1618, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.32822278141975403\n",
      "3460\n",
      "tensor([0.0158, 0.0177, 0.9870, 0.0527, 0.0067, 0.0071, 0.9875, 0.9915, 0.0194,\n",
      "        0.9864, 0.0052, 0.0037, 0.9596, 0.9958, 0.8779, 0.1677, 0.4809, 0.9788,\n",
      "        0.9888, 0.0110, 0.0567, 0.1970, 0.3785, 0.9822, 0.0043, 0.0026, 0.9909,\n",
      "        0.0337, 0.4810, 0.0034, 0.8256, 0.9892], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.32728832960128784\n",
      "3490\n",
      "tensor([0.9784, 0.9166, 0.0094, 0.9866, 0.0196, 0.2346, 0.1244, 0.9881, 0.9643,\n",
      "        0.9387, 0.3490, 0.0032, 0.9385, 0.0240, 0.9796, 0.0652, 0.9825, 0.0273,\n",
      "        0.9935, 0.0074, 0.8572, 0.1930, 0.0318, 0.3715, 0.9107, 0.0075, 0.0206,\n",
      "        0.1521, 0.1215, 0.0057, 0.9843, 0.0115], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.32656508684158325\n",
      "3520\n",
      "tensor([0.0406, 0.0060, 0.5872, 0.0103, 0.9793, 0.0090, 0.9303, 0.0058, 0.9755,\n",
      "        0.9463, 0.0045, 0.9838, 0.8055, 0.0236, 0.0061, 0.0935, 0.9132, 0.0128,\n",
      "        0.9855, 0.9785, 0.0058, 0.0127, 0.9865, 0.9475, 0.0134, 0.8747, 0.9271,\n",
      "        0.0036, 0.9942, 0.0042, 0.0102, 0.0040], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0506, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.32560795545578003\n",
      "3550\n",
      "tensor([0.0350, 0.0469, 0.9841, 0.2186, 0.9290, 0.0084, 0.9536, 0.9888, 0.9928,\n",
      "        0.0061, 0.0171, 0.9975, 0.9595, 0.9899, 0.0034, 0.9785, 0.0654, 0.7641,\n",
      "        0.7251, 0.9072, 0.0109, 0.8402, 0.9946, 0.9818, 0.9819, 0.0899, 0.0050,\n",
      "        0.9945, 0.9671, 0.0058, 0.9919, 0.0172], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0945, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3246828317642212\n",
      "3580\n",
      "tensor([0.9887, 0.1407, 0.0456, 0.9833, 0.0210, 0.0677, 0.9522, 0.9956, 0.0249,\n",
      "        0.9967, 0.0068, 0.9907, 0.3064, 0.0994, 0.9925, 0.0056, 0.8840, 0.0047,\n",
      "        0.9869, 0.0253, 0.0737, 0.8731, 0.1485, 0.9972, 0.0587, 0.0092, 0.0951,\n",
      "        0.9941, 0.0333, 0.0077, 0.0255, 0.0087], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0529, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3236028850078583\n",
      "3610\n",
      "tensor([0.9081, 0.8812, 0.9919, 0.0692, 0.0351, 0.8129, 0.0091, 0.8784, 0.9919,\n",
      "        0.2059, 0.9908, 0.0650, 0.9974, 0.1044, 0.9841, 0.5435, 0.1550, 0.0624,\n",
      "        0.9940, 0.2989, 0.0162, 0.2387, 0.0240, 0.9874, 0.0322, 0.0538, 0.0126,\n",
      "        0.1125, 0.9802, 0.2922, 0.0443, 0.9940], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3228588402271271\n",
      "3640\n",
      "tensor([0.9886, 0.0222, 0.0302, 0.9748, 0.0390, 0.9821, 0.1329, 0.9804, 0.9914,\n",
      "        0.2767, 0.0077, 0.0571, 0.6765, 0.9719, 0.9902, 0.8165, 0.0369, 0.3259,\n",
      "        0.2256, 0.0702, 0.9881, 0.0319, 0.9173, 0.0139, 0.0221, 0.0031, 0.9820,\n",
      "        0.9440, 0.9898, 0.2389, 0.0109, 0.9876], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1215, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3221779763698578\n",
      "3670\n",
      "tensor([0.8842, 0.9952, 0.3059, 0.0369, 0.0102, 0.9930, 0.0109, 0.7369, 0.6666,\n",
      "        0.0183, 0.6008, 0.9926, 0.9937, 0.0273, 0.0070, 0.0054, 0.2511, 0.7846,\n",
      "        0.0123, 0.0737, 0.0104, 0.8270, 0.8173, 0.9894, 0.9951, 0.0299, 0.0249,\n",
      "        0.6705, 0.0076, 0.4915, 0.9963, 0.9451], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2615, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.321332186460495\n",
      "3700\n",
      "tensor([0.0089, 0.0094, 0.0046, 0.9937, 0.8911, 0.0659, 0.0288, 0.0036, 0.0060,\n",
      "        0.6498, 0.8856, 0.9896, 0.0050, 0.9942, 0.7188, 0.0103, 0.9498, 0.9742,\n",
      "        0.0070, 0.7931, 0.0161, 0.0051, 0.5041, 0.9372, 0.9202, 0.9550, 0.9629,\n",
      "        0.9945, 0.0039, 0.0160, 0.7963, 0.0366], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2064, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.32061171531677246\n",
      "3730\n",
      "tensor([0.0270, 0.9111, 0.9941, 0.7532, 0.0658, 0.0068, 0.0220, 0.0186, 0.0084,\n",
      "        0.0707, 0.2678, 0.0269, 0.0466, 0.2623, 0.7071, 0.0072, 0.0058, 0.0046,\n",
      "        0.3163, 0.0151, 0.2437, 0.3776, 0.9907, 0.0062, 0.9161, 0.9688, 0.0142,\n",
      "        0.3247, 0.9959, 0.8846, 0.0057, 0.1186], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3468, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3198869228363037\n",
      "3760\n",
      "tensor([0.9638, 0.0568, 0.9740, 0.0362, 0.8225, 0.0997, 0.1493, 0.0067, 0.0030,\n",
      "        0.8693, 0.8798, 0.0057, 0.0344, 0.0046, 0.9892, 0.0266, 0.9564, 0.9972,\n",
      "        0.9861, 0.9265, 0.9845, 0.4330, 0.4729, 0.4226, 0.0280, 0.8798, 0.0087,\n",
      "        0.0687, 0.9935, 0.1382, 0.9594, 0.0905], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.31902843713760376\n",
      "3790\n",
      "tensor([0.0978, 0.0076, 0.5749, 0.0359, 0.9864, 0.9704, 0.1294, 0.0142, 0.9695,\n",
      "        0.9896, 0.0145, 0.9942, 0.7864, 0.1036, 0.0489, 0.9940, 0.9599, 0.9731,\n",
      "        0.9941, 0.8582, 0.9946, 0.1499, 0.8764, 0.0210, 0.9606, 0.0181, 0.7026,\n",
      "        0.9831, 0.0665, 0.0815, 0.6388, 0.9943], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2076, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.31831875443458557\n",
      "3820\n",
      "tensor([0.3561, 0.9957, 0.4421, 0.0549, 0.0949, 0.0228, 0.0116, 0.9952, 0.0148,\n",
      "        0.7399, 0.9925, 0.6875, 0.0111, 0.0119, 0.9890, 0.1028, 0.9800, 0.9908,\n",
      "        0.0100, 0.9950, 0.2765, 0.0546, 0.8427, 0.9233, 0.0172, 0.0366, 0.8933,\n",
      "        0.9115, 0.0910, 0.0072, 0.9939, 0.0447], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.31739601492881775\n",
      "3850\n",
      "tensor([0.2875, 0.5098, 0.9940, 0.9767, 0.7648, 0.9360, 0.1025, 0.8780, 0.0272,\n",
      "        0.7119, 0.0422, 0.6236, 0.0124, 0.0335, 0.6866, 0.9880, 0.0065, 0.0963,\n",
      "        0.4357, 0.0228, 0.6389, 0.0063, 0.9858, 0.0152, 0.1883, 0.7081, 0.5768,\n",
      "        0.9934, 0.9571, 0.0056, 0.0226, 0.0058], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3239, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3165283799171448\n",
      "3880\n",
      "tensor([0.0232, 0.1168, 0.9336, 0.4763, 0.9664, 0.9940, 0.9845, 0.0460, 0.0367,\n",
      "        0.9273, 0.0680, 0.7266, 0.3652, 0.0612, 0.9700, 0.0223, 0.0423, 0.0271,\n",
      "        0.9711, 0.0371, 0.8372, 0.0272, 0.9935, 0.9818, 0.9879, 0.0223, 0.1775,\n",
      "        0.7703, 0.9840, 0.1163, 0.9831, 0.9697], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0964, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.31564652919769287\n",
      "3910\n",
      "tensor([0.9337, 0.4117, 0.0441, 0.9828, 0.9570, 0.7079, 0.9943, 0.0200, 0.9839,\n",
      "        0.0168, 0.9225, 0.9908, 0.0793, 0.9852, 0.0108, 0.3915, 0.0058, 0.3074,\n",
      "        0.9876, 0.0219, 0.8751, 0.9869, 0.0070, 0.0081, 0.9909, 0.0245, 0.0040,\n",
      "        0.9961, 0.0775, 0.0089, 0.1954, 0.0474], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.31472888588905334\n",
      "3940\n",
      "tensor([0.9923, 0.0700, 0.0052, 0.0060, 0.9817, 0.0116, 0.0067, 0.9503, 0.0138,\n",
      "        0.0092, 0.0056, 0.8852, 0.9342, 0.0071, 0.0047, 0.7710, 0.0068, 0.9891,\n",
      "        0.9486, 0.7627, 0.0075, 0.7197, 0.1099, 0.9661, 0.0396, 0.1990, 0.7891,\n",
      "        0.7665, 0.8082, 0.8046, 0.9909, 0.0037], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1512, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.31378304958343506\n",
      "3970\n",
      "tensor([0.9947, 0.9562, 0.0226, 0.0249, 0.9768, 0.9966, 0.9927, 0.0041, 0.8944,\n",
      "        0.1239, 0.9881, 0.0077, 0.9834, 0.0137, 0.9288, 0.0470, 0.9652, 0.7777,\n",
      "        0.9946, 0.9842, 0.0624, 0.9820, 0.6937, 0.5435, 0.0751, 0.9922, 0.9942,\n",
      "        0.0141, 0.0143, 0.8030, 0.9889, 0.0302], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0773, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3129346966743469\n",
      "4000\n",
      "tensor([0.0470, 0.9932, 0.1733, 0.9950, 0.0069, 0.0048, 0.0076, 0.0075, 0.9965,\n",
      "        0.0197, 0.2669, 0.0283, 0.9961, 0.9684, 0.2357, 0.0039, 0.9881, 0.9913,\n",
      "        0.0071, 0.1100, 0.9961, 0.0231, 0.0194, 0.9848, 0.9911, 0.9957, 0.0715,\n",
      "        0.9921, 0.9934, 0.9954, 0.8989, 0.0083], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.4561, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3119348883628845\n",
      "4030\n",
      "tensor([0.9864, 0.3141, 0.9565, 0.9955, 0.9347, 0.8765, 0.1777, 0.5913, 0.5340,\n",
      "        0.0272, 0.9373, 0.0067, 0.9900, 0.9381, 0.3102, 0.7986, 0.9962, 0.9915,\n",
      "        0.0160, 0.2683, 0.9867, 0.1039, 0.9737, 0.8703, 0.9800, 0.0120, 0.9796,\n",
      "        0.9322, 0.9659, 0.0409, 0.0084, 0.5102], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2471, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3112950921058655\n",
      "4060\n",
      "tensor([0.9926, 0.0132, 0.0179, 0.9770, 0.0130, 0.9963, 0.0757, 0.0040, 0.9968,\n",
      "        0.9820, 0.8978, 0.0046, 0.1366, 0.5092, 0.8493, 0.0056, 0.9474, 0.9222,\n",
      "        0.9860, 0.0060, 0.9946, 0.0027, 0.0579, 0.0065, 0.9952, 0.0036, 0.9885,\n",
      "        0.0036, 0.8218, 0.0088, 0.0063, 0.0031], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3056, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3104945421218872\n",
      "4090\n",
      "tensor([0.9940, 0.9847, 0.0025, 0.6270, 0.1779, 0.9900, 0.9971, 0.0067, 0.9936,\n",
      "        0.2091, 0.7522, 0.9799, 0.1542, 0.0127, 0.0080, 0.0039, 0.3381, 0.9974,\n",
      "        0.9905, 0.5585, 0.0118, 0.0754, 0.0147, 0.9674, 0.9501, 0.0068, 0.8426,\n",
      "        0.0375, 0.1278, 0.9906, 0.0042, 0.9760], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2062, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.30961692333221436\n",
      "4120\n",
      "tensor([0.8326, 0.0739, 0.0136, 0.0252, 0.7583, 0.5719, 0.9758, 0.9855, 0.8733,\n",
      "        0.0025, 0.0121, 0.0188, 0.9374, 0.0661, 0.9934, 0.0176, 0.9945, 0.9657,\n",
      "        0.7288, 0.5662, 0.0204, 0.9969, 0.0086, 0.4555, 0.0048, 0.8756, 0.4351,\n",
      "        0.0036, 0.9874, 0.0085, 0.9562, 0.5327], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2147, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3090130686759949\n",
      "4150\n",
      "tensor([0.9738, 0.9778, 0.7181, 0.0039, 0.9687, 0.0029, 0.9916, 0.0044, 0.0561,\n",
      "        0.7985, 0.9956, 0.0394, 0.1593, 0.0317, 0.0096, 0.9943, 0.9918, 0.0280,\n",
      "        0.9380, 0.9914, 0.0034, 0.9886, 0.0104, 0.1705, 0.0121, 0.9689, 0.9957,\n",
      "        0.0299, 0.2540, 0.0167, 0.6036, 0.0065], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1776, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.308096319437027\n",
      "4180\n",
      "tensor([0.0152, 0.9741, 0.0119, 0.0538, 0.8664, 0.0943, 0.9903, 0.0100, 0.9883,\n",
      "        0.9941, 0.0055, 0.0047, 0.9596, 0.0229, 0.1605, 0.9911, 0.0442, 0.1497,\n",
      "        0.9616, 0.0088, 0.2747, 0.8759, 0.0250, 0.0841, 0.0035, 0.0777, 0.6047,\n",
      "        0.1229, 0.3798, 0.0033, 0.9897, 0.9692], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2283, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3073999583721161\n",
      "4210\n",
      "tensor([0.9939, 0.9606, 0.9886, 0.6599, 0.2102, 0.0445, 0.6751, 0.6231, 0.0084,\n",
      "        0.9447, 0.9948, 0.8579, 0.0032, 0.9201, 0.1874, 0.1496, 0.9928, 0.9896,\n",
      "        0.9913, 0.0073, 0.0180, 0.9969, 0.0364, 0.9861, 0.0078, 0.3260, 0.9858,\n",
      "        0.0054, 0.9824, 0.2832, 0.0154, 0.9892], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1521, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3065709173679352\n",
      "4240\n",
      "tensor([0.0143, 0.3763, 0.0545, 0.3919, 0.9793, 0.8326, 0.0291, 0.0884, 0.7844,\n",
      "        0.9863, 0.2847, 0.9088, 0.0057, 0.9904, 0.9288, 0.9884, 0.0202, 0.1753,\n",
      "        0.0160, 0.6697, 0.9933, 0.9673, 0.1031, 0.7167, 0.0378, 0.9854, 0.3736,\n",
      "        0.5430, 0.8677, 0.2805, 0.1635, 0.9959], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3378, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3058989942073822\n",
      "4270\n",
      "tensor([0.0047, 0.0040, 0.0206, 0.5414, 0.0049, 0.9380, 0.9879, 0.0054, 0.0048,\n",
      "        0.0047, 0.9959, 0.0108, 0.0126, 0.0058, 0.0033, 0.9524, 0.9821, 0.0235,\n",
      "        0.0042, 0.1368, 0.9222, 0.0462, 0.0123, 0.9339, 0.3171, 0.3354, 0.2597,\n",
      "        0.0778, 0.0035, 0.0215, 0.9952, 0.0302], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.30509111285209656\n",
      "4300\n",
      "tensor([0.6953, 0.9549, 0.0956, 0.9289, 0.0133, 0.0146, 0.9915, 0.9647, 0.8226,\n",
      "        0.9835, 0.3379, 0.3259, 0.0234, 0.9881, 0.9947, 0.1410, 0.9896, 0.0343,\n",
      "        0.0308, 0.9961, 0.0333, 0.9877, 0.9894, 0.9050, 0.0065, 0.0044, 0.0082,\n",
      "        0.0100, 0.9856, 0.8861, 0.1308, 0.0373], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1540, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.30431854724884033\n",
      "4330\n",
      "tensor([0.0080, 0.9955, 0.9589, 0.8292, 0.9914, 0.0801, 0.0042, 0.0038, 0.0062,\n",
      "        0.0147, 0.9756, 0.9944, 0.9712, 0.9874, 0.9926, 0.0335, 0.1932, 0.0179,\n",
      "        0.9958, 0.0028, 0.9916, 0.9759, 0.0713, 0.9919, 0.9932, 0.9851, 0.0083,\n",
      "        0.9971, 0.9947, 0.9652, 0.0091, 0.0251], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0294, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.30346083641052246\n",
      "4360\n",
      "tensor([0.9715, 0.9921, 0.3904, 0.2844, 0.4638, 0.9260, 0.6751, 0.9747, 0.0046,\n",
      "        0.0036, 0.9899, 0.9789, 0.9837, 0.0483, 0.0678, 0.0043, 0.9349, 0.9957,\n",
      "        0.0385, 0.0997, 0.8398, 0.0091, 0.9757, 0.9687, 0.7131, 0.8362, 0.0049,\n",
      "        0.4634, 0.3482, 0.0313, 0.0168, 0.0425], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1385, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3029089868068695\n",
      "4390\n",
      "tensor([0.3946, 0.0120, 0.0111, 0.9963, 0.9933, 0.0413, 0.0436, 0.9878, 0.9938,\n",
      "        0.0025, 0.0140, 0.9931, 0.9943, 0.1824, 0.9944, 0.9935, 0.0227, 0.0459,\n",
      "        0.0457, 0.1933, 0.8772, 0.3391, 0.4757, 0.9870, 0.7958, 0.0077, 0.9802,\n",
      "        0.5824, 0.0742, 0.0475, 0.9943, 0.9971], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1181, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.302283376455307\n",
      "4420\n",
      "tensor([0.1095, 0.9750, 0.8983, 0.9854, 0.9817, 0.0849, 0.0135, 0.0405, 0.0082,\n",
      "        0.7907, 0.9195, 0.9971, 0.7251, 0.5671, 0.9769, 0.5340, 0.0046, 0.0571,\n",
      "        0.9111, 0.9955, 0.9966, 0.9936, 0.0201, 0.9932, 0.0295, 0.9766, 0.7707,\n",
      "        0.9925, 0.9925, 0.0384, 0.9360, 0.0183], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.301682710647583\n",
      "4450\n",
      "tensor([0.3241, 0.9485, 0.9875, 0.9741, 0.4909, 0.0102, 0.0283, 0.7896, 0.0044,\n",
      "        0.0034, 0.5988, 0.9035, 0.9734, 0.0056, 0.7342, 0.0031, 0.9271, 0.9202,\n",
      "        0.9945, 0.0800, 0.9726, 0.0242, 0.0149, 0.3500, 0.0107, 0.9820, 0.0595,\n",
      "        0.0314, 0.0864, 0.6049, 0.9398, 0.1150], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2585, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3012169599533081\n",
      "4480\n",
      "tensor([0.0147, 0.0746, 0.7353, 0.0064, 0.9934, 0.8955, 0.0689, 0.0679, 0.1088,\n",
      "        0.0070, 0.9949, 0.1779, 0.0761, 0.0070, 0.0493, 0.0208, 0.0959, 0.9947,\n",
      "        0.9907, 0.9222, 0.9965, 0.9943, 0.5659, 0.0030, 0.0055, 0.9944, 0.8879,\n",
      "        0.4792, 0.1773, 0.0024, 0.0527, 0.9579], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.4088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.3004814684391022\n",
      "4510\n",
      "tensor([0.0271, 0.0555, 0.0906, 0.8820, 0.9975, 0.0059, 0.0506, 0.0074, 0.9910,\n",
      "        0.0180, 0.0642, 0.0032, 0.1308, 0.9824, 0.9954, 0.6236, 0.9807, 0.0079,\n",
      "        0.0305, 0.0068, 0.9843, 0.9971, 0.7834, 0.9923, 0.0039, 0.9962, 0.0116,\n",
      "        0.0776, 0.8061, 0.0107, 0.8992, 0.9961], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29975438117980957\n",
      "4540\n",
      "tensor([0.9975, 0.1034, 0.0165, 0.9934, 0.9302, 0.0100, 0.9541, 0.0316, 0.8879,\n",
      "        0.0040, 0.9690, 0.0076, 0.5826, 0.8489, 0.9904, 0.0494, 0.8999, 0.0518,\n",
      "        0.9939, 0.0072, 0.9510, 0.3821, 0.9910, 0.0114, 0.7565, 0.8035, 0.9520,\n",
      "        0.0267, 0.0037, 0.0197, 0.9871, 0.9785], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29911020398139954\n",
      "4570\n",
      "tensor([0.0553, 0.0237, 0.2705, 0.9560, 0.9937, 0.0288, 0.0115, 0.9420, 0.3686,\n",
      "        0.5822, 0.9695, 0.9961, 0.7120, 0.7416, 0.4203, 0.0201, 0.0328, 0.9766,\n",
      "        0.9980, 0.0121, 0.9494, 0.2167, 0.9022, 0.9965, 0.7394, 0.9946, 0.0045,\n",
      "        0.9927, 0.0292, 0.0023, 0.0103, 0.0045], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2156, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2984105050563812\n",
      "4600\n",
      "tensor([0.9940, 0.9922, 0.5810, 0.9940, 0.5743, 0.0467, 0.9976, 0.9932, 0.9556,\n",
      "        0.3278, 0.9024, 0.9901, 0.0949, 0.9874, 0.0073, 0.9331, 0.6045, 0.9928,\n",
      "        0.9961, 0.9952, 0.6356, 0.9930, 0.9933, 0.9932, 0.0255, 0.4951, 0.9390,\n",
      "        0.9940, 0.8964, 0.5320, 0.0857, 0.0496], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2781, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2979224920272827\n",
      "4630\n",
      "tensor([0.0062, 0.9765, 0.8111, 0.1500, 0.7301, 0.9953, 0.0181, 0.0167, 0.3066,\n",
      "        0.0267, 0.0137, 0.9126, 0.8997, 0.0088, 0.0447, 0.0194, 0.0156, 0.9952,\n",
      "        0.1685, 0.9937, 0.9864, 0.0312, 0.6259, 0.9895, 0.0292, 0.9953, 0.9931,\n",
      "        0.9969, 0.0121, 0.3506, 0.2741, 0.9983], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1963, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29721373319625854\n",
      "4660\n",
      "tensor([0.4437, 0.9933, 0.9968, 0.3957, 0.8300, 0.0324, 0.0020, 0.0170, 0.0022,\n",
      "        0.0205, 0.9772, 0.7806, 0.0051, 0.9911, 0.0271, 0.5557, 0.4928, 0.9899,\n",
      "        0.6717, 0.9914, 0.9484, 0.0044, 0.0033, 0.0034, 0.9906, 0.9012, 0.6052,\n",
      "        0.9943, 0.9958, 0.9965, 0.0037, 0.9865], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1574, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2964745759963989\n",
      "4690\n",
      "tensor([0.0096, 0.0056, 0.0804, 0.0025, 0.9930, 0.0061, 0.0426, 0.0118, 0.0085,\n",
      "        0.9899, 0.0511, 0.0073, 0.1239, 0.7966, 0.9682, 0.0066, 0.0510, 0.1823,\n",
      "        0.0087, 0.0054, 0.7231, 0.9141, 0.0026, 0.9826, 0.9897, 0.5471, 0.9732,\n",
      "        0.9937, 0.3357, 0.0220, 0.1040, 0.1915], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2957979142665863\n",
      "4720\n",
      "tensor([0.9936, 0.0619, 0.9965, 0.1068, 0.9737, 0.0083, 0.9965, 0.0176, 0.1272,\n",
      "        0.8287, 0.0027, 0.0020, 0.0035, 0.0071, 0.9971, 0.0401, 0.0102, 0.9975,\n",
      "        0.0217, 0.9907, 0.9766, 0.0036, 0.9540, 0.0442, 0.0096, 0.9929, 0.9826,\n",
      "        0.3934, 0.9316, 0.9919, 0.7713, 0.1660], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0711, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29503992199897766\n",
      "4750\n",
      "tensor([0.9410, 0.6268, 0.0322, 0.0130, 0.9700, 0.9962, 0.8133, 0.0477, 0.0445,\n",
      "        0.0335, 0.0040, 0.8842, 0.9783, 0.0043, 0.0057, 0.0107, 0.9939, 0.9204,\n",
      "        0.9779, 0.0349, 0.0420, 0.3736, 0.9890, 0.0060, 0.0071, 0.0032, 0.9898,\n",
      "        0.9228, 0.9702, 0.9200, 0.9646, 0.9709], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3576, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29436197876930237\n",
      "4780\n",
      "tensor([0.0271, 0.2101, 0.9878, 0.9920, 0.9877, 0.8234, 0.9954, 0.3813, 0.0613,\n",
      "        0.9966, 0.3623, 0.9605, 0.0319, 0.9913, 0.9942, 0.9548, 0.0066, 0.1395,\n",
      "        0.9876, 0.8550, 0.0821, 0.1040, 0.0534, 0.0223, 0.9504, 0.0071, 0.9882,\n",
      "        0.9967, 0.4045, 0.0099, 0.0190, 0.9539], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1713, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2937484383583069\n",
      "4810\n",
      "tensor([0.0073, 0.9915, 0.0925, 0.1133, 0.9376, 0.0499, 0.9299, 0.0121, 0.2507,\n",
      "        0.9925, 0.7131, 0.9894, 0.0771, 0.0070, 0.9965, 0.9858, 0.9666, 0.0359,\n",
      "        0.0132, 0.3737, 0.0596, 0.9912, 0.4576, 0.9866, 0.8754, 0.0811, 0.9848,\n",
      "        0.0041, 0.0117, 0.0215, 0.9902, 0.9953], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2931486666202545\n",
      "4840\n",
      "tensor([0.0164, 0.0047, 0.0090, 0.7099, 0.9945, 0.8946, 0.0069, 0.0038, 0.9909,\n",
      "        0.9966, 0.1359, 0.9778, 0.9944, 0.9979, 0.8915, 0.9768, 0.0069, 0.9949,\n",
      "        0.9914, 0.9963, 0.9109, 0.0547, 0.8771, 0.9933, 0.0026, 0.9830, 0.0063,\n",
      "        0.7939, 0.8657, 0.9881, 0.9881, 0.9294], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2186, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29260313510894775\n",
      "4870\n",
      "tensor([0.9810, 0.0047, 0.9912, 0.0024, 0.1918, 0.9866, 0.9948, 0.0079, 0.0259,\n",
      "        0.0045, 0.9964, 0.9975, 0.8138, 0.0082, 0.9967, 0.9934, 0.0098, 0.0151,\n",
      "        0.7637, 0.0097, 0.0122, 0.9885, 0.0454, 0.0394, 0.9655, 0.3495, 0.9950,\n",
      "        0.0223, 0.0133, 0.0897, 0.9772, 0.0062], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1446, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2921055555343628\n",
      "4900\n",
      "tensor([0.0205, 0.9921, 0.0049, 0.9972, 0.0044, 0.9918, 0.9949, 0.0067, 0.9924,\n",
      "        0.0069, 0.0049, 0.0034, 0.0038, 0.2582, 0.9856, 0.1563, 0.0449, 0.0917,\n",
      "        0.9784, 0.9966, 0.9403, 0.0054, 0.9450, 0.3639, 0.0032, 0.0654, 0.9898,\n",
      "        0.9026, 0.0069, 0.0044, 0.0066, 0.0069], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0805, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29143989086151123\n",
      "4930\n",
      "tensor([0.1872, 0.1116, 0.0286, 0.2722, 0.9974, 0.4629, 0.2677, 0.0192, 0.0193,\n",
      "        0.0124, 0.7814, 0.0228, 0.0226, 0.0047, 0.0063, 0.3380, 0.9936, 0.6200,\n",
      "        0.8094, 0.9412, 0.5639, 0.9072, 0.0816, 0.0426, 0.0226, 0.0910, 0.9360,\n",
      "        0.1293, 0.0164, 0.0386, 0.9939, 0.5899], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2289, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.29093867540359497\n",
      "4960\n",
      "tensor([0.9888, 0.9759, 0.0037, 0.9442, 0.9912, 0.9936, 0.0157, 0.0873, 0.0054,\n",
      "        0.0160, 0.0027, 0.9955, 0.0019, 0.9389, 0.0060, 0.0099, 0.0086, 0.3595,\n",
      "        0.0052, 0.9017, 0.9972, 0.0232, 0.0027, 0.0396, 0.2421, 0.0015, 0.3986,\n",
      "        0.9934, 0.7481, 0.9113, 0.1491, 0.0057], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1206, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2901827394962311\n",
      "4990\n",
      "tensor([0.0066, 0.0053, 0.2617, 0.6904, 0.9948, 0.9320, 0.0088, 0.0253, 0.9907,\n",
      "        0.4095, 0.9689, 0.0292, 0.9937, 0.0055, 0.0035, 0.9945, 0.9849, 0.0120,\n",
      "        0.0040, 0.9977, 0.0030, 0.1300, 0.9856, 0.9942, 0.4645, 0.0430, 0.9324,\n",
      "        0.9923, 0.9890, 0.1176, 0.9655, 0.9974], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1385, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28955188393592834\n",
      "Save the weights\n",
      "5020\n",
      "tensor([0.9678, 0.4354, 0.9389, 0.0135, 0.9971, 0.4105, 0.9344, 0.9943, 0.0117,\n",
      "        0.0383, 0.0067, 0.0056, 0.9646, 0.0387, 0.1341, 0.5605, 0.0086, 0.9540,\n",
      "        0.0026, 0.0663, 0.1120, 0.9890, 0.9796, 0.1567, 0.0031, 0.0060, 0.0310,\n",
      "        0.9713, 0.9875, 0.9918, 0.9852, 0.9173], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1028, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28895002603530884\n",
      "5050\n",
      "tensor([0.4948, 0.9961, 0.0054, 0.0147, 0.2077, 0.0210, 0.0164, 0.9848, 0.0120,\n",
      "        0.0105, 0.9963, 0.9964, 0.0397, 0.9846, 0.9979, 0.9961, 0.0194, 0.0032,\n",
      "        0.9856, 0.8416, 0.0099, 0.9969, 0.0049, 0.9868, 0.0050, 0.0037, 0.4965,\n",
      "        0.9927, 0.0182, 0.0037, 0.5775, 0.0300], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2881913185119629\n",
      "5080\n",
      "tensor([0.0150, 0.9440, 0.3349, 0.9975, 0.0080, 0.0025, 0.0132, 0.0566, 0.9974,\n",
      "        0.0148, 0.9718, 0.0036, 0.9969, 0.9956, 0.9896, 0.0110, 0.9913, 0.9954,\n",
      "        0.9837, 0.2313, 0.0114, 0.0179, 0.0105, 0.0118, 0.0291, 0.9869, 0.9870,\n",
      "        0.3005, 0.0395, 0.9926, 0.1800, 0.9865], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0519, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2876039147377014\n",
      "5110\n",
      "tensor([0.9418, 0.4248, 0.0064, 0.9554, 0.0054, 0.0305, 0.9959, 0.9974, 0.9941,\n",
      "        0.9967, 0.0088, 0.0021, 0.2608, 0.9908, 0.9956, 0.0116, 0.9879, 0.9891,\n",
      "        0.9784, 0.0052, 0.9462, 0.9941, 0.0853, 0.0540, 0.8714, 0.9764, 0.0052,\n",
      "        0.9876, 0.9977, 0.9978, 0.7855, 0.9963], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2867542505264282\n",
      "5140\n",
      "tensor([0.0203, 0.9874, 0.0072, 0.0559, 0.9928, 0.8896, 0.9967, 0.0133, 0.5490,\n",
      "        0.9896, 0.1282, 0.0048, 0.9398, 0.0047, 0.9886, 0.9857, 0.9894, 0.0265,\n",
      "        0.9482, 0.9876, 0.6587, 0.0226, 0.0050, 0.6094, 0.6263, 0.4175, 0.9732,\n",
      "        0.0059, 0.0031, 0.1010, 0.2176, 0.0031], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1564, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28606024384498596\n",
      "5170\n",
      "tensor([0.7502, 0.9165, 0.0671, 0.9862, 0.7251, 0.0029, 0.0053, 0.0067, 0.0032,\n",
      "        0.0124, 0.0054, 0.9943, 0.0040, 0.6130, 0.9905, 0.8663, 0.6396, 0.6648,\n",
      "        0.0028, 0.1395, 0.7665, 0.9922, 0.1581, 0.9009, 0.0200, 0.3701, 0.0029,\n",
      "        0.0066, 0.0022, 0.1265, 0.9958, 0.9961], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2987, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.285521924495697\n",
      "5200\n",
      "tensor([0.0033, 0.9912, 0.0059, 0.9937, 0.9858, 0.8048, 0.0021, 0.0065, 0.4033,\n",
      "        0.0041, 0.0799, 0.7513, 0.2041, 0.0151, 0.5148, 0.9298, 0.7167, 0.0036,\n",
      "        0.9776, 0.7593, 0.5563, 0.1152, 0.9941, 0.0121, 0.5908, 0.6081, 0.0030,\n",
      "        0.0518, 0.2317, 0.0039, 0.9946, 0.0017], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1720, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28490957617759705\n",
      "5230\n",
      "tensor([0.9974, 0.0524, 0.0386, 0.0119, 0.8405, 0.1279, 0.9940, 0.1075, 0.9948,\n",
      "        0.0016, 0.2481, 0.0739, 0.9904, 0.9967, 0.2851, 0.0033, 0.0369, 0.0050,\n",
      "        0.0072, 0.1550, 0.0031, 0.9952, 0.8225, 0.0022, 0.0029, 0.0210, 0.0047,\n",
      "        0.0041, 0.9875, 0.9319, 0.3770, 0.2232], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28431862592697144\n",
      "5260\n",
      "tensor([0.0096, 0.0041, 0.0886, 0.9846, 0.9967, 0.9811, 0.1466, 0.0754, 0.9467,\n",
      "        0.0034, 0.0025, 0.9965, 0.9255, 0.0188, 0.1919, 0.8250, 0.9656, 0.0091,\n",
      "        0.4887, 0.0293, 0.0041, 0.7704, 0.0015, 0.9977, 0.1284, 0.9972, 0.6071,\n",
      "        0.2623, 0.0192, 0.9950, 0.9524, 0.9970], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2836087644100189\n",
      "5290\n",
      "tensor([0.9775, 0.6766, 0.9985, 0.9880, 0.0037, 0.9651, 0.0441, 0.9951, 0.0032,\n",
      "        0.9413, 0.0121, 0.9909, 0.0027, 0.4200, 0.0062, 0.2918, 0.0906, 0.0359,\n",
      "        0.3041, 0.0569, 0.9478, 0.9888, 0.9564, 0.0048, 0.4976, 0.9970, 0.6150,\n",
      "        0.9962, 0.1068, 0.9967, 0.9603, 0.9918], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2355, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28308576345443726\n",
      "5320\n",
      "tensor([0.0062, 0.9915, 0.9871, 0.8805, 0.0081, 0.0102, 0.0227, 0.0889, 0.9925,\n",
      "        0.0067, 0.0136, 0.0818, 0.3712, 0.9936, 0.9944, 0.3361, 0.4537, 0.9907,\n",
      "        0.9905, 0.0033, 0.9976, 0.9967, 0.0276, 0.0138, 0.0022, 0.9959, 0.9973,\n",
      "        0.9742, 0.0087, 0.0176, 0.9863, 0.9850], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.282505065202713\n",
      "5350\n",
      "tensor([0.2607, 0.0055, 0.0029, 0.0184, 0.0264, 0.7222, 0.0031, 0.9953, 0.0017,\n",
      "        0.5697, 0.8429, 0.0025, 0.0024, 0.0025, 0.1972, 0.9797, 0.0027, 0.9977,\n",
      "        0.1120, 0.0031, 0.1131, 0.9873, 0.0068, 0.3317, 0.0027, 0.0025, 0.0015,\n",
      "        0.0034, 0.0032, 0.3005, 0.1966, 0.0105], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3279, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28189802169799805\n",
      "5380\n",
      "tensor([0.6935, 0.3791, 0.0032, 0.9842, 0.7005, 0.9739, 0.9960, 0.2226, 0.9896,\n",
      "        0.9635, 0.9967, 0.9772, 0.8915, 0.9944, 0.0030, 0.9888, 0.9446, 0.9942,\n",
      "        0.9295, 0.9857, 0.3063, 0.9408, 0.0023, 0.0397, 0.9520, 0.9937, 0.0089,\n",
      "        0.0034, 0.9835, 0.0026, 0.0050, 0.9792], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1759, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2812535762786865\n",
      "5410\n",
      "tensor([0.0074, 0.0037, 0.9866, 0.9936, 0.0217, 0.0473, 0.0270, 0.1177, 0.4993,\n",
      "        0.7449, 0.0087, 0.7196, 0.8292, 0.9579, 0.9942, 0.9087, 0.6815, 0.0038,\n",
      "        0.0139, 0.0376, 0.8745, 0.8138, 0.5982, 0.4538, 0.9945, 0.0287, 0.0057,\n",
      "        0.5623, 0.0030, 0.0083, 0.0136, 0.9953], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2273, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.28075727820396423\n",
      "5440\n",
      "tensor([0.9768, 0.9862, 0.9763, 0.9966, 0.9971, 0.9456, 0.0286, 0.9882, 0.6808,\n",
      "        0.9231, 0.0022, 0.0060, 0.8850, 0.9910, 0.0056, 0.0171, 0.0036, 0.9820,\n",
      "        0.0036, 0.9710, 0.0058, 0.9947, 0.9957, 0.9971, 0.9828, 0.9904, 0.0026,\n",
      "        0.0018, 0.9855, 0.0060, 0.9962, 0.9637], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.6678, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2801532447338104\n",
      "5470\n",
      "tensor([0.0061, 0.0025, 0.0244, 0.0068, 0.9947, 0.9820, 0.9893, 0.0064, 0.0095,\n",
      "        0.1569, 0.9971, 0.0161, 0.0109, 0.0069, 0.0063, 0.9969, 0.0142, 0.0222,\n",
      "        0.0015, 0.9495, 0.9971, 0.0109, 0.0918, 0.9920, 0.0060, 0.9034, 0.0124,\n",
      "        0.0291, 0.8753, 0.0052, 0.0171, 0.9966], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2327, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2796597480773926\n",
      "5500\n",
      "tensor([0.1460, 0.9576, 0.0089, 0.8903, 0.9037, 0.3923, 0.8458, 0.0037, 0.9820,\n",
      "        0.6937, 0.1039, 0.9854, 0.0234, 0.9686, 0.0072, 0.0052, 0.9719, 0.9751,\n",
      "        0.6527, 0.8213, 0.9602, 0.0409, 0.0078, 0.0090, 0.9656, 0.9977, 0.9413,\n",
      "        0.7721, 0.0922, 0.1556, 0.9468, 0.0032], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1530, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2790908217430115\n",
      "5530\n",
      "tensor([0.0227, 0.9964, 0.9465, 0.9872, 0.0077, 0.0044, 0.9856, 0.9733, 0.4509,\n",
      "        0.9939, 0.9903, 0.9937, 0.0178, 0.0042, 0.9959, 0.9974, 0.0190, 0.0505,\n",
      "        0.7006, 0.9958, 0.1642, 0.1926, 0.0085, 0.7411, 0.9967, 0.0068, 0.0059,\n",
      "        0.9919, 0.9920, 0.9637, 0.9008, 0.0082], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2180, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2786230146884918\n",
      "5560\n",
      "tensor([0.1607, 0.9975, 0.9977, 0.9820, 0.0469, 0.0064, 0.9947, 0.9874, 0.5507,\n",
      "        0.7102, 0.0730, 0.4224, 0.3107, 0.0186, 0.9695, 0.0455, 0.0087, 0.0097,\n",
      "        0.1040, 0.8613, 0.0108, 0.4717, 0.0238, 0.7660, 0.0231, 0.9196, 0.9965,\n",
      "        0.9962, 0.9913, 0.9935, 0.9966, 0.9942], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2945, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2780931293964386\n",
      "5590\n",
      "tensor([0.0066, 0.0154, 0.0080, 0.0053, 0.9962, 0.0258, 0.9676, 0.0141, 0.9931,\n",
      "        0.6996, 0.1928, 0.9281, 0.9972, 0.7650, 0.0453, 0.0219, 0.5562, 0.1381,\n",
      "        0.9951, 0.0445, 0.1491, 0.9970, 0.8658, 0.0172, 0.0042, 0.0169, 0.0259,\n",
      "        0.0074, 0.9911, 0.0856, 0.0261, 0.5238], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3019, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2774668037891388\n",
      "5620\n",
      "tensor([0.0453, 0.0022, 0.0981, 0.0057, 0.0401, 0.0353, 0.8935, 0.9985, 0.0068,\n",
      "        0.0133, 0.1112, 0.9978, 0.9973, 0.1592, 0.9881, 0.3424, 0.3691, 0.9952,\n",
      "        0.0082, 0.9729, 0.0030, 0.9961, 0.9929, 0.9967, 0.9946, 0.4255, 0.9967,\n",
      "        0.2850, 0.9977, 0.1337, 0.9986, 0.9988], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1036, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2768802344799042\n",
      "5650\n",
      "tensor([0.9402, 0.9667, 0.9301, 0.2109, 0.8835, 0.8299, 0.9953, 0.8952, 0.9838,\n",
      "        0.9972, 0.9981, 0.9857, 0.3037, 0.5301, 0.6933, 0.9824, 0.0126, 0.0061,\n",
      "        0.9940, 0.9063, 0.0082, 0.0187, 0.0116, 0.6853, 0.0120, 0.9975, 0.0135,\n",
      "        0.0031, 0.5615, 0.0031, 0.0116, 0.0057], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1778, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.27634239196777344\n",
      "5680\n",
      "tensor([0.0379, 0.9920, 0.0041, 0.4295, 0.0035, 0.9932, 0.8320, 0.1748, 0.9689,\n",
      "        0.9978, 0.9913, 0.9923, 0.9942, 0.9809, 0.3162, 0.7483, 0.9231, 0.9961,\n",
      "        0.0136, 0.0506, 0.0544, 0.6491, 0.0019, 0.9954, 0.1556, 0.3996, 0.9973,\n",
      "        0.9858, 0.0035, 0.0235, 0.0026, 0.9968], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1315, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.27580031752586365\n",
      "5710\n",
      "tensor([0.0091, 0.9949, 0.9779, 0.0151, 0.9936, 0.1557, 0.1116, 0.8548, 0.9931,\n",
      "        0.1457, 0.9858, 0.0083, 0.0296, 0.7765, 0.2672, 0.9973, 0.9934, 0.4570,\n",
      "        0.0034, 0.9417, 0.0107, 0.9979, 0.9619, 0.9934, 0.0069, 0.0180, 0.5147,\n",
      "        0.7196, 0.7357, 0.9846, 0.0020, 0.0048], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1721, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.275198370218277\n",
      "5740\n",
      "tensor([0.9909, 0.0137, 0.5524, 0.0673, 0.0258, 0.0249, 0.9620, 0.0118, 0.0201,\n",
      "        0.0052, 0.0151, 0.9961, 0.2139, 0.3681, 0.6959, 0.0038, 0.9906, 0.0376,\n",
      "        0.8231, 0.0152, 0.7246, 0.9922, 0.0059, 0.0108, 0.0047, 0.1055, 0.0062,\n",
      "        0.0118, 0.9812, 0.0308, 0.0234, 0.9438], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2112, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2747485041618347\n",
      "5770\n",
      "tensor([0.9976, 0.9974, 0.4686, 0.9876, 0.0170, 0.0824, 0.2019, 0.0090, 0.0020,\n",
      "        0.9972, 0.0024, 0.9964, 0.9786, 0.8842, 0.0078, 0.9835, 0.0530, 0.1196,\n",
      "        0.9988, 0.0058, 0.0095, 0.9985, 0.0061, 0.9940, 0.0035, 0.9967, 0.0051,\n",
      "        0.9387, 0.0118, 0.5430, 0.1861, 0.0076], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2600, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2742674946784973\n",
      "5800\n",
      "tensor([0.0080, 0.9956, 0.1665, 0.0048, 0.8679, 0.0039, 0.9960, 0.9969, 0.9582,\n",
      "        0.0223, 0.0075, 0.0028, 0.0058, 0.0070, 0.0206, 0.3014, 0.9838, 0.4936,\n",
      "        0.7184, 0.9969, 0.9350, 0.9846, 0.9479, 0.9937, 0.9973, 0.0833, 0.0595,\n",
      "        0.9934, 0.9978, 0.9909, 0.9975, 0.0065], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2408, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.27366602420806885\n",
      "5830\n",
      "tensor([0.0235, 0.9951, 0.8949, 0.9959, 0.9958, 0.0746, 0.9882, 0.0048, 0.0025,\n",
      "        0.8093, 0.9706, 0.9965, 0.0651, 0.2664, 0.0495, 0.0385, 0.9625, 0.0093,\n",
      "        0.0230, 0.0026, 0.9978, 0.9671, 0.0163, 0.9979, 0.9982, 0.1116, 0.9637,\n",
      "        0.9825, 0.2321, 0.9795, 0.1332, 0.7466], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0956, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2731661796569824\n",
      "5860\n",
      "tensor([0.0022, 0.0110, 0.9892, 0.9671, 0.9855, 0.0811, 0.0175, 0.9969, 0.0077,\n",
      "        0.9887, 0.9795, 0.9984, 0.8256, 0.0056, 0.0109, 0.9974, 0.7860, 0.9937,\n",
      "        0.9816, 0.9028, 0.0210, 0.1729, 0.9970, 0.9675, 0.0298, 0.0091, 0.0077,\n",
      "        0.9981, 0.0096, 0.1417, 0.4290, 0.0017], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0658, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2727614641189575\n",
      "5890\n",
      "tensor([0.0044, 0.9955, 0.0056, 0.0039, 0.0017, 0.9955, 0.6770, 0.9920, 0.9962,\n",
      "        0.0057, 0.9956, 0.9977, 0.9949, 0.9339, 0.9920, 0.0079, 0.0089, 0.0159,\n",
      "        0.8486, 0.0073, 0.0124, 0.0084, 0.0338, 0.9947, 0.9938, 0.0220, 0.0037,\n",
      "        0.0055, 0.9130, 0.0090, 0.0025, 0.9311], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2404, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2722876965999603\n",
      "5920\n",
      "tensor([0.3098, 0.0090, 0.1364, 0.0873, 0.9988, 0.9977, 0.8016, 0.3279, 0.0112,\n",
      "        0.0333, 0.3504, 0.0064, 0.0176, 0.9962, 0.9976, 0.0104, 0.8396, 0.0117,\n",
      "        0.0097, 0.7847, 0.6290, 0.0183, 0.6978, 0.4303, 0.5441, 0.0068, 0.0092,\n",
      "        0.1077, 0.0083, 0.9820, 0.2775, 0.0064], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2050, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2718794047832489\n",
      "5950\n",
      "tensor([0.0072, 0.9944, 0.0917, 0.0052, 0.0018, 0.0048, 0.0365, 0.2893, 0.0270,\n",
      "        0.0196, 0.0063, 0.8460, 0.9960, 0.0034, 0.2304, 0.0042, 0.9524, 0.9901,\n",
      "        0.0099, 0.0172, 0.1675, 0.0062, 0.9970, 0.9927, 0.9813, 0.9968, 0.9957,\n",
      "        0.9954, 0.9264, 0.9914, 0.9800, 0.9872], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1260, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2712949514389038\n",
      "5980\n",
      "tensor([0.0164, 0.0052, 0.0319, 0.9866, 0.4500, 0.0033, 0.0024, 0.0053, 0.8380,\n",
      "        0.0142, 0.1219, 0.2408, 0.9809, 0.8257, 0.7042, 0.9777, 0.0035, 0.0115,\n",
      "        0.0755, 0.6591, 0.8125, 0.4793, 0.0016, 0.0034, 0.9678, 0.0101, 0.0430,\n",
      "        0.0046, 0.9836, 0.9946, 0.9844, 0.9784], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1687, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2707950472831726\n",
      "6010\n",
      "tensor([0.0122, 0.8947, 0.9925, 0.0053, 0.0039, 0.0083, 0.0386, 0.9954, 0.6795,\n",
      "        0.0024, 0.6648, 0.0022, 0.0203, 0.9953, 0.9950, 0.0032, 0.0047, 0.0038,\n",
      "        0.9873, 0.9847, 0.9668, 0.0785, 0.0131, 0.5345, 0.9611, 0.9962, 0.9936,\n",
      "        0.0023, 0.9420, 0.9644, 0.9928, 0.9751], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0624, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.27035751938819885\n",
      "6040\n",
      "tensor([0.9972, 0.0150, 0.5037, 0.1122, 0.9344, 0.0032, 0.8714, 0.9189, 0.4700,\n",
      "        0.9647, 0.0330, 0.0030, 0.9922, 0.0087, 0.0055, 0.9629, 0.0041, 0.0037,\n",
      "        0.0071, 0.0053, 0.0100, 0.8284, 0.6454, 0.9972, 0.9974, 0.9924, 0.0024,\n",
      "        0.9981, 0.0148, 0.9672, 0.9980, 0.8200], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.269832581281662\n",
      "6070\n",
      "tensor([0.7337, 0.9893, 0.0352, 0.9904, 0.9953, 0.0063, 0.9973, 0.6795, 0.9955,\n",
      "        0.9654, 0.9956, 0.0029, 0.9918, 0.9975, 0.9931, 0.0035, 0.0011, 0.9951,\n",
      "        0.9976, 0.9657, 0.0023, 0.2174, 0.0024, 0.4589, 0.0013, 0.6232, 0.3410,\n",
      "        0.0087, 0.9971, 0.0057, 0.8401, 0.0213], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2442, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2692020833492279\n",
      "6100\n",
      "tensor([0.9783, 0.9351, 0.6614, 0.9977, 0.0068, 0.0395, 0.0137, 0.9700, 0.0665,\n",
      "        0.0071, 0.7661, 0.9950, 0.9960, 0.0102, 0.0104, 0.9408, 0.1032, 0.0205,\n",
      "        0.0053, 0.9810, 0.9974, 0.0071, 0.0128, 0.0136, 0.9969, 0.0760, 0.9917,\n",
      "        0.9890, 0.0117, 0.0127, 0.0237, 0.0099], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26876622438430786\n",
      "6130\n",
      "tensor([0.0038, 0.0054, 0.7027, 0.0231, 0.0066, 0.3551, 0.3118, 0.0093, 0.0065,\n",
      "        0.9788, 0.9952, 0.0103, 0.0073, 0.9953, 0.9964, 0.5974, 0.9933, 0.9974,\n",
      "        0.1048, 0.0049, 0.2065, 0.2298, 0.0202, 0.9761, 0.0049, 0.9959, 0.9940,\n",
      "        0.9922, 0.0039, 0.9173, 0.3586, 0.3525], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2784, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26826339960098267\n",
      "6160\n",
      "tensor([0.9870, 0.1844, 0.0997, 0.8794, 0.0075, 0.0305, 0.0044, 0.9945, 0.0023,\n",
      "        0.9964, 0.0212, 0.0245, 0.0122, 0.0536, 0.9755, 0.9320, 0.9532, 0.0156,\n",
      "        0.0065, 0.0103, 0.7694, 0.0042, 0.0171, 0.9006, 0.0081, 0.9925, 0.0140,\n",
      "        0.0070, 0.0121, 0.0482, 0.2600, 0.0144], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26766669750213623\n",
      "6190\n",
      "tensor([0.9622, 0.9968, 0.0125, 0.9976, 0.6049, 0.0061, 0.9924, 0.0048, 0.9890,\n",
      "        0.3641, 0.0079, 0.7328, 0.9764, 0.9829, 0.0454, 0.9937, 0.0081, 0.9957,\n",
      "        0.1311, 0.0057, 0.9389, 0.6888, 0.1837, 0.9872, 0.9866, 0.9216, 0.4449,\n",
      "        0.9949, 0.0080, 0.9953, 0.2069, 0.1140], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2721, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26727935671806335\n",
      "6220\n",
      "tensor([0.0048, 0.9620, 0.9847, 0.0063, 0.0204, 0.0110, 0.9973, 0.0067, 0.0274,\n",
      "        0.0032, 0.9897, 0.9605, 0.0114, 0.9885, 0.9953, 0.9033, 0.4536, 0.9966,\n",
      "        0.9946, 0.9336, 0.0039, 0.0772, 0.4165, 0.8890, 0.0041, 0.9038, 0.1848,\n",
      "        0.9944, 0.9683, 0.2155, 0.9926, 0.0073], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1538, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26676344871520996\n",
      "6250\n",
      "tensor([0.7368, 0.1323, 0.9946, 0.9971, 0.0020, 0.9157, 0.2708, 0.9922, 0.0648,\n",
      "        0.9856, 0.9949, 0.0083, 0.0074, 0.9887, 0.0055, 0.0274, 0.0080, 0.9807,\n",
      "        0.0034, 0.0062, 0.4586, 0.0028, 0.0076, 0.9793, 0.0570, 0.7506, 0.2594,\n",
      "        0.0040, 0.9849, 0.8927, 0.9843, 0.9955], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1142, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26634395122528076\n",
      "6280\n",
      "tensor([9.8392e-01, 9.8281e-04, 9.9582e-01, 9.9693e-01, 9.9685e-01, 9.8968e-01,\n",
      "        9.8208e-01, 1.0564e-02, 4.5945e-02, 5.1206e-02, 9.9090e-01, 5.9414e-01,\n",
      "        9.9656e-01, 2.2401e-01, 1.2078e-02, 9.1429e-03, 9.9608e-01, 6.6209e-01,\n",
      "        3.2320e-03, 2.7182e-02, 4.9843e-03, 9.5501e-01, 5.7944e-02, 9.7625e-01,\n",
      "        9.9684e-01, 9.6673e-03, 2.3527e-03, 7.6967e-02, 6.0082e-03, 9.9260e-01,\n",
      "        9.9731e-01, 9.7210e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0530, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26578155159950256\n",
      "6310\n",
      "tensor([0.9870, 0.5808, 0.9529, 0.9870, 0.4721, 0.8151, 0.0034, 0.0024, 0.9962,\n",
      "        0.9089, 0.0030, 0.8772, 0.5828, 0.0013, 0.0112, 0.0116, 0.9318, 0.9499,\n",
      "        0.0060, 0.9930, 0.0053, 0.9923, 0.9973, 0.0079, 0.9718, 0.0287, 0.0581,\n",
      "        0.9866, 0.9837, 0.0052, 0.0255, 0.0055], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2652842402458191\n",
      "6340\n",
      "tensor([0.9952, 0.9685, 0.0086, 0.0236, 0.0026, 0.9959, 0.9896, 0.8438, 0.5731,\n",
      "        0.6865, 0.0026, 0.9969, 0.9910, 0.0054, 0.9838, 0.9928, 0.3318, 0.9944,\n",
      "        0.6503, 0.9943, 0.0139, 0.9964, 0.8905, 0.0035, 0.0029, 0.0252, 0.2212,\n",
      "        0.1995, 0.0073, 0.6443, 0.9959, 0.9954], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2118, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26477643847465515\n",
      "6370\n",
      "tensor([0.9946, 0.2914, 0.9859, 0.9796, 0.9967, 0.8821, 0.0043, 0.0213, 0.0016,\n",
      "        0.9015, 0.9724, 0.9955, 0.9937, 0.0159, 0.9956, 0.0797, 0.9414, 0.9943,\n",
      "        0.3466, 0.9187, 0.0234, 0.0070, 0.1216, 0.5332, 0.0470, 0.0152, 0.0019,\n",
      "        0.0032, 0.9959, 0.0638, 0.0028, 0.9944], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0958, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26419004797935486\n",
      "6400\n",
      "tensor([0.0035, 0.9971, 0.9748, 0.9379, 0.9190, 0.9984, 0.9889, 0.9983, 0.0019,\n",
      "        0.0017, 0.9938, 0.0041, 0.1482, 0.2608, 0.0019, 0.0026, 0.1104, 0.9911,\n",
      "        0.0024, 0.0014, 0.0062, 0.9980, 0.0112, 0.9961, 0.0039, 0.0087, 0.0134,\n",
      "        0.0047, 0.2394, 0.0027, 0.0040, 0.8293], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1455, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2636721432209015\n",
      "6430\n",
      "tensor([0.0143, 0.2497, 0.9979, 0.0259, 0.0085, 0.0555, 0.6773, 0.0030, 0.9975,\n",
      "        0.0089, 0.0326, 0.6172, 0.9964, 0.7929, 0.0152, 0.0242, 0.0034, 0.9831,\n",
      "        0.9974, 0.9860, 0.9960, 0.0210, 0.9963, 0.0117, 0.0020, 0.9305, 0.8526,\n",
      "        0.9919, 0.9960, 0.5992, 0.0185, 0.9897], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26324698328971863\n",
      "6460\n",
      "tensor([0.6750, 0.9041, 0.0038, 0.0634, 0.0109, 0.0044, 0.9851, 0.9799, 0.0056,\n",
      "        0.6755, 0.0585, 0.9962, 0.0026, 0.9924, 0.9500, 0.0046, 0.0305, 0.0839,\n",
      "        0.0035, 0.0034, 0.0135, 0.9703, 0.0023, 0.9930, 0.0103, 0.0254, 0.0086,\n",
      "        0.9817, 0.7446, 0.0181, 0.9879, 0.0010], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0869, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26279768347740173\n",
      "6490\n",
      "tensor([0.0487, 0.9840, 0.0045, 0.9670, 0.0080, 0.0369, 0.8133, 0.9961, 0.0184,\n",
      "        0.9831, 0.9988, 0.9920, 0.9772, 0.0048, 0.7554, 0.0023, 0.9733, 0.4925,\n",
      "        0.0394, 0.0067, 0.0343, 0.0079, 0.0116, 0.9467, 0.9388, 0.9832, 0.0057,\n",
      "        0.9936, 0.0032, 0.0049, 0.6646, 0.0088], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1221, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2623862624168396\n",
      "6520\n",
      "tensor([0.0041, 0.0112, 0.0067, 0.2638, 0.9957, 0.9962, 0.0332, 0.9962, 0.0130,\n",
      "        0.0070, 0.7597, 0.0017, 0.3094, 0.0018, 0.9952, 0.9938, 0.9807, 0.9967,\n",
      "        0.0032, 0.5128, 0.9876, 0.0117, 0.0029, 0.9980, 0.9869, 0.0021, 0.9372,\n",
      "        0.9923, 0.9969, 0.9080, 0.0631, 0.9948], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0636, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26185545325279236\n",
      "6550\n",
      "tensor([0.0028, 0.0834, 0.7251, 0.1485, 0.9985, 0.0118, 0.9962, 0.9752, 0.8967,\n",
      "        0.8095, 0.7997, 0.5853, 0.0050, 0.9255, 0.0036, 0.9866, 0.9738, 0.9950,\n",
      "        0.9904, 0.5023, 0.0048, 0.0031, 0.0038, 0.0083, 0.9978, 0.0079, 0.9970,\n",
      "        0.0071, 0.6077, 0.5715, 0.9969, 0.7211], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1464, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2613831162452698\n",
      "6580\n",
      "tensor([0.0055, 0.8125, 0.0013, 0.9976, 0.9969, 0.2245, 0.2124, 0.0010, 0.0051,\n",
      "        0.0011, 0.9972, 0.0758, 0.9985, 0.0022, 0.0054, 0.1528, 0.9938, 0.9982,\n",
      "        0.9973, 0.0121, 0.0030, 0.9752, 0.9664, 0.9210, 0.9805, 0.9935, 0.0068,\n",
      "        0.0912, 0.9965, 0.9986, 0.3442, 0.5992], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0691, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2608955204486847\n",
      "6610\n",
      "tensor([0.0031, 0.2484, 0.9940, 0.9431, 0.9815, 0.0086, 0.0094, 0.9983, 0.0166,\n",
      "        0.0373, 0.7871, 0.9955, 0.2745, 0.9961, 0.0392, 0.0031, 0.9974, 0.9883,\n",
      "        0.9871, 0.0102, 0.9964, 0.8611, 0.7105, 0.9391, 0.9262, 0.9972, 0.0072,\n",
      "        0.9984, 0.0022, 0.2126, 0.9704, 0.0027], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0630, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.26061415672302246\n",
      "6640\n",
      "tensor([0.0503, 0.9829, 0.9721, 0.2005, 0.0014, 0.9266, 0.9962, 0.5129, 0.8918,\n",
      "        0.7808, 0.6835, 0.0537, 0.0124, 0.0092, 0.9961, 0.0308, 0.9183, 0.0602,\n",
      "        0.0031, 0.9348, 0.0017, 0.0056, 0.0049, 0.0025, 0.8843, 0.0040, 0.9964,\n",
      "        0.9897, 0.0098, 0.2820, 0.4507, 0.9636], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2603358030319214\n",
      "6670\n",
      "tensor([0.0033, 0.8676, 0.0026, 0.9934, 0.9987, 0.8648, 0.9354, 0.0036, 0.9986,\n",
      "        0.0015, 0.9963, 0.8848, 0.9973, 0.9984, 0.2550, 0.2209, 0.0068, 0.0024,\n",
      "        0.0146, 0.0014, 0.5645, 0.0010, 0.0042, 0.9194, 0.0051, 0.1566, 0.9841,\n",
      "        0.0031, 0.9980, 0.9364, 0.9652, 0.9982], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1558, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25975140929222107\n",
      "6700\n",
      "tensor([0.9916, 0.0034, 0.9697, 0.9908, 0.9562, 0.9635, 0.9975, 0.0231, 0.0062,\n",
      "        0.1639, 0.9963, 0.9931, 0.5341, 0.9965, 0.9986, 0.0074, 0.0072, 0.0187,\n",
      "        0.9478, 0.0088, 0.9820, 0.8642, 0.0055, 0.1429, 0.0056, 0.9627, 0.1107,\n",
      "        0.9859, 0.9607, 0.0027, 0.9879, 0.0021], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2595349848270416\n",
      "6730\n",
      "tensor([0.9971, 0.9363, 0.0125, 0.0054, 0.9954, 0.0839, 0.9916, 0.0389, 0.9961,\n",
      "        0.9924, 0.0020, 0.9987, 0.0234, 0.9984, 0.9829, 0.9926, 0.9757, 0.0020,\n",
      "        0.9967, 0.0025, 0.9954, 0.9937, 0.9674, 0.9962, 0.0034, 0.0019, 0.0122,\n",
      "        0.0032, 0.9963, 0.0040, 0.9931, 0.1333], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0172, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25906872749328613\n",
      "6760\n",
      "tensor([0.0098, 0.0098, 0.9957, 0.0188, 0.0052, 0.9979, 0.9351, 0.9951, 0.8752,\n",
      "        0.9968, 0.0394, 0.3556, 0.7530, 0.9958, 0.0132, 0.9983, 0.0892, 0.0094,\n",
      "        0.0073, 0.9985, 0.0048, 0.1005, 0.9968, 0.0047, 0.9962, 0.6151, 0.9947,\n",
      "        0.1029, 0.9903, 0.9693, 0.9965, 0.0134], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3683, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.258645236492157\n",
      "6790\n",
      "tensor([0.9951, 0.0513, 0.9908, 0.9992, 0.5810, 0.9027, 0.0075, 0.9982, 0.0013,\n",
      "        0.9982, 0.0035, 0.9918, 0.9374, 0.9810, 0.3699, 0.9970, 0.0702, 0.9982,\n",
      "        0.0032, 0.9824, 0.9618, 0.2630, 0.5792, 0.0035, 0.0022, 0.9938, 0.0042,\n",
      "        0.0323, 0.0056, 0.0039, 0.0030, 0.9091], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1081, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2580834925174713\n",
      "6820\n",
      "tensor([0.2878, 0.0097, 0.0010, 0.9973, 0.0241, 0.9152, 0.0041, 0.9952, 0.0228,\n",
      "        0.9947, 0.0035, 0.0980, 0.9966, 0.9468, 0.7387, 0.9900, 0.9969, 0.9482,\n",
      "        0.6494, 0.0146, 0.9936, 0.0129, 0.0031, 0.9910, 0.0198, 0.0354, 0.6951,\n",
      "        0.9941, 0.0031, 0.0043, 0.9976, 0.0073], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.5312, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25763213634490967\n",
      "6850\n",
      "tensor([0.3626, 0.0520, 0.0059, 0.0044, 0.9972, 0.9945, 0.9234, 0.9340, 0.0050,\n",
      "        0.9888, 0.9904, 0.9416, 0.9939, 0.4932, 0.0254, 0.0028, 0.9975, 0.9978,\n",
      "        0.0739, 0.0971, 0.0040, 0.0060, 0.2284, 0.0187, 0.7316, 0.9490, 0.2232,\n",
      "        0.6091, 0.6440, 0.1638, 0.0236, 0.9902], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1482, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2572331726551056\n",
      "6880\n",
      "tensor([0.9939, 0.0535, 0.9856, 0.9926, 0.9932, 0.4476, 0.9978, 0.0132, 0.0273,\n",
      "        0.9644, 0.9921, 0.2972, 0.9896, 0.0041, 0.0097, 0.9934, 0.3417, 0.9962,\n",
      "        0.0268, 0.0051, 0.1429, 0.8635, 0.0024, 0.9975, 0.8619, 0.9978, 0.2925,\n",
      "        0.0049, 0.0041, 0.9504, 0.8380, 0.0031], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2328, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2568906545639038\n",
      "6910\n",
      "tensor([0.9956, 0.0024, 0.9983, 0.0268, 0.8735, 0.8290, 0.9804, 0.0404, 0.0857,\n",
      "        0.0470, 0.0178, 0.0067, 0.0036, 0.9949, 0.9856, 0.9955, 0.0520, 0.9980,\n",
      "        0.0124, 0.8588, 0.0156, 0.0013, 0.9939, 0.1655, 0.9975, 0.9601, 0.9954,\n",
      "        0.0317, 0.0049, 0.9959, 0.9972, 0.9576], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1475, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2564111649990082\n",
      "6940\n",
      "tensor([0.9410, 0.9963, 0.9924, 0.9959, 0.0161, 0.0052, 0.0185, 0.5246, 0.9984,\n",
      "        0.0029, 0.9721, 0.9973, 0.1156, 0.6977, 0.0022, 0.4160, 0.9945, 0.0096,\n",
      "        0.9219, 0.9954, 0.0119, 0.9957, 0.0259, 0.0383, 0.0068, 0.9971, 0.0027,\n",
      "        0.9981, 0.0028, 0.0023, 0.0020, 0.9981], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0664, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25591760873794556\n",
      "6970\n",
      "tensor([0.0100, 0.9968, 0.8831, 0.9956, 0.9691, 0.9882, 0.9966, 0.9801, 0.0055,\n",
      "        0.1293, 0.0247, 0.9916, 0.9951, 0.0132, 0.3533, 0.0160, 0.9741, 0.9685,\n",
      "        0.0028, 0.0117, 0.0026, 0.0025, 0.9977, 0.9978, 0.9961, 0.0019, 0.3766,\n",
      "        0.5066, 0.9848, 0.0076, 0.0126, 0.0186], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2599, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2555537223815918\n",
      "7000\n",
      "tensor([0.9895, 0.9713, 0.9989, 0.0024, 0.0031, 0.0053, 0.0297, 0.9983, 0.2131,\n",
      "        0.9750, 0.0480, 0.0073, 0.8969, 0.9746, 0.5306, 0.9913, 0.0437, 0.1838,\n",
      "        0.0121, 0.0102, 0.8672, 0.0365, 0.0030, 0.9655, 0.9940, 0.9978, 0.1186,\n",
      "        0.9803, 0.9931, 0.0416, 0.9920, 0.0130], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0630, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2551318109035492\n",
      "7030\n",
      "tensor([0.9900, 0.0282, 0.0899, 0.7769, 0.9401, 0.2479, 0.0011, 0.9980, 0.0085,\n",
      "        0.0672, 0.9957, 0.9921, 0.9858, 0.0348, 0.0019, 0.0247, 0.0290, 0.9667,\n",
      "        0.9897, 0.9583, 0.0018, 0.0016, 0.6875, 0.9607, 0.9953, 0.0244, 0.9977,\n",
      "        0.9778, 0.0046, 0.0283, 0.0010, 0.9918], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0479, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2547311782836914\n",
      "7060\n",
      "tensor([0.0067, 0.0030, 0.9966, 0.9975, 0.9769, 0.7984, 0.8337, 0.9196, 0.9799,\n",
      "        0.9952, 0.9964, 0.9956, 0.9954, 0.0040, 0.9958, 0.9958, 0.9684, 0.0016,\n",
      "        0.2056, 0.0043, 0.9565, 0.9972, 0.0013, 0.0021, 0.9941, 0.9984, 0.9649,\n",
      "        0.0545, 0.1819, 0.9978, 0.0531, 0.0053], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25423145294189453\n",
      "7090\n",
      "tensor([0.4014, 0.4709, 0.9502, 0.2319, 0.0036, 0.0176, 0.9781, 0.0089, 0.9966,\n",
      "        0.9896, 0.9964, 0.9959, 0.9932, 0.4215, 0.0038, 0.8841, 0.9975, 0.9872,\n",
      "        0.0018, 0.9986, 0.9984, 0.0045, 0.0204, 0.9963, 0.9975, 0.0157, 0.0045,\n",
      "        0.9953, 0.0027, 0.1458, 0.9069, 0.0018], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2538513243198395\n",
      "7120\n",
      "tensor([0.9938, 0.0021, 0.0072, 0.0023, 0.0085, 0.7646, 0.9804, 0.9422, 0.0027,\n",
      "        0.9578, 0.9951, 0.2938, 0.9953, 0.9046, 0.9930, 0.0029, 0.0051, 0.0636,\n",
      "        0.0654, 0.9016, 0.0222, 0.0404, 0.9952, 0.9961, 0.9980, 0.0072, 0.6185,\n",
      "        0.9960, 0.1864, 0.9958, 0.0044, 0.0075], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0599, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25328704714775085\n",
      "7150\n",
      "tensor([0.0796, 0.1990, 0.9589, 0.0110, 0.9931, 0.0036, 0.0014, 0.8975, 0.9981,\n",
      "        0.8846, 0.0016, 0.9409, 0.0025, 0.9977, 0.6169, 0.9932, 0.0604, 0.6842,\n",
      "        0.9259, 0.0015, 0.7934, 0.0031, 0.0023, 0.9958, 0.0969, 0.0284, 0.0027,\n",
      "        0.9883, 0.9903, 0.0047, 0.9929, 0.9724], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0661, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2529033422470093\n",
      "7180\n",
      "tensor([0.1479, 0.9966, 0.9942, 0.9829, 0.0046, 0.3420, 0.9947, 0.9917, 0.9889,\n",
      "        0.9985, 0.9903, 0.9922, 0.0742, 0.0405, 0.0045, 0.0043, 0.0236, 0.0210,\n",
      "        0.9938, 0.9984, 0.9940, 0.9963, 0.0143, 0.0081, 0.9933, 0.0016, 0.9945,\n",
      "        0.0063, 0.9481, 0.0898, 0.0569, 0.9925], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25247982144355774\n",
      "7210\n",
      "tensor([0.9993, 0.9987, 0.9979, 0.1190, 0.0052, 0.9101, 0.9892, 0.9963, 0.8000,\n",
      "        0.9936, 0.0027, 0.9914, 0.9970, 0.9000, 0.0119, 0.9725, 0.0025, 0.0043,\n",
      "        0.1272, 0.8778, 0.7607, 0.9965, 0.0045, 0.9293, 0.9966, 0.9979, 0.0124,\n",
      "        0.9874, 0.0061, 0.9959, 0.5707, 0.8371], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1343, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25204139947891235\n",
      "7240\n",
      "tensor([0.6527, 0.9864, 0.0047, 0.0018, 0.0896, 0.9976, 0.1279, 0.0024, 0.0016,\n",
      "        0.0322, 0.9767, 0.8282, 0.9617, 0.0032, 0.9770, 0.9757, 0.9518, 0.9398,\n",
      "        0.0075, 0.0017, 0.0025, 0.0161, 0.9978, 0.8398, 0.1905, 0.9747, 0.0062,\n",
      "        0.0019, 0.9975, 0.7204, 0.0125, 0.0393], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0614, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25157153606414795\n",
      "7270\n",
      "tensor([8.6960e-04, 6.3244e-03, 4.0215e-03, 2.3062e-02, 9.7670e-01, 9.9633e-01,\n",
      "        5.4259e-01, 3.6316e-03, 8.9871e-01, 8.1236e-02, 3.7856e-03, 1.2608e-02,\n",
      "        9.6475e-01, 9.8282e-01, 1.1745e-01, 7.1981e-03, 3.8917e-03, 4.2828e-03,\n",
      "        1.2276e-02, 9.7187e-01, 1.7401e-02, 9.9636e-01, 1.1900e-01, 9.0590e-01,\n",
      "        4.0050e-01, 2.8970e-01, 9.9827e-01, 8.3266e-01, 2.2100e-03, 7.2473e-03,\n",
      "        4.5178e-01, 8.6367e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.251108318567276\n",
      "7300\n",
      "tensor([0.9941, 0.9864, 0.9983, 0.0029, 0.0060, 0.0912, 0.0061, 0.9943, 0.0022,\n",
      "        0.0046, 0.0065, 0.0029, 0.0201, 0.0132, 0.9938, 0.9681, 0.9546, 0.0039,\n",
      "        0.0025, 0.9982, 0.0064, 0.0989, 0.6539, 0.0076, 0.9614, 0.9946, 0.0063,\n",
      "        0.2005, 0.9782, 0.0063, 0.9524, 0.0084], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0569, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25068262219429016\n",
      "7330\n",
      "tensor([4.2890e-03, 9.7252e-01, 9.7998e-03, 7.9537e-04, 3.8552e-03, 9.9667e-01,\n",
      "        3.1818e-03, 5.9171e-03, 6.7353e-02, 3.1511e-03, 3.0236e-03, 4.8377e-01,\n",
      "        2.0069e-01, 6.5321e-01, 9.3484e-01, 7.6634e-03, 2.5564e-01, 9.9621e-01,\n",
      "        9.8981e-01, 2.8904e-03, 5.4224e-03, 6.6193e-01, 9.9707e-01, 2.3730e-03,\n",
      "        3.8616e-02, 9.6710e-01, 9.8101e-01, 4.2402e-03, 9.8096e-01, 9.5596e-01,\n",
      "        4.0076e-03, 9.1356e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1312, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.25026994943618774\n",
      "7360\n",
      "tensor([0.0528, 0.9918, 0.3747, 0.0070, 0.8335, 0.1081, 0.0021, 0.6802, 0.1850,\n",
      "        0.9876, 0.9951, 0.1467, 0.0653, 0.0290, 0.9027, 0.2894, 0.9958, 0.0110,\n",
      "        0.0020, 0.0202, 0.9968, 0.9925, 0.9952, 0.9969, 0.9863, 0.0086, 0.0910,\n",
      "        0.0052, 0.0064, 0.0041, 0.9971, 0.0430], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2545, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24992170929908752\n",
      "7390\n",
      "tensor([0.9153, 0.0484, 0.0031, 0.0066, 0.0238, 0.0121, 0.4495, 0.9973, 0.0020,\n",
      "        0.3871, 0.5499, 0.0360, 0.9944, 0.9687, 0.9780, 0.6197, 0.9883, 0.9435,\n",
      "        0.0404, 0.7300, 0.9804, 0.8472, 0.0065, 0.9568, 0.0496, 0.0050, 0.9768,\n",
      "        0.2821, 0.9911, 0.9123, 0.9974, 0.9904], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1738, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24957701563835144\n",
      "7420\n",
      "tensor([0.0169, 0.9918, 0.6297, 0.9977, 0.9518, 0.0015, 0.0039, 0.0058, 0.0023,\n",
      "        0.9124, 0.9792, 0.0118, 0.0853, 0.0041, 0.9953, 0.0018, 0.9960, 0.0086,\n",
      "        0.9952, 0.5146, 0.9982, 0.9968, 0.9773, 0.7862, 0.0028, 0.9366, 0.9966,\n",
      "        0.0033, 0.0038, 0.9977, 0.0245, 0.4089], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2052, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24906787276268005\n",
      "7450\n",
      "tensor([0.9966, 0.1201, 0.8130, 0.0181, 0.9947, 0.9911, 0.9939, 0.2230, 0.1647,\n",
      "        0.9318, 0.0242, 0.0149, 0.0029, 0.0705, 0.1314, 0.9966, 0.0308, 0.9967,\n",
      "        0.0842, 0.9854, 0.9961, 0.0256, 0.5944, 0.9908, 0.5625, 0.3981, 0.0199,\n",
      "        0.7090, 0.2722, 0.9437, 0.0216, 0.0069], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1579, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2487165480852127\n",
      "7480\n",
      "tensor([0.0718, 0.9982, 0.7244, 0.0026, 0.9972, 0.0459, 0.9321, 0.9974, 0.9987,\n",
      "        0.0039, 0.0211, 0.9985, 0.6823, 0.9984, 0.0600, 0.9965, 0.9951, 0.6910,\n",
      "        0.0047, 0.9980, 0.9751, 0.0136, 0.9973, 0.3844, 0.9231, 0.3160, 0.1332,\n",
      "        0.9973, 0.0134, 0.9990, 0.9774, 0.0202], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24826288223266602\n",
      "7510\n",
      "tensor([0.0035, 0.9913, 0.9916, 0.0068, 0.9816, 0.0622, 0.9200, 0.9961, 0.9436,\n",
      "        0.9955, 0.9965, 0.0929, 0.1716, 0.9965, 0.9555, 0.0069, 0.0569, 0.0161,\n",
      "        0.9950, 0.0026, 0.8065, 0.9991, 0.0033, 0.0633, 0.9984, 0.3175, 0.9942,\n",
      "        0.9049, 0.9984, 0.0053, 0.9974, 0.0139], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2423, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24780558049678802\n",
      "7540\n",
      "tensor([0.7509, 0.9952, 0.0013, 0.8417, 0.0123, 0.0041, 0.0042, 0.9932, 0.0019,\n",
      "        0.0279, 0.9632, 0.9628, 0.0022, 0.9616, 0.1145, 0.4639, 0.2094, 0.0023,\n",
      "        0.5339, 0.0264, 0.5735, 0.0057, 0.9784, 0.3480, 0.9317, 0.9834, 0.9694,\n",
      "        0.9941, 0.9809, 0.0123, 0.0106, 0.0466], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1748, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2475099116563797\n",
      "7570\n",
      "tensor([0.9792, 0.0036, 0.0049, 0.9988, 0.8972, 0.9965, 0.9720, 0.4452, 0.7955,\n",
      "        0.9960, 0.5012, 0.9741, 0.2242, 0.8915, 0.9957, 0.7798, 0.9099, 0.0040,\n",
      "        0.0356, 0.9987, 0.9785, 0.0042, 0.9625, 0.0650, 0.9984, 0.9948, 0.0017,\n",
      "        0.0027, 0.0097, 0.8908, 0.9743, 0.7845], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1595, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24715808033943176\n",
      "7600\n",
      "tensor([0.0988, 0.0044, 0.0173, 0.9505, 0.0026, 0.0049, 0.9853, 0.5515, 0.0351,\n",
      "        0.9975, 0.2157, 0.0087, 0.9473, 0.0675, 0.0027, 0.9811, 0.0854, 0.0035,\n",
      "        0.0023, 0.0024, 0.0027, 0.9850, 0.9920, 0.9624, 0.3747, 0.0182, 0.9980,\n",
      "        0.0027, 0.6705, 0.0041, 0.0106, 0.9893], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0944, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24675971269607544\n",
      "7630\n",
      "tensor([0.3751, 0.0018, 0.0054, 0.0029, 0.0090, 0.7136, 0.0459, 0.7162, 0.4979,\n",
      "        0.9426, 0.9445, 0.0204, 0.0212, 0.9323, 0.0017, 0.0251, 0.1238, 0.9987,\n",
      "        0.0123, 0.9080, 0.9186, 0.0071, 0.0165, 0.7626, 0.9910, 0.1945, 0.0081,\n",
      "        0.0094, 0.9778, 0.9957, 0.0024, 0.9906], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1117, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24641066789627075\n",
      "7660\n",
      "tensor([0.0255, 0.0024, 0.9341, 0.9978, 0.9933, 0.4013, 0.9976, 0.0046, 0.5803,\n",
      "        0.9905, 0.0022, 0.9979, 0.9908, 0.3760, 0.9979, 0.9974, 0.0026, 0.9982,\n",
      "        0.0148, 0.0036, 0.8972, 0.0109, 0.0042, 0.9967, 0.9957, 0.0066, 0.8725,\n",
      "        0.0567, 0.0029, 0.9987, 0.9956, 0.7366], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1609, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24608998000621796\n",
      "7690\n",
      "tensor([0.2930, 0.9955, 0.9967, 0.0313, 0.9135, 0.9963, 0.0879, 0.3205, 0.8157,\n",
      "        0.2796, 0.0017, 0.9958, 0.0054, 0.0042, 0.0177, 0.9885, 0.9981, 0.9982,\n",
      "        0.9983, 0.9882, 0.9959, 0.9985, 0.0034, 0.9895, 0.9983, 0.0090, 0.9908,\n",
      "        0.9985, 0.5029, 0.9961, 0.9977, 0.0034], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2266, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2457292228937149\n",
      "7720\n",
      "tensor([0.7488, 0.0357, 0.9694, 0.7079, 0.0157, 0.9889, 0.9944, 0.8331, 0.0033,\n",
      "        0.0034, 0.9978, 0.9934, 0.1528, 0.0039, 0.9807, 0.0027, 0.9816, 0.0031,\n",
      "        0.8327, 0.1329, 0.9967, 0.9971, 0.1053, 0.0313, 0.9989, 0.0025, 0.0056,\n",
      "        0.0035, 0.0017, 0.0044, 0.0022, 0.9984], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2219, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24541381001472473\n",
      "7750\n",
      "tensor([0.9968, 0.9977, 0.0872, 0.0041, 0.0036, 0.9979, 0.0084, 0.4917, 0.0038,\n",
      "        0.9985, 0.9986, 0.0037, 0.9965, 0.9470, 0.9929, 0.0063, 0.9987, 0.1282,\n",
      "        0.0177, 0.9986, 0.3248, 0.0050, 0.8502, 0.3948, 0.0040, 0.1487, 0.6900,\n",
      "        0.9958, 0.9487, 0.9983, 0.0324, 0.0124], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1766, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24498961865901947\n",
      "7780\n",
      "tensor([3.7265e-03, 3.8463e-03, 1.0976e-01, 6.4377e-01, 6.7380e-02, 9.9507e-01,\n",
      "        9.9781e-01, 6.1967e-03, 9.9869e-01, 2.1484e-02, 5.7252e-03, 5.4320e-01,\n",
      "        9.9151e-01, 7.4571e-03, 9.8898e-01, 8.9352e-01, 9.9790e-01, 9.3672e-01,\n",
      "        9.9476e-01, 2.0317e-03, 9.8754e-01, 3.2570e-02, 2.4393e-03, 9.9591e-01,\n",
      "        9.3859e-03, 3.8833e-02, 5.7886e-02, 2.0091e-02, 9.3357e-04, 1.5202e-02,\n",
      "        9.9837e-01, 9.9555e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0533, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24452628195285797\n",
      "7810\n",
      "tensor([0.9977, 0.9962, 0.7641, 0.4750, 0.9970, 0.0287, 0.9945, 0.2262, 0.9960,\n",
      "        0.0394, 0.1108, 0.9735, 0.9971, 0.9247, 0.9968, 0.0089, 0.9588, 0.9976,\n",
      "        0.9538, 0.0047, 0.9912, 0.2040, 0.0295, 0.0316, 0.9094, 0.8154, 0.0216,\n",
      "        0.0140, 0.9960, 0.9989, 0.9880, 0.0374], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1129, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24420054256916046\n",
      "7840\n",
      "tensor([0.0596, 0.0036, 0.7817, 0.9874, 0.9923, 0.0196, 0.2991, 0.9905, 0.9803,\n",
      "        0.9988, 0.9878, 0.0777, 0.0083, 0.9944, 0.2457, 0.9926, 0.0018, 0.9979,\n",
      "        0.9918, 0.9798, 0.0054, 0.9322, 0.0072, 0.4307, 0.9962, 0.0199, 0.5940,\n",
      "        0.9029, 0.0109, 0.9073, 0.9987, 0.9838], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1161, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24382948875427246\n",
      "7870\n",
      "tensor([0.9946, 0.0038, 0.9979, 0.8779, 0.9900, 0.0028, 0.7069, 0.0014, 0.9932,\n",
      "        0.9967, 0.9345, 0.9083, 0.9979, 0.0652, 0.0027, 0.9964, 0.0788, 0.9620,\n",
      "        0.9774, 0.9187, 0.2297, 0.9739, 0.9983, 0.9889, 0.9923, 0.9962, 0.0049,\n",
      "        0.0195, 0.0022, 0.7931, 0.9949, 0.0044], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24349026381969452\n",
      "7900\n",
      "tensor([0.6520, 0.0074, 0.9961, 0.6808, 0.9976, 0.0271, 0.0200, 0.0020, 0.0466,\n",
      "        0.0038, 0.0763, 0.9954, 0.0098, 0.0260, 0.0044, 0.5941, 0.9977, 0.0064,\n",
      "        0.0038, 0.2974, 0.9964, 0.9660, 0.5927, 0.0033, 0.0101, 0.9756, 0.9986,\n",
      "        0.0022, 0.0028, 0.0028, 0.9954, 0.9414], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3157, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2432221621274948\n",
      "7930\n",
      "tensor([0.0487, 0.9804, 0.0049, 0.9423, 0.9915, 0.9875, 0.0326, 0.0259, 0.9973,\n",
      "        0.0978, 0.0490, 0.6205, 0.9982, 0.9672, 0.9602, 0.9963, 0.9386, 0.4691,\n",
      "        0.0084, 0.0022, 0.9977, 0.1207, 0.4795, 0.9969, 0.9877, 0.9539, 0.0031,\n",
      "        0.9971, 0.0031, 0.5936, 0.0036, 0.9900], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24296504259109497\n",
      "7960\n",
      "tensor([0.0039, 0.0079, 0.9499, 0.9873, 0.0012, 0.0251, 0.0087, 0.9981, 0.9972,\n",
      "        0.9612, 0.3453, 0.0267, 0.0048, 0.0087, 0.9685, 0.0356, 0.9983, 0.9927,\n",
      "        0.1003, 0.0019, 0.0070, 0.0042, 0.0535, 0.0048, 0.9274, 0.0059, 0.0869,\n",
      "        0.0062, 0.0474, 0.0180, 0.8701, 0.0040], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0395, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24259795248508453\n",
      "7990\n",
      "tensor([9.4625e-01, 1.8039e-02, 4.5272e-03, 4.0566e-03, 9.9096e-01, 9.7026e-01,\n",
      "        9.6899e-01, 9.4808e-01, 9.9761e-01, 9.7575e-01, 9.7881e-04, 9.9878e-01,\n",
      "        9.4104e-01, 9.8078e-01, 5.7557e-02, 9.8954e-01, 1.1078e-02, 4.4178e-03,\n",
      "        9.5619e-01, 5.8788e-01, 2.2667e-03, 2.3993e-03, 2.7744e-03, 4.4085e-02,\n",
      "        4.9832e-03, 6.8863e-03, 9.8367e-01, 5.0956e-01, 6.2159e-01, 1.4140e-02,\n",
      "        9.9729e-01, 2.8349e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24217671155929565\n",
      "8020\n",
      "tensor([0.0585, 0.9989, 0.9865, 0.0662, 0.9956, 0.0135, 0.4877, 0.0473, 0.9853,\n",
      "        0.0803, 0.0307, 0.9821, 0.0807, 0.9971, 0.1329, 0.9458, 0.0084, 0.0097,\n",
      "        0.9834, 0.0294, 0.7474, 0.9984, 0.0156, 0.3927, 0.3009, 0.9950, 0.9946,\n",
      "        0.8807, 0.9980, 0.9637, 0.9536, 0.0158], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0885, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24184781312942505\n",
      "8050\n",
      "tensor([0.9974, 0.1014, 0.9985, 0.9959, 0.9940, 0.0065, 0.9959, 0.0031, 0.9986,\n",
      "        0.0722, 0.0066, 0.9775, 0.0449, 0.7360, 0.9981, 0.0045, 0.9814, 0.0013,\n",
      "        0.0041, 0.0042, 0.0196, 0.9791, 0.9986, 0.0198, 0.0054, 0.1173, 0.0467,\n",
      "        0.0159, 0.9788, 0.1308, 0.9098, 0.0748], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0701, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24144698679447174\n",
      "8080\n",
      "tensor([0.8862, 0.9967, 0.0487, 0.9852, 0.9697, 0.0076, 0.9941, 0.0020, 0.0045,\n",
      "        0.9986, 0.6406, 0.0526, 0.9983, 0.4174, 0.9910, 0.0021, 0.0262, 0.7250,\n",
      "        0.0079, 0.0186, 0.0044, 0.0188, 0.9993, 0.6414, 0.9546, 0.6571, 0.0025,\n",
      "        0.0051, 0.4157, 0.7640, 0.0038, 0.9899], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1179, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24100983142852783\n",
      "8110\n",
      "tensor([0.0058, 0.9913, 0.0293, 0.0024, 0.9978, 0.0012, 0.0127, 0.9966, 0.6408,\n",
      "        0.1235, 0.9561, 0.0129, 0.9989, 0.0027, 0.9966, 0.9934, 0.9989, 0.0023,\n",
      "        0.0068, 0.8683, 0.9989, 0.9956, 0.9980, 0.0233, 0.0113, 0.0011, 0.0180,\n",
      "        0.0523, 0.5747, 0.9976, 0.0016, 0.0027], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0576, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24058933556079865\n",
      "8140\n",
      "tensor([0.1115, 0.9981, 0.2163, 0.0934, 0.0526, 0.0218, 0.9918, 0.0313, 0.9794,\n",
      "        0.8413, 0.0033, 0.0283, 0.0057, 0.0878, 0.0422, 0.9978, 0.0047, 0.9982,\n",
      "        0.4248, 0.0179, 0.0026, 0.9977, 0.0046, 0.9938, 0.9988, 0.9970, 0.9914,\n",
      "        0.9866, 0.9977, 0.9987, 0.0022, 0.9965], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1203, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.24021443724632263\n",
      "8170\n",
      "tensor([3.8124e-02, 8.8958e-04, 3.8044e-02, 4.4829e-03, 9.0564e-01, 2.0203e-03,\n",
      "        2.0249e-03, 1.3394e-01, 8.3815e-01, 9.9701e-01, 8.4563e-03, 9.9894e-01,\n",
      "        9.8809e-01, 9.8108e-01, 9.9583e-01, 8.0133e-03, 9.9785e-01, 9.9323e-01,\n",
      "        6.5924e-02, 9.4514e-01, 9.9299e-01, 2.5071e-02, 9.9401e-01, 1.0778e-02,\n",
      "        9.9429e-01, 2.4900e-01, 5.3402e-01, 9.7279e-01, 1.0889e-03, 9.7271e-01,\n",
      "        9.9828e-01, 7.4865e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0583, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23988237977027893\n",
      "8200\n",
      "tensor([4.1262e-03, 9.9782e-01, 4.8627e-03, 3.5683e-03, 9.7662e-01, 9.1778e-02,\n",
      "        8.3562e-01, 9.4302e-01, 9.0940e-01, 1.9016e-01, 9.8302e-01, 9.8865e-01,\n",
      "        8.0230e-01, 1.7921e-02, 9.4673e-01, 9.9628e-01, 9.1758e-01, 9.2894e-01,\n",
      "        9.7112e-01, 2.2920e-03, 3.6077e-01, 7.4858e-02, 9.8088e-01, 9.8402e-01,\n",
      "        9.9402e-01, 8.7919e-03, 9.7354e-01, 9.9430e-01, 8.8179e-03, 9.3506e-04,\n",
      "        1.2483e-02, 9.6836e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0759, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23955480754375458\n",
      "8230\n",
      "tensor([0.7766, 0.8926, 0.0831, 0.5048, 0.0038, 0.0339, 0.8671, 0.9957, 0.9973,\n",
      "        0.9991, 0.3674, 0.0075, 0.0013, 0.9978, 0.9970, 0.3304, 0.0056, 0.8594,\n",
      "        0.0015, 0.9989, 0.9715, 0.0210, 0.0018, 0.0031, 0.9990, 0.0016, 0.9987,\n",
      "        0.9965, 0.2671, 0.0022, 0.0684, 0.9562], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2182, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23925688862800598\n",
      "8260\n",
      "tensor([0.9987, 0.6870, 0.9935, 0.9512, 0.9956, 0.0027, 0.2376, 0.9957, 0.0264,\n",
      "        0.0021, 0.5339, 0.9962, 0.4424, 0.9967, 0.9967, 0.0068, 0.9846, 0.0170,\n",
      "        0.9940, 0.9849, 0.9323, 0.0041, 0.0015, 0.0012, 0.0013, 0.9990, 0.9962,\n",
      "        0.0131, 0.0041, 0.9980, 0.0143, 0.0029], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2116, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23882398009300232\n",
      "8290\n",
      "tensor([0.9553, 0.1936, 0.9992, 0.9927, 0.9972, 0.9987, 0.0084, 0.0029, 0.0033,\n",
      "        0.0020, 0.9551, 0.0098, 0.9987, 0.0014, 0.0633, 0.0050, 0.0067, 0.0024,\n",
      "        0.9967, 0.0267, 0.0972, 0.6858, 0.9982, 0.0028, 0.0026, 0.9818, 0.9945,\n",
      "        0.9970, 0.9959, 0.0253, 0.9969, 0.9981], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0558, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2383643090724945\n",
      "8320\n",
      "tensor([0.9975, 0.9084, 0.9980, 0.9756, 0.9947, 0.0389, 0.9975, 0.9979, 0.0039,\n",
      "        0.9928, 0.0026, 0.6398, 0.0076, 0.3792, 0.9637, 0.9972, 0.0390, 0.0101,\n",
      "        0.1500, 0.0229, 0.0032, 0.0296, 0.9979, 0.0068, 0.9974, 0.0035, 0.0117,\n",
      "        0.8116, 0.6410, 0.0071, 0.9984, 0.1143], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2516, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.238067626953125\n",
      "8350\n",
      "tensor([7.8233e-03, 1.0606e-02, 9.9751e-01, 1.6024e-03, 9.9152e-01, 2.9003e-03,\n",
      "        1.2146e-02, 7.2949e-04, 3.6927e-02, 9.9871e-01, 9.9849e-01, 1.6083e-02,\n",
      "        9.9755e-01, 4.8491e-03, 9.9857e-01, 1.9659e-03, 2.3720e-02, 8.0105e-03,\n",
      "        9.9875e-01, 7.4291e-04, 4.7343e-03, 9.8746e-01, 9.9833e-01, 3.6317e-03,\n",
      "        1.1088e-03, 3.8002e-03, 9.9827e-01, 2.2498e-03, 2.0032e-03, 9.9749e-01,\n",
      "        1.8973e-02, 9.9743e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0064, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23760409653186798\n",
      "8380\n",
      "tensor([0.9959, 0.0771, 0.9981, 0.9993, 0.9861, 0.9182, 0.9942, 0.9988, 0.0353,\n",
      "        0.0039, 0.0029, 0.9980, 0.0436, 0.8492, 0.0029, 0.9857, 0.9711, 0.9987,\n",
      "        0.0590, 0.9990, 0.9975, 0.0309, 0.9985, 0.9983, 0.0017, 0.1614, 0.0020,\n",
      "        0.1154, 0.9989, 0.9994, 0.9894, 0.0018], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2371918112039566\n",
      "8410\n",
      "tensor([2.0671e-03, 9.9801e-01, 3.3538e-03, 4.9284e-01, 7.6144e-03, 9.9804e-01,\n",
      "        2.4880e-01, 9.9816e-01, 9.9916e-01, 9.3320e-01, 9.8785e-01, 3.5513e-03,\n",
      "        9.9815e-01, 5.2138e-01, 7.4878e-04, 1.6244e-03, 9.8548e-01, 9.9754e-01,\n",
      "        2.5029e-03, 3.0083e-03, 1.4171e-03, 9.9635e-01, 4.1232e-01, 9.9887e-01,\n",
      "        1.1044e-02, 3.7031e-02, 1.9550e-02, 1.5711e-03, 3.3634e-03, 9.9946e-01,\n",
      "        1.5991e-03, 9.9669e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23678258061408997\n",
      "8440\n",
      "tensor([0.9255, 0.2558, 0.2329, 0.0772, 0.0308, 0.4395, 0.9987, 0.9853, 0.9773,\n",
      "        0.7979, 0.0133, 0.0752, 0.3273, 0.9746, 0.3992, 0.9874, 0.6671, 0.9857,\n",
      "        0.9111, 0.9989, 0.9961, 0.9673, 0.9990, 0.6864, 0.9984, 0.7866, 0.9988,\n",
      "        0.0039, 0.9962, 0.9990, 0.9947, 0.9975], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.4158, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2364945262670517\n",
      "8470\n",
      "tensor([0.0234, 0.0013, 0.9990, 0.2792, 0.8310, 0.0019, 0.9956, 0.0043, 0.0015,\n",
      "        0.9950, 0.9229, 0.9979, 0.0439, 0.0068, 0.0162, 0.9975, 0.9882, 0.0010,\n",
      "        0.2610, 0.9775, 0.0024, 0.9991, 0.9901, 0.0080, 0.9988, 0.9979, 0.9976,\n",
      "        0.9735, 0.9902, 0.0018, 0.0031, 0.0054], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2256, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23615452647209167\n",
      "8500\n",
      "tensor([0.9947, 0.5949, 0.5907, 0.0227, 0.0318, 0.9853, 0.0052, 0.9329, 0.0073,\n",
      "        0.9783, 0.0032, 0.0197, 0.8801, 0.0114, 0.8651, 0.9449, 0.6008, 0.1148,\n",
      "        0.9961, 0.9988, 0.0083, 0.1273, 0.9987, 0.0066, 0.7546, 0.9434, 0.0802,\n",
      "        0.0313, 0.9388, 0.0026, 0.0963, 0.7012], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1283, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23583054542541504\n",
      "8530\n",
      "tensor([0.9607, 0.0014, 0.6829, 0.0077, 0.9763, 0.9811, 0.9936, 0.9955, 0.7858,\n",
      "        0.0061, 0.0062, 0.9906, 0.9673, 0.9961, 0.0013, 0.9970, 0.9976, 0.0019,\n",
      "        0.9890, 0.0173, 0.9963, 0.9970, 0.9983, 0.0046, 0.0897, 0.0030, 0.0135,\n",
      "        0.0277, 0.9989, 0.0493, 0.5772, 0.0047], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0831, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23538942635059357\n",
      "8560\n",
      "tensor([0.0051, 0.0021, 0.9886, 0.0082, 0.1569, 0.9648, 0.0030, 0.0550, 0.1569,\n",
      "        0.0026, 0.9427, 0.0403, 0.6878, 0.0055, 0.0030, 0.9972, 0.0034, 0.0070,\n",
      "        0.9986, 0.0022, 0.0062, 0.9560, 0.0039, 0.0023, 0.0055, 0.9960, 0.9936,\n",
      "        0.0109, 0.9631, 0.9989, 0.9982, 0.5583], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1398, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23501963913440704\n",
      "8590\n",
      "tensor([0.8887, 0.0586, 0.0410, 0.9940, 0.9989, 0.9667, 0.9257, 0.0218, 0.9992,\n",
      "        0.9992, 0.0285, 0.9985, 0.9970, 0.9986, 0.8654, 0.9984, 0.9987, 0.9969,\n",
      "        0.9966, 0.0619, 0.7537, 0.8979, 0.0241, 0.0022, 0.9193, 0.9977, 0.0394,\n",
      "        0.9945, 0.0022, 0.2370, 0.9987, 0.9983], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1797, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23465944826602936\n",
      "8620\n",
      "tensor([1.2580e-02, 3.9771e-03, 9.9763e-01, 1.4294e-01, 6.5768e-01, 7.7623e-03,\n",
      "        9.9307e-01, 2.9511e-03, 9.4654e-01, 9.9631e-01, 1.1959e-02, 9.9289e-01,\n",
      "        3.1768e-03, 9.9778e-01, 3.0995e-03, 9.9794e-01, 9.9822e-01, 9.7934e-01,\n",
      "        1.2640e-02, 4.5242e-01, 8.6705e-02, 9.9910e-01, 1.1128e-03, 2.8772e-02,\n",
      "        2.3115e-01, 8.0709e-04, 8.8691e-01, 9.9749e-01, 3.7812e-03, 8.4064e-03,\n",
      "        9.7749e-01, 9.9518e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23428991436958313\n",
      "8650\n",
      "tensor([0.9978, 0.9977, 0.9938, 0.9209, 0.9986, 0.0546, 0.7375, 0.1360, 0.0556,\n",
      "        0.0029, 0.9915, 0.0046, 0.0433, 0.9810, 0.9953, 0.0089, 0.9980, 0.9977,\n",
      "        0.0026, 0.0063, 0.9981, 0.2983, 0.9986, 0.9978, 0.9961, 0.9908, 0.0021,\n",
      "        0.0051, 0.9819, 0.9949, 0.0158, 0.9994], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0693, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23386834561824799\n",
      "8680\n",
      "tensor([9.9689e-01, 1.2390e-01, 1.6415e-02, 1.6383e-03, 9.9815e-01, 1.3523e-02,\n",
      "        9.6146e-01, 4.9866e-02, 4.8622e-02, 8.6431e-01, 9.9632e-01, 9.9627e-01,\n",
      "        1.0272e-02, 9.9866e-01, 9.9244e-01, 9.9740e-01, 3.6099e-01, 9.9864e-01,\n",
      "        4.7373e-01, 9.9645e-01, 9.9735e-01, 5.5413e-03, 2.6738e-03, 9.9634e-01,\n",
      "        2.5929e-03, 9.6365e-01, 1.9538e-03, 7.1522e-03, 2.6797e-03, 6.8683e-01,\n",
      "        5.4733e-03, 8.0000e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1090, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2335347980260849\n",
      "8710\n",
      "tensor([6.9612e-01, 7.6387e-03, 9.9684e-01, 9.2305e-01, 9.9846e-01, 3.7396e-03,\n",
      "        7.2748e-01, 9.9799e-01, 5.0685e-01, 7.4282e-02, 1.0110e-03, 1.1796e-03,\n",
      "        9.8587e-01, 4.2086e-03, 9.4819e-01, 9.8824e-04, 9.9808e-01, 1.3933e-02,\n",
      "        9.5779e-01, 9.7109e-01, 4.7968e-02, 9.9216e-01, 9.0809e-01, 1.3367e-03,\n",
      "        9.9866e-01, 9.9827e-01, 3.5479e-03, 9.9829e-01, 9.7333e-03, 9.6803e-01,\n",
      "        7.8500e-03, 9.9782e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1164, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2332535833120346\n",
      "8740\n",
      "tensor([0.8541, 0.0289, 0.0127, 0.0067, 0.0136, 0.9584, 0.0026, 0.2880, 0.9778,\n",
      "        0.9988, 0.1464, 0.0033, 0.0260, 0.9988, 0.9920, 0.5671, 0.0117, 0.9970,\n",
      "        0.9739, 0.9985, 0.0042, 0.9863, 0.0020, 0.4532, 0.0047, 0.9549, 0.9928,\n",
      "        0.0134, 0.0320, 0.4502, 0.9995, 0.1835], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23293082416057587\n",
      "8770\n",
      "tensor([0.0039, 0.0052, 0.9990, 0.9962, 0.9697, 0.0038, 0.9976, 0.4961, 0.9973,\n",
      "        0.0112, 0.9979, 0.9937, 0.0022, 0.0012, 0.0287, 0.9887, 0.9977, 0.0041,\n",
      "        0.0015, 0.0028, 0.7259, 0.0054, 0.9962, 0.0016, 0.9796, 0.1432, 0.9977,\n",
      "        0.9976, 0.9929, 0.0029, 0.2549, 0.0341], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2326056957244873\n",
      "8800\n",
      "tensor([9.9595e-01, 9.7175e-01, 9.8374e-01, 9.9530e-01, 8.8697e-01, 2.8453e-02,\n",
      "        9.9638e-01, 3.3384e-02, 2.5973e-03, 9.8240e-01, 1.0091e-03, 9.2640e-01,\n",
      "        5.5420e-01, 3.5571e-02, 2.8357e-02, 3.2600e-01, 5.1260e-01, 9.9850e-01,\n",
      "        9.9262e-01, 3.5630e-03, 7.1021e-03, 8.4689e-04, 3.2410e-02, 9.9895e-01,\n",
      "        1.0642e-02, 9.9647e-01, 8.2919e-01, 8.9103e-02, 4.9745e-03, 4.7564e-01,\n",
      "        8.5682e-01, 9.0370e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23227427899837494\n",
      "8830\n",
      "tensor([0.0049, 0.9982, 0.0146, 0.0143, 0.9992, 0.9991, 0.9910, 0.9987, 0.9775,\n",
      "        0.8626, 0.9951, 0.9964, 0.9590, 0.3294, 0.9993, 0.9992, 0.9993, 0.0172,\n",
      "        0.0022, 0.0022, 0.1018, 0.9924, 0.0124, 0.9988, 0.3095, 0.0074, 0.9381,\n",
      "        0.9763, 0.9971, 0.0040, 0.9989, 0.9861], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1090, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23193465173244476\n",
      "8860\n",
      "tensor([0.1549, 0.9758, 0.9953, 0.1651, 0.9914, 0.0206, 0.9950, 0.9909, 0.8246,\n",
      "        0.0088, 0.0206, 0.9988, 0.9443, 0.0081, 0.0151, 0.0013, 0.9979, 0.0026,\n",
      "        0.9770, 0.9965, 0.0028, 0.0498, 0.0260, 0.9707, 0.2899, 0.0599, 0.0368,\n",
      "        0.8525, 0.9948, 0.0068, 0.9937, 0.0442], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0479, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23166340589523315\n",
      "8890\n",
      "tensor([0.0436, 0.0025, 0.1109, 0.9370, 0.9983, 0.0010, 0.0084, 0.0153, 0.9991,\n",
      "        0.9990, 0.9146, 0.0018, 0.6705, 0.0013, 0.9992, 0.0021, 0.9986, 0.1363,\n",
      "        0.0219, 0.0024, 0.8510, 0.1858, 0.0341, 0.0059, 0.0189, 0.0012, 0.8181,\n",
      "        0.0275, 0.0036, 0.0643, 0.0379, 0.0073], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1214, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23136289417743683\n",
      "8920\n",
      "tensor([0.9368, 0.9982, 0.0244, 0.0350, 0.9350, 0.9625, 0.9959, 0.9954, 0.0148,\n",
      "        0.2645, 0.0314, 0.8160, 0.0019, 0.0024, 0.0059, 0.9933, 0.0062, 0.0048,\n",
      "        0.0167, 0.0029, 0.9260, 0.0100, 0.1884, 0.0127, 0.0804, 0.9994, 0.0035,\n",
      "        0.9981, 0.0816, 0.0075, 0.9982, 0.9859], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0423, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23114661872386932\n",
      "8950\n",
      "tensor([1.6115e-03, 1.5627e-03, 9.7044e-03, 1.8265e-03, 3.7271e-03, 1.4545e-03,\n",
      "        1.9831e-01, 9.7929e-01, 9.5594e-04, 2.2277e-03, 2.9287e-02, 5.4698e-03,\n",
      "        5.6630e-03, 9.9909e-01, 2.4334e-03, 9.9725e-01, 2.9940e-03, 9.9194e-01,\n",
      "        2.1737e-03, 8.9036e-01, 3.9127e-03, 5.0773e-03, 9.5796e-01, 9.9704e-01,\n",
      "        9.0356e-04, 6.2759e-02, 2.6692e-02, 9.9905e-01, 8.0167e-02, 1.9354e-03,\n",
      "        2.3298e-02, 6.9113e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2622, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23086434602737427\n",
      "8980\n",
      "tensor([0.0043, 0.0080, 0.9673, 0.9384, 0.0243, 0.1985, 0.9257, 0.9852, 0.9475,\n",
      "        0.9988, 0.9962, 0.8842, 0.0029, 0.3602, 0.9013, 0.9981, 0.5434, 0.9365,\n",
      "        0.0200, 0.0029, 0.0114, 0.0116, 0.0162, 0.1165, 0.9937, 0.7793, 0.0790,\n",
      "        0.0049, 0.9957, 0.6943, 0.9991, 0.0040], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23057293891906738\n",
      "9010\n",
      "tensor([0.9949, 0.9874, 0.9990, 0.8019, 0.9976, 0.0013, 0.0013, 0.0061, 0.9844,\n",
      "        0.9995, 0.0064, 0.0027, 0.0012, 0.0024, 0.0026, 0.0020, 0.1009, 0.0016,\n",
      "        0.1952, 0.9621, 0.9991, 0.0011, 0.3208, 0.9293, 0.0019, 0.9990, 0.9926,\n",
      "        0.0016, 0.0183, 0.0031, 0.9586, 0.0211], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1049, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.23024113476276398\n",
      "9040\n",
      "tensor([1.4553e-03, 2.5776e-03, 9.9709e-01, 5.8304e-02, 3.7646e-02, 1.3704e-01,\n",
      "        1.5566e-02, 2.1105e-03, 1.4032e-03, 9.9691e-01, 3.3513e-03, 8.3706e-03,\n",
      "        5.7132e-03, 7.7927e-02, 9.6742e-01, 2.3206e-03, 2.4862e-01, 9.9842e-01,\n",
      "        2.6848e-03, 8.9493e-04, 9.9051e-01, 9.9786e-01, 9.9900e-01, 6.2930e-03,\n",
      "        9.9912e-01, 1.1265e-02, 4.2795e-03, 9.9870e-01, 3.0082e-03, 3.4674e-03,\n",
      "        2.0645e-02, 9.9889e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0239, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2299288511276245\n",
      "9070\n",
      "tensor([0.9973, 0.0849, 0.9992, 0.0030, 0.2094, 0.6543, 0.9674, 0.0047, 0.9988,\n",
      "        0.0522, 0.9665, 0.9315, 0.9992, 0.9990, 0.0019, 0.0014, 0.0028, 0.0042,\n",
      "        0.0070, 0.9967, 0.0017, 0.0719, 0.0043, 0.9915, 0.9952, 0.9318, 0.0053,\n",
      "        0.0022, 0.0365, 0.8851, 0.0046, 0.9974], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22952400147914886\n",
      "9100\n",
      "tensor([0.4707, 0.9963, 0.9022, 0.9989, 0.8351, 0.9780, 0.9453, 0.9965, 0.0080,\n",
      "        0.2936, 0.3839, 0.2800, 0.9985, 0.0071, 0.9630, 0.0644, 0.9983, 0.9923,\n",
      "        0.9955, 0.0017, 0.9986, 0.0023, 0.1886, 0.0037, 0.9987, 0.9653, 0.9829,\n",
      "        0.0140, 0.9781, 0.0021, 0.9468, 0.9980], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2464, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22919176518917084\n",
      "9130\n",
      "tensor([9.6030e-01, 9.9602e-01, 1.4649e-02, 9.9457e-01, 7.5568e-01, 6.5663e-02,\n",
      "        3.5027e-02, 9.9869e-01, 6.0504e-03, 9.9555e-01, 7.6628e-03, 9.5886e-01,\n",
      "        9.9311e-01, 9.9765e-01, 9.8898e-01, 9.9803e-01, 6.3498e-01, 3.4739e-01,\n",
      "        7.8867e-04, 8.3417e-01, 5.8727e-03, 9.9730e-01, 8.5631e-01, 9.8978e-01,\n",
      "        1.5779e-02, 9.9860e-01, 9.8577e-01, 4.5626e-03, 9.9716e-01, 1.1949e-02,\n",
      "        7.2096e-01, 8.9009e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2173, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22891248762607574\n",
      "9160\n",
      "tensor([7.2118e-01, 3.1666e-03, 1.2335e-01, 9.9529e-01, 9.7278e-03, 3.2180e-01,\n",
      "        1.5172e-01, 9.9711e-01, 1.3118e-02, 7.8674e-01, 1.4034e-03, 9.9354e-01,\n",
      "        9.5332e-01, 9.9218e-01, 3.0585e-03, 1.5554e-01, 1.5415e-03, 8.5222e-03,\n",
      "        8.3174e-04, 9.9343e-01, 1.9250e-03, 8.5244e-01, 1.3018e-03, 9.9541e-01,\n",
      "        9.9571e-01, 3.1651e-01, 1.0585e-03, 9.9784e-01, 8.3966e-03, 9.9072e-01,\n",
      "        9.9678e-01, 9.1218e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2286204844713211\n",
      "9190\n",
      "tensor([9.9592e-01, 9.8324e-01, 9.1499e-04, 4.9899e-03, 9.5872e-01, 2.9901e-03,\n",
      "        2.8638e-03, 2.7738e-03, 1.7975e-03, 1.3071e-03, 1.2779e-03, 9.8282e-01,\n",
      "        4.8386e-01, 2.5633e-03, 1.3182e-03, 9.9696e-01, 5.8803e-03, 2.9188e-03,\n",
      "        8.9900e-01, 1.0423e-02, 6.4854e-03, 5.7709e-01, 9.9644e-01, 1.8236e-03,\n",
      "        3.0031e-03, 3.2024e-01, 8.9190e-01, 4.1812e-03, 1.0502e-01, 9.9626e-01,\n",
      "        9.9773e-01, 9.9715e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22834636270999908\n",
      "9220\n",
      "tensor([1.3146e-02, 5.1611e-03, 2.1374e-01, 9.9836e-01, 9.9781e-01, 3.9501e-03,\n",
      "        2.2459e-03, 2.1154e-01, 8.0877e-01, 9.8460e-01, 1.1606e-03, 9.9885e-01,\n",
      "        4.2468e-03, 9.8806e-01, 9.9890e-01, 8.9494e-04, 4.6558e-01, 9.9854e-01,\n",
      "        1.0068e-01, 3.3678e-03, 2.7349e-01, 4.4445e-03, 1.1795e-02, 9.9470e-01,\n",
      "        1.8265e-02, 9.9863e-01, 1.3057e-03, 9.8418e-01, 3.5649e-03, 9.9863e-01,\n",
      "        2.8688e-01, 9.9389e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0999, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22793543338775635\n",
      "9250\n",
      "tensor([9.9268e-01, 4.5715e-03, 1.1279e-01, 9.9708e-01, 9.9668e-01, 3.8935e-03,\n",
      "        1.5260e-01, 9.8395e-01, 8.3659e-03, 9.9837e-01, 2.2282e-02, 2.5091e-02,\n",
      "        4.6587e-01, 1.9050e-03, 3.4574e-03, 9.9865e-01, 9.9665e-01, 1.9260e-02,\n",
      "        9.9822e-01, 9.5757e-01, 4.4997e-03, 9.6605e-01, 9.7849e-01, 3.1833e-03,\n",
      "        2.9455e-02, 9.9907e-01, 1.4875e-02, 7.0731e-03, 7.4889e-04, 2.2768e-03,\n",
      "        8.2015e-01, 9.9756e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0439, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2276041954755783\n",
      "9280\n",
      "tensor([8.3613e-03, 9.6553e-01, 9.9563e-01, 9.9729e-01, 9.6414e-01, 2.6989e-03,\n",
      "        9.9513e-01, 2.5456e-03, 7.8283e-03, 2.5353e-03, 4.3890e-03, 9.5444e-01,\n",
      "        5.4374e-03, 9.3407e-01, 7.7157e-04, 1.5204e-01, 9.9722e-01, 3.0692e-03,\n",
      "        1.5821e-03, 6.4508e-01, 9.9831e-01, 2.0255e-03, 3.0029e-02, 5.3632e-02,\n",
      "        2.1109e-03, 9.3231e-01, 1.6224e-03, 2.1191e-02, 9.9814e-03, 5.8833e-02,\n",
      "        9.6932e-01, 9.8205e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2273, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2272844761610031\n",
      "9310\n",
      "tensor([0.9567, 0.0015, 0.8822, 0.9635, 0.0055, 0.0021, 0.9984, 0.0017, 0.9502,\n",
      "        0.9986, 0.0058, 0.9951, 0.0063, 0.0945, 0.2226, 0.0012, 0.9974, 0.9445,\n",
      "        0.9987, 0.9989, 0.0036, 0.0025, 0.9795, 0.0084, 0.9951, 0.3223, 0.9954,\n",
      "        0.9867, 0.0018, 0.0104, 0.0017, 0.0095], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0599, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22702926397323608\n",
      "9340\n",
      "tensor([1.0504e-02, 9.9814e-01, 9.6517e-01, 9.2015e-01, 9.9764e-01, 2.0042e-03,\n",
      "        3.7457e-03, 9.9685e-01, 9.9825e-01, 1.3413e-03, 7.5610e-01, 9.9925e-01,\n",
      "        1.9001e-03, 9.6894e-01, 1.2355e-03, 2.2544e-02, 1.4384e-03, 2.3893e-03,\n",
      "        9.9897e-01, 9.8718e-01, 1.2185e-03, 9.9891e-01, 6.3365e-03, 3.6963e-03,\n",
      "        9.3364e-01, 3.1940e-03, 9.9697e-01, 9.9485e-01, 8.8912e-04, 8.6791e-01,\n",
      "        4.0199e-03, 9.8209e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2333, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22661778330802917\n",
      "9370\n",
      "tensor([0.9980, 0.1055, 0.0040, 0.0065, 0.0010, 0.0012, 0.9960, 0.9284, 0.0215,\n",
      "        0.1066, 0.9995, 0.0133, 0.0296, 0.0024, 0.7017, 0.0844, 0.0035, 0.0103,\n",
      "        0.9907, 0.3041, 0.0021, 0.0034, 0.7548, 0.9903, 0.4462, 0.9949, 0.9553,\n",
      "        0.9410, 0.9974, 0.9922, 0.9956, 0.0025], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1023, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2263771891593933\n",
      "9400\n",
      "tensor([0.0492, 0.3248, 0.0028, 0.1296, 0.0020, 0.0020, 0.0030, 0.3769, 0.9971,\n",
      "        0.0106, 0.9950, 0.0094, 0.0027, 0.0045, 0.9545, 0.0025, 0.0013, 0.0019,\n",
      "        0.0013, 0.0032, 0.0115, 0.9932, 0.9978, 0.4877, 0.9992, 0.0023, 0.9971,\n",
      "        0.0022, 0.0049, 0.0013, 0.0659, 0.9935], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1687, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22601564228534698\n",
      "9430\n",
      "tensor([0.0073, 0.9871, 0.8575, 0.9878, 0.9888, 0.9963, 0.4510, 0.9939, 0.9994,\n",
      "        0.9775, 0.9747, 0.9983, 0.9719, 0.9362, 0.9375, 0.9901, 0.9507, 0.1616,\n",
      "        0.9917, 0.0031, 0.0029, 0.9976, 0.9952, 0.0044, 0.0013, 0.0039, 0.9982,\n",
      "        0.9919, 0.9974, 0.0024, 0.0022, 0.0016], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0469, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22564402222633362\n",
      "9460\n",
      "tensor([5.1220e-03, 9.9014e-01, 6.1728e-04, 3.3024e-03, 4.9115e-03, 1.9382e-03,\n",
      "        9.9919e-01, 3.7027e-03, 9.9262e-01, 1.9080e-03, 2.0156e-02, 9.9918e-01,\n",
      "        9.9695e-01, 9.9722e-01, 9.9906e-01, 2.0625e-01, 9.9831e-01, 9.9883e-01,\n",
      "        8.2184e-01, 9.9195e-01, 9.9455e-01, 2.0404e-03, 7.1016e-04, 3.6523e-03,\n",
      "        9.9681e-01, 9.9870e-01, 9.4716e-01, 2.2709e-03, 9.9774e-01, 9.9832e-01,\n",
      "        9.9673e-01, 9.9660e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0184, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22527478635311127\n",
      "9490\n",
      "tensor([1.6451e-01, 9.8762e-01, 9.9424e-01, 9.9905e-01, 7.7897e-03, 1.2207e-03,\n",
      "        9.9931e-01, 9.7223e-01, 9.0333e-01, 9.9171e-01, 2.2784e-03, 3.6464e-03,\n",
      "        3.6741e-01, 1.4785e-03, 9.9065e-01, 2.8842e-03, 1.2295e-03, 9.5357e-01,\n",
      "        2.0033e-02, 6.9021e-04, 7.2618e-03, 3.8062e-03, 9.2624e-01, 9.4624e-01,\n",
      "        9.9912e-01, 1.5691e-02, 3.4712e-03, 9.9886e-01, 3.8950e-03, 9.9266e-01,\n",
      "        9.9867e-01, 9.9830e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22494715452194214\n",
      "9520\n",
      "tensor([0.9979, 0.9992, 0.0336, 0.9802, 0.9956, 0.0799, 0.6624, 0.0074, 0.5138,\n",
      "        0.9988, 0.0016, 0.0639, 0.0249, 0.9710, 0.0989, 0.9994, 0.0021, 0.0076,\n",
      "        0.1805, 0.1504, 0.9342, 0.1351, 0.0075, 0.9185, 0.9976, 0.9981, 0.9972,\n",
      "        0.0057, 0.0053, 0.9889, 0.0070, 0.0053], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22463931143283844\n",
      "9550\n",
      "tensor([0.0220, 0.0082, 0.0030, 0.9906, 0.4411, 0.9904, 0.0037, 0.0023, 0.0037,\n",
      "        0.1070, 0.9971, 0.9977, 0.9646, 0.9964, 0.0042, 0.8102, 0.0390, 0.0061,\n",
      "        0.9130, 0.9975, 0.9968, 0.9420, 0.9609, 0.0031, 0.9979, 0.9903, 0.0012,\n",
      "        0.9407, 0.9982, 0.9963, 0.9990, 0.2293], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22430065274238586\n",
      "9580\n",
      "tensor([0.9602, 0.9830, 0.0011, 0.9989, 0.9893, 0.9249, 0.0643, 0.9992, 0.9975,\n",
      "        0.9798, 0.9739, 0.6525, 0.4907, 0.0023, 0.4469, 0.9952, 0.9097, 0.9989,\n",
      "        0.9874, 0.9901, 0.9985, 0.9692, 0.9970, 0.0024, 0.0645, 0.9907, 0.1096,\n",
      "        0.9987, 0.0050, 0.9845, 0.0309, 0.0024], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2239753007888794\n",
      "9610\n",
      "tensor([0.9970, 0.9984, 0.9985, 0.0365, 0.9973, 0.9957, 0.0017, 0.9786, 0.9921,\n",
      "        0.9993, 0.0019, 0.0012, 0.0066, 0.9848, 0.8980, 0.1041, 0.9156, 0.9990,\n",
      "        0.9989, 0.9986, 0.9731, 0.0076, 0.0034, 0.9985, 0.9857, 0.9968, 0.0014,\n",
      "        0.9933, 0.8312, 0.9907, 0.2383, 0.9988], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0660, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22358448803424835\n",
      "9640\n",
      "tensor([4.6952e-02, 6.2722e-02, 1.1132e-01, 2.7564e-03, 9.9824e-01, 6.3057e-01,\n",
      "        1.1608e-01, 4.0003e-03, 9.0805e-02, 1.0933e-03, 9.9906e-01, 1.4205e-02,\n",
      "        9.9908e-01, 8.7149e-03, 9.9804e-01, 9.9561e-01, 8.0381e-04, 3.9784e-03,\n",
      "        9.9775e-01, 9.6935e-01, 3.6634e-03, 4.5803e-01, 9.4648e-01, 1.8574e-03,\n",
      "        9.9952e-01, 2.7680e-02, 5.3660e-02, 9.9780e-01, 8.1524e-02, 9.1150e-01,\n",
      "        1.5561e-02, 2.2206e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1510, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2232978343963623\n",
      "9670\n",
      "tensor([9.9917e-01, 4.4862e-03, 9.9933e-01, 6.8273e-03, 2.3333e-03, 1.1106e-03,\n",
      "        2.2859e-01, 9.9807e-01, 9.9779e-01, 9.8493e-01, 6.4991e-02, 9.2258e-01,\n",
      "        8.5785e-01, 9.6997e-01, 9.9821e-01, 9.3243e-03, 9.9673e-01, 1.5206e-01,\n",
      "        9.9698e-01, 5.2713e-01, 9.2774e-04, 9.9673e-01, 9.5830e-01, 3.7765e-02,\n",
      "        9.9729e-01, 3.5724e-02, 5.2036e-01, 1.6971e-01, 9.0246e-01, 5.0784e-01,\n",
      "        4.3983e-03, 9.9815e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2292, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22298386693000793\n",
      "9700\n",
      "tensor([0.0821, 0.0098, 0.0553, 0.9948, 0.9938, 0.9977, 0.8455, 0.9947, 0.9958,\n",
      "        0.5515, 0.9973, 0.9931, 0.8185, 0.0090, 0.9936, 0.0044, 0.0194, 0.9971,\n",
      "        0.9893, 0.0025, 0.0041, 0.9951, 0.0099, 0.9086, 0.0028, 0.0063, 0.9936,\n",
      "        0.1391, 0.0133, 0.0109, 0.9948, 0.0279], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0482, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2227148711681366\n",
      "9730\n",
      "tensor([0.9841, 0.9654, 0.0054, 0.0029, 0.0212, 0.4958, 0.9912, 0.0057, 0.9632,\n",
      "        0.1374, 0.9974, 0.0019, 0.9972, 0.9688, 0.3563, 0.0071, 0.9889, 0.9672,\n",
      "        0.0157, 0.9963, 0.4075, 0.9851, 0.0030, 0.9947, 0.0296, 0.0025, 0.0011,\n",
      "        0.9978, 0.9911, 0.0351, 0.0057, 0.0079], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0674, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2224147468805313\n",
      "9760\n",
      "tensor([0.0066, 0.0702, 0.0168, 0.8657, 0.9756, 0.6138, 0.0011, 0.9983, 0.9986,\n",
      "        0.9985, 0.0346, 0.0032, 0.0015, 0.0016, 0.0060, 0.0017, 0.0012, 0.9988,\n",
      "        0.0018, 0.0034, 0.0011, 0.9342, 0.0071, 0.9988, 0.9860, 0.0031, 0.0014,\n",
      "        0.0053, 0.0036, 0.9942, 0.9989, 0.0030], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0291, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2220982313156128\n",
      "9790\n",
      "tensor([0.9985, 0.0084, 0.0043, 0.9984, 0.1795, 0.5801, 0.0058, 0.8052, 0.9842,\n",
      "        0.9315, 0.0015, 0.9988, 0.9992, 0.5154, 0.0085, 0.0019, 0.0028, 0.9814,\n",
      "        0.0014, 0.0350, 0.0047, 0.9665, 0.0031, 0.0214, 0.0072, 0.9945, 0.0074,\n",
      "        0.9971, 0.0105, 0.0032, 0.0139, 0.0056], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0620, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.221791073679924\n",
      "9820\n",
      "tensor([9.7820e-01, 4.4917e-02, 9.9855e-01, 9.9602e-01, 9.9862e-01, 9.9707e-01,\n",
      "        3.7355e-03, 9.9529e-01, 2.8377e-01, 8.1712e-03, 9.9805e-01, 2.2504e-02,\n",
      "        7.3359e-01, 1.9500e-03, 5.9672e-02, 9.9809e-01, 9.9890e-01, 1.7738e-02,\n",
      "        3.9320e-03, 2.3077e-03, 1.2446e-03, 9.9506e-01, 5.3929e-03, 1.8535e-03,\n",
      "        1.8749e-02, 9.4028e-04, 1.0262e-02, 3.3886e-01, 9.9710e-01, 9.9699e-01,\n",
      "        9.9848e-01, 7.0807e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0644, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2214670181274414\n",
      "9850\n",
      "tensor([9.9894e-01, 6.5074e-01, 9.9668e-01, 1.5977e-03, 2.0485e-02, 7.4949e-01,\n",
      "        3.6776e-03, 9.7660e-01, 9.9291e-01, 9.8463e-01, 5.1238e-03, 9.9564e-01,\n",
      "        1.0590e-02, 8.1132e-04, 9.9801e-01, 1.0303e-03, 9.9466e-01, 9.9883e-01,\n",
      "        1.5001e-01, 9.7439e-01, 9.9774e-01, 9.9601e-01, 1.8690e-02, 1.0089e-02,\n",
      "        9.9186e-01, 7.8328e-02, 8.4831e-02, 6.0551e-03, 9.2395e-02, 9.9907e-01,\n",
      "        1.9542e-02, 2.7549e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0423, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2211456447839737\n",
      "9880\n",
      "tensor([5.4513e-03, 9.9663e-01, 9.9828e-01, 9.9208e-01, 9.7314e-01, 7.6695e-01,\n",
      "        9.0510e-01, 5.5373e-03, 3.4619e-02, 9.9912e-01, 1.2670e-02, 9.7015e-01,\n",
      "        8.9851e-04, 9.9830e-01, 2.8615e-03, 9.1506e-03, 7.6291e-01, 1.2724e-01,\n",
      "        9.4504e-01, 9.9078e-01, 9.9830e-01, 1.9743e-03, 9.9168e-01, 9.8217e-01,\n",
      "        9.9376e-01, 1.5353e-03, 8.3256e-02, 1.5741e-03, 6.0510e-03, 1.3879e-03,\n",
      "        8.0139e-01, 3.9082e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0792, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22088037431240082\n",
      "9910\n",
      "tensor([0.9880, 0.0192, 0.9985, 0.1062, 0.0133, 0.9761, 0.0013, 0.9970, 0.9941,\n",
      "        0.9924, 0.9975, 0.8974, 0.9949, 0.9891, 0.0014, 0.0165, 0.0012, 0.0022,\n",
      "        0.8177, 0.0044, 0.0017, 0.0071, 0.9982, 0.0559, 0.9001, 0.0011, 0.9988,\n",
      "        0.0078, 0.1256, 0.0119, 0.2392, 0.0056], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1801, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22055965662002563\n",
      "9940\n",
      "tensor([2.1909e-02, 7.8644e-01, 1.5813e-03, 3.1730e-01, 1.7782e-03, 9.9803e-01,\n",
      "        9.5724e-01, 9.9888e-01, 9.9750e-01, 7.2188e-01, 6.0814e-01, 2.3690e-01,\n",
      "        1.2253e-03, 4.3929e-03, 6.7629e-04, 8.7832e-02, 9.9297e-01, 6.9357e-01,\n",
      "        1.8390e-03, 9.7161e-01, 1.9621e-02, 9.7924e-01, 6.5464e-02, 1.5980e-03,\n",
      "        1.5541e-02, 9.5992e-02, 3.0254e-01, 1.6720e-02, 9.9743e-01, 9.9788e-01,\n",
      "        9.3089e-01, 9.4757e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2618, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22032727301120758\n",
      "9970\n",
      "tensor([8.4277e-01, 2.3359e-02, 9.3941e-01, 3.0873e-02, 4.5617e-03, 2.4164e-02,\n",
      "        1.6963e-02, 7.8956e-02, 6.8521e-04, 9.9653e-01, 1.6414e-02, 9.7494e-01,\n",
      "        9.5257e-01, 4.4645e-01, 3.7778e-04, 9.9143e-01, 8.4468e-03, 1.7284e-03,\n",
      "        6.3263e-03, 8.8727e-01, 9.9786e-01, 2.1479e-03, 3.0410e-02, 8.6551e-01,\n",
      "        1.4689e-01, 4.7416e-02, 1.1943e-03, 9.9439e-01, 4.4966e-03, 9.1389e-01,\n",
      "        5.8048e-01, 9.9772e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1671, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.22005707025527954\n",
      "10000\n",
      "tensor([2.5337e-03, 9.9647e-01, 9.9352e-01, 9.9924e-01, 5.6598e-01, 1.0931e-03,\n",
      "        2.0976e-03, 1.2948e-03, 1.8911e-03, 7.1713e-03, 9.9729e-01, 9.9432e-01,\n",
      "        9.9890e-01, 7.4404e-02, 6.7664e-01, 3.2695e-03, 9.9804e-01, 9.9403e-01,\n",
      "        8.7581e-01, 9.9949e-01, 9.9806e-01, 1.3780e-03, 1.5386e-01, 9.9655e-01,\n",
      "        3.0815e-03, 9.4244e-04, 9.9671e-01, 9.9412e-01, 8.0159e-01, 9.9517e-01,\n",
      "        9.9048e-01, 6.7182e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0534, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21975108981132507\n",
      "10030\n",
      "tensor([1.3001e-03, 8.6096e-02, 1.7871e-03, 9.9749e-01, 2.4482e-01, 9.9731e-01,\n",
      "        9.9926e-01, 1.0460e-01, 8.5639e-02, 9.9649e-01, 8.2467e-01, 8.4331e-01,\n",
      "        9.1060e-01, 2.4409e-01, 9.9581e-01, 1.6817e-02, 7.6576e-04, 9.9293e-01,\n",
      "        9.4829e-01, 8.6569e-04, 7.5746e-03, 9.9769e-01, 9.9941e-01, 3.8235e-02,\n",
      "        9.7624e-01, 9.9875e-01, 8.0608e-04, 1.2476e-02, 1.0346e-03, 9.9247e-01,\n",
      "        2.7337e-01, 2.2370e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1095, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21944525837898254\n",
      "10060\n",
      "tensor([9.9368e-04, 9.9640e-01, 9.9120e-01, 9.9484e-01, 7.3084e-02, 9.9769e-01,\n",
      "        7.0788e-03, 9.9904e-01, 8.7986e-02, 1.5064e-03, 9.8806e-01, 9.9738e-01,\n",
      "        2.7319e-02, 1.0904e-03, 9.9967e-01, 1.5207e-03, 9.9783e-01, 6.7476e-01,\n",
      "        9.9823e-01, 2.9694e-01, 2.0351e-03, 9.9887e-01, 6.3616e-02, 1.1494e-03,\n",
      "        2.3362e-03, 1.3264e-03, 8.0969e-01, 9.9416e-01, 9.9910e-01, 9.9903e-01,\n",
      "        9.1849e-01, 9.9900e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21913589537143707\n",
      "10090\n",
      "tensor([9.9406e-01, 8.7571e-01, 9.9826e-01, 2.2097e-03, 5.0308e-04, 3.6399e-01,\n",
      "        9.9592e-01, 9.9569e-01, 9.9753e-01, 7.2072e-03, 1.8059e-03, 9.9830e-01,\n",
      "        3.4652e-02, 1.6677e-02, 7.9411e-01, 2.4046e-03, 9.7219e-01, 2.2494e-03,\n",
      "        3.3952e-02, 9.9870e-01, 8.8724e-01, 2.2060e-02, 8.8696e-03, 9.0895e-01,\n",
      "        7.8024e-01, 5.8195e-01, 1.4536e-01, 7.3441e-03, 9.9695e-01, 9.8131e-01,\n",
      "        3.7552e-02, 1.2007e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.4526, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21889184415340424\n",
      "10120\n",
      "tensor([4.3728e-03, 1.3857e-02, 2.4046e-02, 9.9596e-01, 2.0983e-01, 9.9864e-01,\n",
      "        9.9474e-01, 5.6938e-02, 9.8659e-01, 1.6511e-03, 9.9452e-01, 1.6720e-01,\n",
      "        9.8892e-04, 9.8307e-01, 9.9950e-01, 9.9872e-01, 3.3334e-03, 8.7822e-01,\n",
      "        6.9921e-02, 9.9441e-01, 6.3320e-01, 9.9546e-01, 9.0317e-02, 2.1137e-02,\n",
      "        9.9926e-01, 9.9796e-01, 2.5810e-02, 9.7409e-01, 9.9633e-01, 9.9750e-01,\n",
      "        9.9725e-01, 1.1178e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1477, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2186328023672104\n",
      "10150\n",
      "tensor([9.9905e-01, 1.3064e-03, 9.9844e-01, 1.8897e-03, 5.0593e-02, 9.7998e-01,\n",
      "        9.9729e-01, 8.0804e-01, 9.8924e-01, 9.9852e-01, 9.9921e-01, 9.9956e-01,\n",
      "        1.7180e-03, 2.8214e-03, 9.9603e-01, 9.9472e-01, 1.3611e-02, 5.9848e-03,\n",
      "        9.9844e-01, 1.0685e-03, 9.9462e-01, 9.9796e-01, 9.6342e-02, 1.3651e-01,\n",
      "        9.9044e-01, 3.5802e-02, 8.3655e-01, 6.9851e-04, 9.9880e-01, 1.7784e-03,\n",
      "        9.6200e-01, 1.9448e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0271, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21825970709323883\n",
      "10180\n",
      "tensor([9.2888e-01, 1.0507e-02, 2.4423e-03, 1.9426e-02, 9.9913e-01, 1.0995e-03,\n",
      "        2.1267e-03, 9.8461e-01, 1.5151e-03, 9.9425e-01, 1.5283e-03, 5.2514e-02,\n",
      "        9.4992e-04, 2.3583e-03, 2.1048e-03, 4.1155e-03, 1.8707e-03, 9.7686e-01,\n",
      "        1.6376e-01, 9.9899e-01, 9.6344e-01, 1.9642e-02, 9.9597e-01, 3.7813e-03,\n",
      "        9.9786e-01, 9.9775e-01, 1.4717e-03, 2.8335e-02, 9.9723e-01, 9.9875e-01,\n",
      "        9.9646e-01, 5.6433e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0161, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2178959995508194\n",
      "10210\n",
      "tensor([0.0068, 0.0010, 0.0094, 0.9992, 0.0012, 0.9953, 0.9047, 0.0015, 0.0333,\n",
      "        0.0014, 0.9981, 0.0120, 0.0015, 0.1199, 0.9984, 0.9040, 0.0023, 0.0537,\n",
      "        0.8909, 0.9979, 0.0341, 0.9970, 0.0128, 0.5566, 0.9971, 0.0169, 0.9883,\n",
      "        0.0013, 0.0866, 0.9974, 0.0017, 0.0046], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0422, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21766217052936554\n",
      "10240\n",
      "tensor([9.9437e-01, 8.8113e-01, 2.5469e-03, 9.9868e-01, 4.6703e-03, 6.2229e-01,\n",
      "        8.9137e-04, 6.6774e-02, 5.7893e-01, 9.9945e-01, 9.9921e-01, 3.2899e-02,\n",
      "        9.9929e-01, 9.8185e-02, 5.1956e-02, 1.5352e-03, 9.9874e-01, 9.9252e-01,\n",
      "        2.2103e-03, 9.9917e-01, 1.0711e-03, 2.2501e-03, 8.8126e-03, 9.9243e-01,\n",
      "        1.6269e-02, 9.9861e-01, 7.6539e-03, 9.8930e-01, 9.9936e-01, 8.4796e-01,\n",
      "        2.9553e-03, 2.4987e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1584, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21731452643871307\n",
      "10270\n",
      "tensor([8.6368e-04, 9.9588e-01, 9.9945e-01, 1.2389e-02, 9.8020e-01, 6.1312e-02,\n",
      "        9.9884e-01, 9.4028e-01, 1.5268e-03, 1.1183e-03, 6.0066e-04, 7.4309e-03,\n",
      "        9.9758e-01, 4.4078e-03, 9.9763e-01, 1.3880e-03, 5.7256e-03, 1.3720e-03,\n",
      "        7.4574e-01, 7.6368e-03, 9.9867e-01, 5.7139e-03, 9.9897e-01, 9.9896e-01,\n",
      "        9.9022e-01, 9.9723e-01, 9.9823e-01, 9.9772e-01, 9.9318e-01, 9.8102e-01,\n",
      "        1.9498e-03, 2.3084e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0253, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21698220074176788\n",
      "10300\n",
      "tensor([7.1895e-03, 7.6982e-04, 9.1775e-01, 9.9920e-01, 9.7540e-01, 9.9939e-01,\n",
      "        9.9836e-01, 9.9833e-01, 9.9955e-01, 1.0742e-03, 9.9884e-01, 1.2225e-03,\n",
      "        9.9746e-01, 1.0830e-03, 9.9811e-01, 2.4288e-03, 9.4296e-01, 6.2420e-03,\n",
      "        8.5102e-04, 3.1616e-03, 8.7670e-04, 8.5024e-04, 9.9743e-01, 3.4602e-04,\n",
      "        3.1565e-02, 9.9932e-01, 9.9629e-01, 8.8754e-04, 5.0323e-04, 1.8603e-03,\n",
      "        9.5981e-01, 6.5154e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0093, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21660450100898743\n",
      "10330\n",
      "tensor([0.3781, 0.9996, 0.0389, 0.9836, 0.0016, 0.0031, 0.9993, 0.0011, 0.0054,\n",
      "        0.0037, 0.9988, 0.8787, 0.9384, 0.5895, 0.9986, 0.0082, 0.0018, 0.0030,\n",
      "        0.9995, 0.0020, 0.9909, 0.9578, 0.4495, 0.0207, 0.9254, 0.0133, 0.0513,\n",
      "        0.9990, 0.9247, 0.9979, 0.9516, 0.9839], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21633902192115784\n",
      "10360\n",
      "tensor([4.5178e-04, 9.9780e-01, 9.6225e-01, 7.3606e-01, 1.2595e-03, 9.9905e-01,\n",
      "        9.9877e-01, 9.9709e-01, 9.9826e-01, 9.9903e-01, 9.9931e-01, 1.1968e-01,\n",
      "        4.4396e-01, 9.9926e-01, 5.2687e-03, 9.9882e-01, 9.9775e-01, 1.0896e-01,\n",
      "        9.9916e-01, 9.7758e-01, 9.8491e-01, 1.1701e-02, 2.7615e-03, 9.9616e-01,\n",
      "        2.6401e-03, 9.9818e-01, 3.8728e-04, 1.5782e-01, 2.0519e-01, 9.4663e-01,\n",
      "        6.6078e-04, 7.6722e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1437, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2160572111606598\n",
      "10390\n",
      "tensor([4.9863e-01, 4.4064e-04, 3.9955e-03, 1.7184e-02, 1.6456e-03, 9.6832e-01,\n",
      "        9.9341e-01, 9.9584e-01, 1.2803e-02, 1.9789e-03, 9.9535e-01, 1.8629e-02,\n",
      "        2.0958e-03, 9.7613e-01, 8.7160e-01, 9.9363e-01, 1.5259e-03, 1.3028e-03,\n",
      "        9.7381e-01, 9.8572e-01, 2.2848e-03, 3.8039e-03, 9.9762e-01, 9.9491e-01,\n",
      "        9.7311e-01, 1.5216e-03, 9.9835e-01, 6.5521e-03, 9.6969e-01, 9.9176e-01,\n",
      "        9.9870e-01, 9.3859e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1630, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21569135785102844\n",
      "10420\n",
      "tensor([9.8939e-01, 8.8067e-01, 9.9321e-01, 9.9797e-01, 9.8727e-01, 1.3086e-02,\n",
      "        6.2055e-03, 1.1140e-01, 9.9851e-01, 9.8846e-01, 2.3559e-01, 3.4395e-03,\n",
      "        2.7880e-03, 8.6066e-02, 7.6671e-04, 9.6315e-01, 7.9703e-01, 1.3726e-03,\n",
      "        9.9830e-01, 9.9904e-01, 1.7197e-03, 9.5166e-01, 9.9929e-01, 2.9561e-03,\n",
      "        9.7727e-01, 9.0998e-02, 2.6537e-03, 2.6229e-03, 3.2245e-03, 5.7613e-04,\n",
      "        3.6893e-03, 9.9853e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0721, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21533669531345367\n",
      "10450\n",
      "tensor([0.9983, 0.8946, 0.9984, 0.0023, 0.0021, 0.9960, 0.0011, 0.0932, 0.9980,\n",
      "        0.9843, 0.0063, 0.9962, 0.8880, 0.9987, 0.0036, 0.9973, 0.0091, 0.9972,\n",
      "        0.9930, 0.9540, 0.4230, 0.0017, 0.9986, 0.0022, 0.9764, 0.9875, 0.9682,\n",
      "        0.1090, 0.9988, 0.1571, 0.0055, 0.0645], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3778, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21509866416454315\n",
      "10480\n",
      "tensor([5.6218e-02, 9.9892e-01, 2.7456e-03, 2.9978e-03, 9.9924e-01, 4.1987e-03,\n",
      "        4.6284e-02, 7.0545e-04, 7.9803e-04, 9.7684e-01, 4.8584e-03, 1.2553e-03,\n",
      "        9.2561e-01, 9.4021e-01, 9.9899e-01, 1.4190e-01, 1.5584e-02, 9.9904e-01,\n",
      "        2.3821e-03, 9.9961e-01, 2.8075e-03, 9.9747e-01, 9.9876e-01, 9.6772e-01,\n",
      "        9.9790e-01, 9.9548e-01, 9.9884e-01, 9.9958e-01, 6.5722e-03, 9.9507e-01,\n",
      "        2.6406e-03, 9.5043e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2653, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2147798091173172\n",
      "10510\n",
      "tensor([1.6863e-03, 8.2071e-02, 1.6575e-02, 9.9942e-01, 9.9941e-01, 1.9124e-03,\n",
      "        9.9901e-01, 9.9890e-01, 2.2741e-03, 2.6037e-02, 2.6650e-02, 1.4895e-02,\n",
      "        9.9650e-01, 6.8038e-03, 9.8994e-01, 9.7036e-01, 1.6749e-02, 9.7832e-01,\n",
      "        4.7259e-02, 2.2356e-01, 2.3699e-03, 9.9936e-01, 9.0226e-04, 9.8897e-01,\n",
      "        9.9903e-01, 5.3273e-02, 1.1858e-03, 9.8424e-01, 9.9582e-01, 9.9806e-01,\n",
      "        1.2075e-03, 9.9757e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0598, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21447241306304932\n",
      "10540\n",
      "tensor([9.8245e-01, 2.3406e-03, 9.9930e-01, 9.9849e-01, 9.9868e-01, 1.5584e-03,\n",
      "        3.8160e-03, 1.0996e-02, 9.9762e-01, 9.9945e-01, 1.1430e-03, 2.2857e-03,\n",
      "        1.8349e-03, 9.9849e-01, 1.6124e-02, 1.4002e-03, 7.6676e-01, 2.6048e-02,\n",
      "        7.5552e-01, 2.2197e-03, 9.8669e-01, 3.0800e-03, 9.9615e-01, 1.7115e-02,\n",
      "        3.0945e-03, 9.9738e-01, 5.3328e-02, 9.9732e-01, 7.7904e-01, 1.1793e-03,\n",
      "        6.7621e-04, 3.6115e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3718, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2141740620136261\n",
      "10570\n",
      "tensor([0.9035, 0.9925, 0.0061, 0.9779, 0.0205, 0.9985, 0.9665, 0.9973, 0.5536,\n",
      "        0.9982, 0.0049, 0.0021, 0.9904, 0.9976, 0.0797, 0.9991, 0.0031, 0.9978,\n",
      "        0.9946, 0.9753, 0.9992, 0.9687, 0.1307, 0.9989, 0.9985, 0.9965, 0.2190,\n",
      "        0.0014, 0.0052, 0.8568, 0.9982, 0.9883], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0478, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21386903524398804\n",
      "10600\n",
      "tensor([2.1204e-03, 7.3494e-03, 4.7805e-02, 2.1349e-02, 9.0423e-01, 3.5329e-03,\n",
      "        9.9908e-01, 9.3702e-01, 9.9821e-01, 9.9922e-01, 9.7842e-04, 3.2653e-01,\n",
      "        8.6787e-01, 1.5176e-03, 9.6067e-01, 5.8556e-01, 5.9724e-01, 9.9901e-01,\n",
      "        9.9681e-01, 9.9712e-01, 5.2568e-01, 1.5022e-02, 9.9878e-01, 2.3284e-02,\n",
      "        3.8478e-03, 3.3892e-03, 2.4084e-03, 5.4920e-03, 9.9152e-01, 8.1405e-01,\n",
      "        3.4032e-02, 5.3441e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21359699964523315\n",
      "10630\n",
      "tensor([8.6802e-01, 1.2342e-03, 4.8237e-04, 8.7905e-03, 9.6006e-01, 1.7055e-03,\n",
      "        1.8616e-02, 2.4240e-02, 1.0113e-02, 8.8417e-03, 2.0264e-03, 6.8417e-03,\n",
      "        1.0109e-03, 9.9856e-01, 9.9865e-01, 9.9956e-01, 9.6438e-01, 9.3227e-02,\n",
      "        9.9898e-01, 8.7397e-01, 8.8767e-04, 9.9722e-01, 2.1491e-01, 1.5411e-01,\n",
      "        1.0131e-03, 9.9693e-01, 9.5638e-01, 1.5120e-03, 9.9788e-01, 9.9046e-01,\n",
      "        2.7696e-03, 9.9798e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0319, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21330951154232025\n",
      "10660\n",
      "tensor([9.9912e-01, 9.9645e-01, 4.7814e-03, 3.7114e-03, 9.7598e-01, 1.2561e-02,\n",
      "        2.2778e-03, 4.7417e-02, 9.6666e-01, 9.9889e-01, 9.9894e-01, 9.9853e-01,\n",
      "        1.8735e-02, 9.9699e-01, 2.7000e-03, 5.1831e-02, 4.5673e-01, 8.4921e-01,\n",
      "        8.5354e-02, 2.4625e-01, 9.8838e-01, 2.1979e-03, 9.7543e-02, 9.5911e-04,\n",
      "        2.5521e-03, 9.6379e-02, 9.8655e-01, 7.4911e-02, 9.9648e-01, 3.6992e-03,\n",
      "        3.3083e-03, 8.8187e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1618, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21302536129951477\n",
      "10690\n",
      "tensor([9.9903e-01, 8.6369e-01, 1.2344e-03, 3.7829e-03, 9.9907e-01, 2.6306e-03,\n",
      "        9.9231e-01, 9.6942e-01, 3.8176e-03, 7.0966e-04, 1.0747e-02, 3.7220e-03,\n",
      "        9.4880e-01, 1.3409e-03, 4.9595e-01, 8.3171e-03, 9.4040e-02, 9.0258e-03,\n",
      "        2.0419e-03, 3.0179e-03, 2.3307e-03, 9.6595e-01, 1.2712e-02, 9.9239e-01,\n",
      "        9.9921e-01, 5.7102e-01, 9.9755e-01, 1.3237e-01, 9.9869e-01, 9.9643e-01,\n",
      "        2.8815e-01, 9.9929e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0682, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21271993219852448\n",
      "10720\n",
      "tensor([6.2560e-04, 1.2851e-03, 1.7392e-03, 9.9598e-01, 1.0689e-03, 9.9501e-01,\n",
      "        1.7285e-03, 9.2907e-01, 9.9913e-01, 7.1540e-03, 2.1001e-03, 9.9640e-01,\n",
      "        3.7290e-02, 5.8818e-03, 9.9645e-01, 9.9661e-01, 6.4620e-01, 1.7987e-03,\n",
      "        9.9853e-01, 1.3117e-03, 2.9806e-01, 4.9069e-03, 9.9593e-01, 2.2822e-01,\n",
      "        9.9901e-01, 1.6323e-03, 9.5933e-01, 9.8771e-01, 1.5200e-03, 2.3072e-03,\n",
      "        5.1142e-02, 9.4017e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0604, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21239618957042694\n",
      "10750\n",
      "tensor([8.5424e-01, 2.8300e-03, 1.3122e-03, 6.5291e-04, 9.9883e-01, 1.2557e-03,\n",
      "        9.9886e-01, 7.3686e-03, 5.1929e-03, 9.9812e-01, 5.2200e-02, 9.8666e-01,\n",
      "        9.9627e-01, 1.6373e-02, 9.9936e-01, 9.4528e-01, 4.0473e-03, 9.8198e-01,\n",
      "        1.5731e-03, 9.9831e-01, 9.9940e-01, 1.7959e-01, 4.6238e-01, 2.4346e-02,\n",
      "        9.8390e-01, 9.9860e-01, 4.7008e-04, 1.9810e-03, 9.5707e-01, 9.9136e-01,\n",
      "        9.9697e-01, 9.9549e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0398, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21209581196308136\n",
      "10780\n",
      "tensor([2.0253e-03, 1.1444e-03, 1.0103e-02, 9.9306e-01, 9.9802e-01, 9.9915e-01,\n",
      "        1.3798e-03, 1.4212e-02, 9.9348e-01, 9.2469e-01, 9.9940e-01, 1.0114e-03,\n",
      "        9.9715e-01, 9.7055e-04, 9.9933e-01, 9.9625e-01, 9.9931e-01, 9.9955e-01,\n",
      "        9.9936e-01, 5.0820e-03, 9.9638e-01, 1.3380e-03, 1.0618e-03, 4.0961e-01,\n",
      "        1.0231e-03, 1.5940e-03, 5.9953e-02, 9.9966e-01, 9.9842e-01, 9.9807e-01,\n",
      "        9.9833e-01, 5.7398e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1016, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21181730926036835\n",
      "10810\n",
      "tensor([9.9934e-01, 9.7608e-01, 2.9419e-03, 9.9945e-01, 9.9929e-01, 2.2640e-03,\n",
      "        9.9727e-01, 9.9951e-01, 1.4708e-01, 6.9417e-04, 9.9898e-01, 9.9183e-01,\n",
      "        9.9658e-01, 4.4175e-01, 9.9181e-01, 7.5465e-04, 4.2953e-03, 3.6587e-03,\n",
      "        4.6270e-03, 2.4375e-02, 9.9769e-01, 2.3247e-03, 9.9320e-01, 9.9901e-01,\n",
      "        6.6517e-03, 9.9846e-01, 2.6445e-03, 7.5420e-03, 9.9844e-01, 9.9591e-01,\n",
      "        2.0924e-03, 9.9837e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0347, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21152712404727936\n",
      "10840\n",
      "tensor([9.9799e-01, 2.6694e-03, 9.9805e-01, 9.9805e-01, 1.7619e-03, 9.9658e-01,\n",
      "        9.8263e-04, 9.7351e-01, 9.9525e-01, 7.4030e-04, 2.7195e-03, 9.9351e-01,\n",
      "        1.1212e-03, 9.9876e-01, 5.5631e-01, 9.9955e-01, 5.2915e-01, 4.7152e-02,\n",
      "        8.8401e-04, 9.9880e-01, 9.9911e-01, 1.5628e-03, 8.8657e-04, 9.9947e-01,\n",
      "        1.2179e-03, 9.9731e-01, 6.9125e-01, 5.8399e-03, 3.0177e-01, 1.0061e-03,\n",
      "        8.8362e-04, 1.1368e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21126748621463776\n",
      "10870\n",
      "tensor([1.9215e-02, 9.7903e-01, 6.0998e-02, 1.4682e-03, 3.3222e-03, 5.4725e-02,\n",
      "        2.2444e-03, 9.9853e-01, 1.7816e-03, 8.3578e-01, 7.7949e-01, 9.9513e-01,\n",
      "        9.9903e-01, 8.0455e-01, 9.5818e-01, 9.8204e-01, 1.6120e-01, 9.9779e-01,\n",
      "        9.9595e-01, 1.8453e-01, 9.9737e-01, 2.2919e-03, 1.6580e-03, 4.7452e-02,\n",
      "        8.4736e-04, 9.9261e-01, 1.6887e-03, 9.9932e-01, 9.9078e-01, 8.1806e-04,\n",
      "        1.0080e-03, 1.2159e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0929, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2110178917646408\n",
      "10900\n",
      "tensor([1.1946e-02, 9.3490e-04, 9.9914e-01, 1.6150e-02, 4.4612e-01, 9.9785e-01,\n",
      "        3.1828e-01, 9.8453e-01, 1.7191e-03, 1.8507e-03, 1.1301e-03, 8.3209e-01,\n",
      "        9.9914e-01, 9.8444e-01, 7.0896e-01, 1.5972e-03, 8.1991e-04, 9.9129e-01,\n",
      "        9.9682e-01, 1.2526e-03, 5.8921e-01, 4.2722e-01, 1.2500e-03, 9.9742e-01,\n",
      "        8.1660e-04, 3.6617e-03, 1.0947e-03, 5.3868e-04, 9.8846e-01, 9.9844e-01,\n",
      "        1.6895e-03, 2.5437e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1262, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21068264544010162\n",
      "10930\n",
      "tensor([1.0376e-03, 9.9548e-01, 9.7066e-03, 9.8229e-01, 9.2343e-01, 4.7469e-04,\n",
      "        6.9788e-04, 5.6418e-04, 7.0894e-03, 9.7315e-01, 8.6443e-01, 8.5779e-04,\n",
      "        9.9208e-01, 9.9940e-01, 9.7782e-01, 9.3265e-03, 1.6915e-03, 8.6916e-01,\n",
      "        9.9921e-01, 4.0186e-03, 9.9948e-01, 2.6239e-02, 5.4117e-01, 3.7050e-03,\n",
      "        6.9894e-01, 9.1272e-01, 2.0386e-02, 9.9939e-01, 8.9414e-02, 1.9768e-03,\n",
      "        3.8784e-01, 9.9923e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21043147146701813\n",
      "10960\n",
      "tensor([1.1067e-03, 2.0265e-03, 7.4374e-03, 1.0613e-01, 9.6184e-01, 9.9777e-01,\n",
      "        4.1635e-04, 9.9685e-01, 9.9635e-01, 9.5071e-01, 9.9669e-01, 3.1461e-03,\n",
      "        6.2100e-04, 3.4206e-01, 3.3812e-03, 7.7291e-02, 2.4292e-03, 1.2150e-02,\n",
      "        1.6080e-03, 1.1422e-02, 7.8808e-04, 9.9831e-01, 9.9922e-01, 3.0481e-02,\n",
      "        1.0656e-03, 1.3372e-03, 3.1300e-02, 6.6611e-04, 1.8742e-02, 1.1049e-03,\n",
      "        9.9953e-01, 1.5202e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0266, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.21011236310005188\n",
      "10990\n",
      "tensor([9.0519e-02, 8.4602e-03, 9.9894e-01, 1.3530e-03, 1.5669e-03, 9.9689e-01,\n",
      "        1.2702e-01, 1.3622e-03, 3.1779e-01, 1.0224e-03, 1.4220e-03, 2.4282e-03,\n",
      "        1.8850e-01, 9.9817e-01, 9.7549e-01, 8.3435e-01, 2.1831e-03, 1.4473e-03,\n",
      "        9.9915e-01, 2.1147e-03, 7.8362e-03, 7.6729e-03, 1.4621e-02, 2.3568e-01,\n",
      "        9.9848e-01, 1.5548e-03, 1.2464e-03, 9.9664e-01, 7.4243e-02, 9.9884e-01,\n",
      "        6.7929e-04, 5.5016e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0701, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20988105237483978\n",
      "11020\n",
      "tensor([1.2982e-02, 9.9826e-01, 2.6189e-01, 3.7022e-03, 1.1277e-02, 9.9913e-01,\n",
      "        1.7940e-03, 9.1857e-01, 9.9278e-01, 5.8994e-02, 1.5076e-03, 4.5998e-02,\n",
      "        9.9111e-01, 9.9920e-01, 9.4930e-01, 4.3556e-02, 9.9792e-01, 9.9911e-01,\n",
      "        1.7772e-03, 8.3865e-04, 1.3607e-03, 9.9862e-01, 1.8677e-03, 9.3749e-03,\n",
      "        1.1626e-03, 9.7285e-01, 2.9741e-03, 1.1747e-02, 4.2738e-01, 9.9826e-01,\n",
      "        2.4065e-03, 8.2492e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0548, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20961089432239532\n",
      "11050\n",
      "tensor([0.9965, 0.0019, 0.9918, 0.0033, 0.0466, 0.9495, 0.0128, 0.9909, 0.0254,\n",
      "        0.9982, 0.9934, 0.0015, 0.9985, 0.9977, 0.9980, 0.9988, 0.9990, 0.4367,\n",
      "        0.0021, 0.9942, 0.0163, 0.9968, 0.0017, 0.0013, 0.9982, 0.0015, 0.3225,\n",
      "        0.9996, 0.9983, 0.9974, 0.2907, 0.0207], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0716, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2093185931444168\n",
      "11080\n",
      "tensor([9.6927e-01, 9.9470e-01, 9.7352e-01, 9.9911e-01, 9.7428e-04, 1.9115e-01,\n",
      "        9.9856e-01, 9.3142e-04, 8.9950e-04, 9.8463e-01, 9.9856e-01, 1.5053e-03,\n",
      "        9.8243e-01, 9.7764e-01, 2.3248e-02, 1.5579e-02, 9.9396e-01, 1.6608e-03,\n",
      "        1.8399e-03, 1.3108e-02, 1.8928e-02, 2.4001e-03, 1.0879e-03, 3.9606e-03,\n",
      "        3.5315e-03, 2.0809e-03, 3.8004e-03, 1.4011e-01, 9.9099e-01, 1.5437e-01,\n",
      "        6.3710e-03, 1.5223e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1941, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20906110107898712\n",
      "11110\n",
      "tensor([3.5936e-02, 9.9940e-01, 9.9772e-01, 9.9881e-01, 4.7185e-02, 1.4780e-03,\n",
      "        8.2148e-03, 9.9465e-01, 9.9698e-01, 9.4137e-04, 9.9857e-01, 6.5513e-03,\n",
      "        9.9643e-01, 1.6491e-03, 9.8897e-04, 1.4062e-03, 9.9776e-01, 9.8936e-01,\n",
      "        3.5413e-03, 9.9897e-01, 9.8771e-01, 2.4667e-03, 9.2742e-04, 3.5885e-02,\n",
      "        9.9841e-03, 9.9914e-01, 9.9963e-01, 9.9835e-01, 2.7028e-03, 1.2251e-03,\n",
      "        9.9883e-01, 9.7163e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20870661735534668\n",
      "11140\n",
      "tensor([0.0478, 0.7149, 0.0031, 0.0302, 0.0031, 0.0112, 0.0066, 0.9954, 0.0011,\n",
      "        0.3641, 0.0024, 0.0156, 0.2081, 0.0060, 0.9973, 0.9889, 0.9979, 0.9641,\n",
      "        0.9983, 0.9967, 0.7701, 0.0410, 0.0019, 0.9918, 0.9995, 0.0011, 0.9995,\n",
      "        0.0060, 0.9921, 0.0063, 0.0034, 0.0062], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0487, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20844946801662445\n",
      "11170\n",
      "tensor([9.9856e-01, 9.9651e-01, 2.7307e-03, 1.4269e-03, 3.6456e-03, 8.5882e-02,\n",
      "        2.7450e-03, 1.6155e-02, 9.9825e-01, 4.2966e-02, 9.4948e-03, 4.4078e-03,\n",
      "        9.9503e-01, 8.0984e-03, 1.9888e-03, 7.0776e-01, 3.2067e-03, 5.7519e-01,\n",
      "        9.9955e-01, 1.1319e-02, 2.4343e-03, 1.4103e-03, 9.9287e-01, 9.6399e-01,\n",
      "        3.6577e-03, 9.9188e-01, 9.9907e-01, 2.5119e-02, 5.1268e-03, 8.4887e-04,\n",
      "        9.9884e-01, 9.3205e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2421, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20815932750701904\n",
      "11200\n",
      "tensor([0.0068, 0.9993, 0.9836, 0.9961, 0.9967, 0.9880, 0.9989, 0.9971, 0.9969,\n",
      "        0.5540, 0.9992, 0.0050, 0.9989, 0.9996, 0.0055, 0.0408, 0.9995, 0.9992,\n",
      "        0.9928, 0.0455, 0.0102, 0.9968, 0.9944, 0.9997, 0.9950, 0.0018, 0.0026,\n",
      "        0.9882, 0.0405, 0.9875, 0.0065, 0.9993], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2078801989555359\n",
      "11230\n",
      "tensor([0.0052, 0.9988, 0.0037, 0.0036, 0.9991, 0.2979, 0.9989, 0.0091, 0.9984,\n",
      "        0.0017, 0.9936, 0.9955, 0.9878, 0.9995, 0.0107, 0.0021, 0.8671, 0.0020,\n",
      "        0.0026, 0.9991, 0.9975, 0.9911, 0.9988, 0.9786, 0.8833, 0.0050, 0.9962,\n",
      "        0.0041, 0.8837, 0.9992, 0.9927, 0.0181], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2075749635696411\n",
      "11260\n",
      "tensor([4.3389e-03, 1.9232e-03, 7.4452e-04, 4.6487e-03, 9.8371e-01, 2.7949e-03,\n",
      "        5.3514e-03, 9.6475e-01, 1.9165e-03, 6.0632e-02, 3.1266e-03, 9.9255e-01,\n",
      "        1.6931e-02, 9.9589e-01, 2.5188e-03, 5.4347e-03, 9.7100e-01, 6.1076e-02,\n",
      "        8.8765e-04, 9.3607e-01, 1.4133e-03, 9.9938e-01, 7.8926e-01, 9.9918e-01,\n",
      "        9.9911e-01, 9.9765e-01, 9.9945e-01, 2.6716e-02, 9.9905e-01, 1.1221e-03,\n",
      "        3.2774e-03, 9.7213e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0200, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20732304453849792\n",
      "11290\n",
      "tensor([3.3548e-02, 3.1648e-03, 2.3533e-03, 9.9761e-01, 9.9913e-01, 4.9032e-03,\n",
      "        6.5389e-03, 2.0138e-01, 1.2993e-01, 9.9081e-01, 9.6423e-01, 1.3824e-03,\n",
      "        9.9878e-01, 2.8579e-01, 4.6620e-02, 8.9835e-01, 7.3778e-02, 3.5288e-02,\n",
      "        3.3237e-03, 9.9665e-01, 9.9872e-01, 9.8840e-04, 1.4840e-02, 4.1215e-03,\n",
      "        9.9291e-01, 1.4104e-03, 5.0332e-01, 4.8374e-02, 7.9969e-03, 9.7578e-01,\n",
      "        9.9630e-01, 9.9763e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0592, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2070973664522171\n",
      "11320\n",
      "tensor([0.0832, 0.0037, 0.9988, 0.9980, 0.0040, 0.2076, 0.0265, 0.9900, 0.0034,\n",
      "        0.1952, 0.0040, 0.0388, 0.9979, 0.0051, 0.2190, 0.9250, 0.0199, 0.2654,\n",
      "        0.0017, 0.9971, 0.9749, 0.0127, 0.0088, 0.0034, 0.1482, 0.1859, 0.0034,\n",
      "        0.0198, 0.9924, 0.0119, 0.0020, 0.0024], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0993, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20688031613826752\n",
      "11350\n",
      "tensor([0.9933, 0.0323, 0.0603, 0.0023, 0.9978, 0.0037, 0.0016, 0.9920, 0.7872,\n",
      "        0.0029, 0.9979, 0.9551, 0.7578, 0.0120, 0.9950, 0.0020, 0.9910, 0.0089,\n",
      "        0.0078, 0.0045, 0.0072, 0.9978, 0.0031, 0.2047, 0.4748, 0.0044, 0.9963,\n",
      "        0.0050, 0.9905, 0.0269, 0.6835, 0.0161], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0647, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2066154181957245\n",
      "11380\n",
      "tensor([0.0290, 0.7746, 0.0152, 0.0112, 0.9992, 0.9984, 0.0021, 0.5150, 0.9957,\n",
      "        0.9751, 0.7055, 0.9824, 0.0063, 0.9929, 0.0071, 0.0215, 0.9982, 0.9954,\n",
      "        0.0274, 0.9964, 0.4415, 0.0077, 0.1503, 0.9985, 0.9979, 0.0022, 0.9969,\n",
      "        0.9576, 0.9991, 0.0284, 0.0360, 0.0142], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20639000833034515\n",
      "11410\n",
      "tensor([9.9937e-01, 3.5113e-03, 9.7164e-03, 1.4258e-02, 9.7234e-01, 9.8561e-01,\n",
      "        9.9945e-01, 7.6852e-04, 9.6293e-01, 9.9332e-01, 7.3765e-02, 3.0746e-03,\n",
      "        9.8729e-01, 9.9860e-01, 9.9368e-01, 2.0340e-02, 2.3402e-03, 9.7481e-01,\n",
      "        4.9317e-02, 2.2497e-03, 9.9930e-01, 9.6304e-01, 1.7834e-02, 9.9948e-01,\n",
      "        1.7322e-03, 2.3062e-02, 8.2233e-01, 9.9923e-01, 2.4260e-01, 1.2092e-02,\n",
      "        5.9411e-03, 9.9923e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1549, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.2060984969139099\n",
      "11440\n",
      "tensor([9.8251e-04, 9.9919e-01, 9.9854e-01, 9.9752e-01, 9.6932e-01, 9.9813e-01,\n",
      "        2.4028e-03, 6.8251e-03, 3.5392e-03, 1.5098e-03, 9.8305e-01, 1.7749e-03,\n",
      "        7.0001e-02, 9.9815e-01, 9.8940e-01, 6.2142e-03, 9.9959e-01, 4.0840e-03,\n",
      "        9.9810e-01, 1.5813e-03, 9.9789e-01, 1.6106e-01, 9.9233e-01, 9.7973e-01,\n",
      "        2.3224e-01, 9.9485e-01, 2.6814e-02, 3.4642e-03, 9.9719e-01, 7.2202e-02,\n",
      "        9.9526e-01, 8.5094e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2130, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20581240952014923\n",
      "11470\n",
      "tensor([9.9782e-01, 1.4774e-03, 2.2674e-02, 9.3107e-01, 1.2461e-03, 9.9482e-01,\n",
      "        9.9304e-01, 9.9827e-01, 9.9846e-01, 9.9767e-01, 2.7986e-03, 1.1931e-02,\n",
      "        9.4226e-01, 3.8067e-02, 9.9923e-01, 1.0771e-03, 1.7434e-02, 6.9778e-04,\n",
      "        4.0555e-03, 8.2633e-03, 9.9944e-01, 9.8621e-01, 4.7860e-02, 9.9785e-01,\n",
      "        9.9878e-01, 1.6849e-01, 4.5532e-03, 9.9795e-01, 3.6705e-03, 9.8800e-01,\n",
      "        2.0221e-03, 1.2282e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0169, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.20555204153060913\n",
      "EPOCH\n",
      "10\n",
      "tensor([0.2640, 0.0013, 0.8417, 0.9772, 0.0078, 0.0444, 0.9955, 0.9563, 0.0458,\n",
      "        0.9966, 0.0014, 0.0757, 0.9779, 0.0034, 0.8796, 0.0053, 0.9588, 0.9954,\n",
      "        0.0017, 0.7250, 0.7165, 0.9953, 0.8325, 0.9788, 0.0527, 0.0139, 0.0018,\n",
      "        0.9913, 0.0362, 0.0015, 0.9847, 0.8017], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0676, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06671860814094543\n",
      "40\n",
      "tensor([1.3617e-03, 1.5421e-03, 1.0064e-01, 9.9872e-01, 9.9800e-01, 9.9861e-01,\n",
      "        4.4719e-02, 5.8953e-03, 1.6302e-03, 4.9167e-03, 9.9884e-01, 2.6026e-03,\n",
      "        9.9713e-01, 9.9453e-01, 9.5754e-01, 9.9520e-01, 1.3709e-03, 9.8908e-01,\n",
      "        9.9003e-01, 9.9804e-01, 1.7419e-03, 6.8726e-01, 1.3507e-03, 5.0938e-04,\n",
      "        9.9445e-01, 1.6877e-03, 6.9073e-01, 3.2219e-02, 9.9214e-01, 9.9698e-01,\n",
      "        6.1839e-04, 9.9310e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0332, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0756986141204834\n",
      "70\n",
      "tensor([2.6589e-03, 6.3570e-03, 9.9255e-01, 9.9381e-01, 7.6562e-01, 1.6202e-03,\n",
      "        9.9895e-01, 1.3641e-03, 9.9744e-01, 3.8430e-03, 1.7910e-03, 9.9816e-01,\n",
      "        9.9707e-01, 9.9852e-01, 9.9800e-01, 9.8861e-04, 4.3600e-01, 9.9162e-01,\n",
      "        1.8608e-02, 7.6591e-03, 9.7146e-01, 1.9798e-01, 3.2732e-03, 2.2070e-03,\n",
      "        9.9904e-01, 9.9843e-01, 9.9798e-01, 9.7232e-01, 4.4563e-03, 8.9266e-01,\n",
      "        9.9923e-01, 2.1548e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1077, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.07503155618906021\n",
      "100\n",
      "tensor([3.0903e-03, 1.0064e-03, 6.5733e-04, 3.2409e-03, 9.9738e-01, 9.8424e-01,\n",
      "        1.8591e-03, 2.1078e-03, 8.6586e-03, 9.9817e-01, 9.8065e-01, 2.2185e-01,\n",
      "        9.9096e-01, 6.9285e-03, 9.6542e-01, 9.6124e-01, 4.4449e-02, 9.9875e-01,\n",
      "        9.4359e-01, 9.9777e-01, 1.0071e-03, 9.9780e-01, 1.3949e-03, 8.5001e-01,\n",
      "        9.9578e-01, 9.9812e-01, 4.2251e-03, 9.9703e-01, 9.8890e-04, 3.7574e-03,\n",
      "        7.5063e-02, 2.2076e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0784, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0767151415348053\n",
      "130\n",
      "tensor([7.2714e-04, 9.9603e-01, 1.9141e-03, 9.9764e-01, 9.9494e-01, 9.9842e-01,\n",
      "        9.9815e-01, 3.4354e-03, 9.9645e-01, 9.9647e-01, 9.9470e-01, 6.2489e-03,\n",
      "        9.9831e-01, 9.9362e-01, 9.9088e-01, 4.0894e-01, 1.3538e-03, 1.1630e-03,\n",
      "        1.8385e-03, 5.8456e-02, 1.0002e-03, 9.9768e-01, 2.5266e-02, 9.8580e-01,\n",
      "        9.9894e-01, 2.1037e-02, 9.9824e-01, 9.9660e-01, 3.6128e-02, 7.9942e-04,\n",
      "        8.0924e-04, 4.3583e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2248, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0734294056892395\n",
      "160\n",
      "tensor([4.8047e-03, 9.9216e-01, 9.9936e-01, 3.2234e-03, 1.0224e-02, 9.9624e-01,\n",
      "        1.3031e-03, 8.9309e-04, 1.3111e-02, 9.1633e-04, 9.9435e-01, 7.2874e-01,\n",
      "        1.5215e-03, 7.0830e-03, 1.8119e-01, 3.7930e-04, 1.0915e-03, 9.0322e-01,\n",
      "        1.1100e-03, 1.1269e-03, 4.7273e-03, 2.6308e-02, 9.9160e-01, 9.9907e-01,\n",
      "        2.8443e-02, 9.9716e-01, 9.1745e-04, 4.4894e-03, 8.0448e-04, 2.0571e-03,\n",
      "        9.9891e-01, 8.8692e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0277, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.07303249090909958\n",
      "190\n",
      "tensor([1.1968e-03, 7.7772e-04, 1.3339e-03, 5.0339e-04, 9.9850e-01, 6.4029e-03,\n",
      "        3.0811e-03, 9.8107e-01, 4.8167e-04, 9.4686e-04, 3.7162e-03, 9.9916e-01,\n",
      "        4.0439e-04, 6.7347e-04, 3.8486e-03, 2.9256e-03, 2.6252e-03, 7.8513e-04,\n",
      "        1.8324e-02, 3.2920e-02, 9.3726e-01, 9.9813e-01, 9.9912e-01, 1.2578e-03,\n",
      "        9.9944e-01, 9.9668e-01, 9.4464e-03, 9.9806e-01, 1.3241e-02, 1.4116e-01,\n",
      "        1.3857e-03, 1.1026e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0111, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.07029476761817932\n",
      "220\n",
      "tensor([1.3939e-01, 9.9882e-01, 9.9844e-01, 9.9872e-01, 3.2720e-03, 9.9091e-01,\n",
      "        1.7857e-02, 1.2497e-03, 3.4149e-01, 6.0438e-03, 9.9552e-01, 9.9849e-01,\n",
      "        9.9887e-01, 9.9892e-01, 9.9944e-01, 2.9608e-02, 2.1766e-02, 9.9685e-01,\n",
      "        9.4325e-01, 9.9872e-01, 9.7687e-01, 6.5889e-04, 2.7397e-03, 9.8300e-01,\n",
      "        9.8066e-01, 8.6494e-04, 9.9451e-01, 9.9142e-01, 9.8529e-01, 2.7207e-03,\n",
      "        9.9620e-01, 9.9904e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0261, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0699986144900322\n",
      "250\n",
      "tensor([1.1047e-03, 2.0004e-03, 4.0161e-02, 1.4111e-03, 1.7971e-03, 9.9932e-01,\n",
      "        9.9122e-01, 9.9884e-01, 9.9968e-01, 9.8809e-01, 9.9834e-01, 7.6017e-04,\n",
      "        9.9291e-01, 1.6066e-03, 2.0321e-03, 1.1576e-03, 9.9785e-01, 6.6201e-04,\n",
      "        4.7257e-03, 9.9953e-01, 9.9826e-01, 1.9369e-03, 7.1533e-04, 1.1435e-01,\n",
      "        9.9084e-04, 9.9272e-01, 4.8415e-04, 9.9883e-01, 9.9952e-01, 9.8756e-01,\n",
      "        1.0618e-03, 5.1025e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2337, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06831002980470657\n",
      "280\n",
      "tensor([9.9578e-01, 9.9775e-01, 9.8026e-01, 9.9659e-01, 1.0916e-03, 1.7596e-03,\n",
      "        1.6420e-03, 1.4586e-02, 2.9335e-03, 9.9896e-01, 9.9864e-01, 5.3646e-04,\n",
      "        8.8996e-04, 9.9825e-01, 7.9318e-03, 1.9671e-03, 9.5272e-04, 9.9915e-01,\n",
      "        8.2665e-04, 9.9943e-01, 2.3226e-02, 9.9685e-01, 2.4585e-03, 9.9638e-01,\n",
      "        9.7223e-01, 9.9948e-01, 9.9879e-01, 2.4334e-03, 9.9895e-01, 9.9934e-01,\n",
      "        9.9780e-01, 7.9967e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06682246923446655\n",
      "310\n",
      "tensor([8.0804e-03, 1.4793e-03, 8.2990e-04, 4.9145e-03, 5.5934e-02, 9.9812e-01,\n",
      "        2.5262e-03, 1.3001e-01, 9.9960e-01, 1.3884e-03, 9.9864e-01, 9.9930e-01,\n",
      "        1.0681e-03, 9.9599e-01, 9.9940e-01, 2.6531e-02, 9.9073e-01, 9.9748e-01,\n",
      "        9.9772e-01, 1.8270e-01, 8.4437e-04, 4.4207e-04, 9.9945e-01, 2.8075e-03,\n",
      "        9.9800e-01, 1.8934e-03, 9.9413e-01, 8.2679e-04, 3.2680e-04, 3.8338e-04,\n",
      "        2.3085e-03, 9.6571e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0163, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0664544403553009\n",
      "340\n",
      "tensor([1.0946e-03, 9.3111e-01, 3.5252e-03, 9.9925e-01, 1.4799e-03, 4.5410e-03,\n",
      "        9.9960e-01, 3.6175e-03, 9.9902e-01, 9.9925e-01, 5.9516e-04, 1.0703e-03,\n",
      "        9.9892e-01, 9.9942e-01, 9.9900e-01, 9.9744e-01, 8.5182e-01, 7.4656e-04,\n",
      "        3.2996e-03, 1.5862e-03, 1.5783e-03, 9.9586e-01, 9.9877e-01, 9.9905e-01,\n",
      "        9.3367e-01, 1.0467e-02, 9.9577e-01, 9.9816e-01, 1.4410e-03, 9.9632e-01,\n",
      "        9.9739e-01, 4.8529e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06788022071123123\n",
      "370\n",
      "tensor([2.0216e-03, 1.2905e-02, 9.9919e-01, 7.1465e-03, 9.9049e-01, 1.2885e-02,\n",
      "        2.3382e-01, 9.5967e-01, 2.7835e-02, 2.6624e-01, 1.0754e-02, 1.2124e-03,\n",
      "        1.0466e-03, 4.5792e-03, 9.8671e-01, 9.9864e-01, 6.1107e-04, 3.6373e-03,\n",
      "        9.9170e-01, 1.2999e-03, 9.9858e-01, 7.4479e-02, 1.9258e-02, 3.6933e-02,\n",
      "        9.9930e-01, 9.5627e-01, 1.5790e-02, 1.8769e-03, 2.5386e-01, 2.1863e-02,\n",
      "        9.9932e-01, 8.3453e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1324, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06967270374298096\n",
      "400\n",
      "tensor([0.9648, 0.9923, 0.9995, 0.0075, 0.0020, 0.9990, 0.0917, 0.0014, 0.0032,\n",
      "        0.9986, 0.0017, 0.9989, 0.0025, 0.9986, 0.9984, 0.0168, 0.9977, 0.0016,\n",
      "        0.9979, 0.0012, 0.9972, 0.0131, 0.9989, 0.0087, 0.0023, 0.9744, 0.0065,\n",
      "        0.0143, 0.9759, 0.9992, 0.0290, 0.9988], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0697682574391365\n",
      "430\n",
      "tensor([9.8024e-01, 1.8525e-03, 8.9280e-01, 6.3186e-02, 9.9711e-01, 9.9932e-01,\n",
      "        8.8488e-03, 6.3757e-04, 2.5929e-03, 3.1630e-03, 9.9660e-01, 1.5578e-01,\n",
      "        6.9857e-04, 6.0580e-03, 9.9879e-01, 9.9948e-01, 1.1227e-02, 9.9374e-01,\n",
      "        9.9738e-01, 9.9935e-01, 1.6842e-03, 9.9498e-01, 9.9779e-01, 1.3262e-03,\n",
      "        9.5429e-01, 1.4003e-03, 4.1854e-02, 9.9914e-01, 9.9756e-01, 9.8554e-01,\n",
      "        1.3076e-03, 9.9571e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0171, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.07034219056367874\n",
      "460\n",
      "tensor([1.0061e-01, 9.5440e-01, 1.7590e-02, 9.9765e-01, 1.1234e-03, 3.7159e-03,\n",
      "        9.9826e-01, 9.9387e-01, 1.1021e-03, 7.3615e-04, 9.3962e-01, 9.9661e-01,\n",
      "        9.9955e-01, 7.2695e-04, 1.0189e-03, 9.9797e-01, 9.9209e-01, 9.9872e-01,\n",
      "        2.1364e-01, 9.7864e-01, 6.5641e-04, 1.0040e-03, 9.8503e-01, 9.9351e-01,\n",
      "        9.8917e-01, 9.9450e-01, 9.5306e-01, 9.9748e-01, 9.9837e-01, 9.6337e-01,\n",
      "        4.9986e-04, 3.8179e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0207, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.07024911791086197\n",
      "490\n",
      "tensor([4.8488e-04, 1.8176e-03, 9.9957e-01, 9.9731e-01, 9.2289e-04, 8.7515e-03,\n",
      "        9.9505e-01, 8.7075e-04, 9.9952e-01, 1.8415e-01, 2.6389e-02, 9.9527e-01,\n",
      "        5.1248e-04, 1.0699e-03, 9.0180e-04, 5.2300e-03, 8.5822e-04, 9.9939e-01,\n",
      "        3.0971e-03, 9.9816e-01, 9.9913e-01, 5.1706e-03, 9.9855e-01, 9.9738e-01,\n",
      "        2.9611e-03, 2.4286e-03, 9.9849e-01, 6.8511e-04, 1.9183e-03, 4.2009e-03,\n",
      "        9.9927e-01, 1.3902e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0093, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06989309191703796\n",
      "520\n",
      "tensor([9.9036e-01, 9.9863e-01, 9.9818e-01, 7.8095e-04, 8.9606e-04, 9.9875e-01,\n",
      "        9.9828e-01, 8.4845e-01, 9.9868e-01, 9.9914e-01, 9.9903e-01, 9.9806e-01,\n",
      "        9.9835e-01, 5.0703e-03, 4.1573e-01, 9.9679e-01, 2.7269e-03, 2.2901e-03,\n",
      "        9.0670e-04, 9.8775e-01, 6.3127e-03, 1.0976e-03, 4.3105e-04, 9.8063e-04,\n",
      "        9.9907e-01, 1.2985e-03, 9.9890e-01, 9.9723e-01, 6.3430e-03, 9.9903e-01,\n",
      "        1.2969e-03, 9.9901e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06975861638784409\n",
      "550\n",
      "tensor([5.3530e-04, 2.8568e-03, 9.5940e-01, 9.9606e-01, 1.2302e-02, 9.9192e-01,\n",
      "        1.3969e-02, 7.0453e-03, 9.9824e-01, 2.6418e-03, 6.5896e-03, 3.2704e-01,\n",
      "        9.6673e-03, 1.1905e-03, 1.0150e-03, 9.9890e-01, 9.9927e-01, 2.1581e-02,\n",
      "        1.4298e-03, 1.3346e-02, 9.9868e-01, 9.9893e-01, 8.6024e-01, 6.2018e-04,\n",
      "        1.1200e-02, 3.3039e-03, 1.3262e-03, 9.7300e-01, 5.3000e-04, 1.3394e-03,\n",
      "        9.9856e-01, 9.8089e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0240, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06976312398910522\n",
      "580\n",
      "tensor([9.8090e-01, 3.4710e-02, 7.1226e-04, 8.2048e-01, 3.3355e-04, 9.9607e-01,\n",
      "        2.0362e-03, 9.9942e-01, 6.4760e-04, 2.7078e-02, 1.0540e-03, 1.1232e-03,\n",
      "        1.5187e-03, 1.0091e-03, 9.9773e-01, 9.9748e-01, 7.1776e-04, 9.5505e-01,\n",
      "        8.7935e-01, 3.2236e-03, 9.9838e-01, 9.4271e-01, 7.3738e-04, 9.9878e-01,\n",
      "        1.2811e-03, 2.9654e-03, 1.2144e-03, 9.9913e-01, 1.7395e-03, 4.2943e-01,\n",
      "        2.8903e-04, 9.9848e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06964974105358124\n",
      "610\n",
      "tensor([9.9559e-01, 1.4592e-03, 1.7230e-01, 8.4521e-04, 9.9391e-01, 4.8123e-04,\n",
      "        3.1831e-03, 9.9849e-01, 2.2670e-01, 9.9817e-01, 9.9920e-01, 1.9283e-03,\n",
      "        9.9571e-01, 4.0519e-02, 8.0592e-04, 2.0034e-03, 1.0922e-03, 1.6012e-02,\n",
      "        9.9275e-01, 9.9791e-01, 9.9549e-01, 2.8491e-03, 9.6632e-01, 8.7823e-02,\n",
      "        1.0391e-02, 9.6829e-01, 5.1518e-01, 9.8655e-01, 9.9945e-01, 6.3585e-03,\n",
      "        1.6660e-03, 6.7190e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1527, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06938549876213074\n",
      "640\n",
      "tensor([1.2589e-01, 1.0164e-03, 1.5991e-03, 8.1029e-03, 2.4996e-03, 9.5796e-01,\n",
      "        9.9829e-01, 7.7673e-04, 6.7012e-04, 4.4522e-04, 9.9890e-01, 4.2596e-04,\n",
      "        1.5108e-03, 1.8505e-02, 1.4067e-03, 9.7712e-01, 8.7466e-04, 5.7502e-01,\n",
      "        9.9904e-01, 5.6081e-02, 1.4259e-03, 8.9073e-01, 3.6894e-04, 9.8474e-01,\n",
      "        9.8252e-04, 9.9906e-01, 7.3347e-01, 9.9836e-01, 9.9810e-01, 1.6391e-03,\n",
      "        9.8290e-01, 1.0489e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1612, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06902163475751877\n",
      "670\n",
      "tensor([6.5304e-04, 9.9795e-01, 1.1410e-03, 9.4179e-02, 9.8139e-01, 6.2095e-01,\n",
      "        9.1911e-01, 9.9320e-01, 2.4938e-02, 1.5134e-03, 9.8604e-01, 8.1245e-04,\n",
      "        9.9191e-01, 9.9655e-01, 8.9019e-04, 9.9774e-01, 3.2827e-01, 5.1243e-04,\n",
      "        4.2876e-02, 4.9039e-01, 1.1896e-03, 9.9915e-01, 4.7725e-04, 9.8812e-01,\n",
      "        4.3560e-03, 9.9689e-01, 9.9669e-01, 1.8706e-03, 1.8638e-03, 9.9278e-01,\n",
      "        9.8935e-01, 9.9598e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0976, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06963036209344864\n",
      "700\n",
      "tensor([9.9788e-01, 9.9827e-01, 9.9870e-01, 9.9893e-01, 9.9903e-01, 9.9882e-01,\n",
      "        9.9859e-01, 9.9897e-01, 9.9841e-01, 9.9220e-01, 9.9869e-01, 1.3959e-03,\n",
      "        9.9946e-01, 1.5291e-03, 5.0485e-03, 8.1225e-04, 9.9792e-01, 7.7526e-02,\n",
      "        9.9330e-01, 6.9980e-04, 1.3467e-03, 1.3715e-03, 1.7945e-03, 9.9675e-01,\n",
      "        9.9936e-01, 9.9754e-01, 9.9926e-01, 7.7984e-04, 9.9899e-01, 1.8380e-03,\n",
      "        1.7587e-02, 9.4803e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0065, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06855417788028717\n",
      "730\n",
      "tensor([7.6790e-04, 8.4337e-04, 6.6958e-04, 4.6914e-04, 1.2489e-03, 9.9886e-01,\n",
      "        9.9431e-01, 9.9967e-01, 1.0128e-03, 4.1644e-04, 7.8964e-04, 9.9922e-01,\n",
      "        9.9968e-01, 9.9881e-01, 9.9421e-01, 4.0224e-03, 5.6535e-04, 9.9897e-01,\n",
      "        9.9945e-01, 5.0424e-04, 3.9743e-04, 4.6847e-04, 9.9933e-01, 1.1587e-03,\n",
      "        9.7660e-04, 9.9928e-01, 2.5057e-04, 1.5339e-03, 7.9761e-04, 1.0690e-03,\n",
      "        1.9375e-03, 5.2448e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0012, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0674818679690361\n",
      "760\n",
      "tensor([7.2811e-02, 9.9348e-01, 9.8917e-01, 5.7922e-03, 2.3551e-03, 9.2771e-04,\n",
      "        5.1949e-02, 9.9925e-01, 9.9452e-01, 9.9935e-01, 8.2421e-02, 3.3860e-02,\n",
      "        9.8551e-04, 1.1151e-03, 5.0268e-04, 1.0190e-01, 6.6246e-04, 9.8939e-01,\n",
      "        1.1779e-03, 1.2330e-02, 2.3737e-03, 9.9814e-01, 9.9904e-01, 9.9008e-04,\n",
      "        9.1796e-02, 5.3299e-04, 9.9684e-01, 9.9723e-01, 9.9287e-01, 6.2176e-04,\n",
      "        1.4553e-03, 9.9544e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06773997843265533\n",
      "790\n",
      "tensor([9.9956e-01, 9.9865e-01, 9.8726e-01, 3.9696e-04, 7.8175e-04, 1.4745e-03,\n",
      "        9.9351e-01, 1.4906e-02, 8.5054e-02, 6.8065e-01, 9.9811e-01, 9.9775e-01,\n",
      "        9.9922e-01, 9.9836e-01, 3.1805e-03, 1.8593e-03, 9.9873e-01, 9.9931e-01,\n",
      "        9.8671e-01, 5.6400e-04, 3.0352e-01, 5.7637e-04, 3.9128e-03, 9.9952e-01,\n",
      "        9.9913e-01, 9.9886e-01, 1.3332e-03, 9.7879e-01, 9.9508e-01, 9.3488e-02,\n",
      "        1.8967e-03, 2.3698e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0325, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06769795715808868\n",
      "820\n",
      "tensor([9.9901e-01, 1.8234e-03, 9.9953e-01, 9.9927e-01, 1.2496e-03, 9.9960e-01,\n",
      "        7.8683e-03, 9.9928e-01, 9.6787e-04, 6.3188e-02, 9.9953e-01, 9.9829e-01,\n",
      "        2.4123e-03, 1.9801e-02, 1.0150e-02, 1.8301e-02, 9.9580e-01, 8.3506e-04,\n",
      "        4.0051e-04, 7.4279e-03, 9.9890e-01, 3.1223e-03, 5.2074e-04, 9.9839e-01,\n",
      "        9.9921e-01, 9.8567e-01, 9.9945e-01, 1.2794e-03, 9.2930e-01, 9.9584e-01,\n",
      "        9.9777e-01, 1.1023e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0078, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06771084666252136\n",
      "850\n",
      "tensor([9.9951e-01, 1.1046e-03, 1.6807e-03, 5.4810e-04, 9.9754e-01, 9.9924e-01,\n",
      "        3.3604e-03, 9.9850e-01, 9.9866e-01, 9.9786e-04, 9.1703e-01, 9.9867e-01,\n",
      "        3.3394e-03, 2.5866e-01, 1.3521e-02, 1.6534e-02, 9.9934e-01, 1.1818e-02,\n",
      "        1.2478e-03, 2.3340e-03, 7.0138e-03, 9.9925e-01, 5.1970e-03, 1.6216e-03,\n",
      "        1.6261e-03, 1.2653e-03, 9.9426e-01, 9.9679e-01, 1.0031e-03, 1.0024e-03,\n",
      "        9.9045e-01, 9.9922e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0482, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06785102933645248\n",
      "880\n",
      "tensor([1.0819e-03, 9.9255e-01, 1.2937e-03, 3.7282e-03, 2.2900e-02, 2.3710e-03,\n",
      "        9.9909e-01, 1.7663e-02, 1.1810e-03, 9.9937e-01, 9.8085e-01, 9.0951e-01,\n",
      "        9.9786e-01, 9.9945e-01, 9.7798e-01, 1.2881e-03, 9.9950e-01, 9.9518e-01,\n",
      "        9.8572e-01, 9.9933e-01, 1.8279e-02, 2.8790e-03, 3.5539e-01, 9.9899e-01,\n",
      "        1.6931e-02, 9.9957e-01, 9.9940e-01, 1.7353e-03, 9.9931e-01, 9.9878e-01,\n",
      "        9.9360e-01, 9.3643e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0408, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06739706546068192\n",
      "910\n",
      "tensor([3.2606e-03, 9.8521e-01, 5.9784e-04, 5.7109e-01, 4.7003e-03, 2.1151e-02,\n",
      "        9.9906e-01, 9.9828e-01, 9.9942e-01, 9.9257e-01, 9.9863e-01, 9.9909e-01,\n",
      "        9.9906e-01, 9.8366e-01, 9.9932e-01, 9.9943e-01, 1.2419e-02, 9.9554e-01,\n",
      "        9.8950e-01, 8.7434e-04, 9.9158e-01, 9.9915e-01, 9.9911e-01, 1.5546e-03,\n",
      "        9.5221e-01, 9.9903e-01, 9.4490e-01, 9.9917e-01, 9.9909e-01, 9.9842e-01,\n",
      "        1.2739e-01, 9.7717e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06721478700637817\n",
      "940\n",
      "tensor([7.1064e-04, 7.4298e-04, 4.9212e-03, 9.9899e-01, 2.9251e-04, 9.5874e-01,\n",
      "        9.9932e-01, 9.9752e-01, 4.9241e-03, 1.1328e-03, 9.9896e-01, 2.5433e-03,\n",
      "        9.9905e-01, 1.1338e-02, 9.9674e-01, 9.9888e-01, 9.9885e-01, 9.9641e-01,\n",
      "        9.9837e-01, 9.9724e-01, 7.1713e-04, 9.8614e-01, 2.6331e-03, 9.9897e-01,\n",
      "        1.1473e-03, 9.9852e-01, 9.9582e-01, 9.9726e-01, 3.0897e-01, 9.9945e-01,\n",
      "        9.9908e-01, 4.1336e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1388, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06690723448991776\n",
      "970\n",
      "tensor([4.9177e-02, 7.0534e-04, 1.3191e-03, 9.9729e-01, 2.8362e-02, 9.7574e-01,\n",
      "        9.0529e-01, 9.9792e-01, 9.9828e-01, 9.8415e-01, 2.0484e-03, 9.8695e-01,\n",
      "        2.0021e-03, 6.2234e-03, 1.7508e-01, 1.2764e-02, 9.9889e-01, 9.9806e-01,\n",
      "        8.4706e-01, 1.1614e-03, 9.9638e-03, 9.9890e-01, 9.6460e-01, 9.8966e-04,\n",
      "        1.3910e-02, 9.9473e-01, 8.2904e-04, 7.5753e-04, 6.1567e-04, 1.9825e-01,\n",
      "        1.3425e-03, 2.6048e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0823, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0672588050365448\n",
      "1000\n",
      "tensor([2.0739e-03, 9.8960e-01, 1.1338e-03, 4.6243e-01, 9.9856e-01, 1.7285e-03,\n",
      "        9.9705e-01, 8.5129e-04, 9.9717e-01, 3.5415e-03, 2.1405e-03, 9.9921e-01,\n",
      "        9.9562e-01, 1.1311e-02, 9.4190e-04, 1.4003e-03, 4.7543e-04, 9.9958e-01,\n",
      "        2.0618e-02, 9.9944e-01, 9.9764e-01, 9.9938e-01, 9.9598e-01, 9.9945e-01,\n",
      "        9.9898e-01, 3.9514e-03, 9.9921e-01, 4.3369e-04, 9.9899e-01, 9.9834e-01,\n",
      "        9.9862e-01, 9.9961e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0269, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06710530817508698\n",
      "1030\n",
      "tensor([9.9935e-01, 9.9878e-01, 9.9932e-01, 6.3299e-04, 5.3436e-01, 9.5135e-02,\n",
      "        1.1652e-03, 3.7858e-03, 2.7696e-02, 7.6925e-01, 1.3888e-03, 5.8140e-03,\n",
      "        7.2278e-03, 9.9537e-01, 1.0975e-02, 8.4270e-02, 9.9598e-01, 2.4512e-03,\n",
      "        9.9521e-01, 9.9817e-01, 2.3775e-03, 9.9896e-01, 9.6267e-01, 9.9877e-01,\n",
      "        7.4976e-03, 9.9785e-01, 4.8994e-04, 5.0492e-03, 6.0283e-04, 9.8068e-01,\n",
      "        5.3215e-04, 9.9736e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1657, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0680585652589798\n",
      "1060\n",
      "tensor([9.9149e-04, 1.6781e-03, 9.9631e-01, 9.9676e-01, 9.9925e-01, 4.4161e-04,\n",
      "        7.8277e-04, 2.1753e-01, 7.9828e-04, 9.7926e-01, 1.3495e-02, 8.0808e-03,\n",
      "        5.0716e-03, 9.6315e-01, 2.1970e-03, 9.9785e-01, 9.9858e-01, 9.9312e-01,\n",
      "        9.9875e-01, 2.9043e-03, 9.9896e-01, 9.9922e-01, 3.1511e-03, 9.9932e-01,\n",
      "        1.3153e-03, 9.8290e-01, 9.9932e-01, 4.9842e-04, 9.9904e-01, 9.9770e-01,\n",
      "        1.5020e-03, 2.0147e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0192, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06776131689548492\n",
      "1090\n",
      "tensor([3.0091e-03, 1.6678e-01, 9.8981e-01, 4.4292e-02, 9.9388e-01, 9.9859e-01,\n",
      "        1.5301e-03, 4.9687e-04, 1.2847e-03, 5.3460e-04, 6.3742e-04, 9.9902e-01,\n",
      "        4.5799e-04, 4.2692e-03, 5.2314e-04, 2.7332e-01, 9.9563e-01, 9.8125e-01,\n",
      "        9.9896e-01, 9.9849e-01, 9.9834e-01, 9.8125e-01, 6.2437e-04, 9.9819e-01,\n",
      "        6.8955e-04, 5.5743e-03, 9.9814e-01, 9.7559e-04, 9.9528e-01, 9.9935e-01,\n",
      "        9.9895e-01, 7.1256e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0591, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06743324548006058\n",
      "1120\n",
      "tensor([1.0621e-01, 1.9899e-02, 9.9955e-01, 9.9111e-01, 6.0880e-02, 9.9914e-01,\n",
      "        9.9952e-01, 1.2032e-03, 9.9012e-04, 9.7434e-01, 9.6591e-01, 9.9856e-01,\n",
      "        9.8042e-01, 4.8199e-03, 1.4434e-01, 1.5096e-03, 6.4192e-04, 3.5416e-03,\n",
      "        5.4426e-04, 9.1204e-04, 1.1106e-03, 9.9926e-01, 9.5805e-01, 2.7747e-01,\n",
      "        4.8131e-01, 2.8851e-03, 9.9885e-01, 9.9616e-01, 1.6157e-03, 9.9894e-01,\n",
      "        9.9582e-01, 3.5228e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0469, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06737536936998367\n",
      "1150\n",
      "tensor([2.8179e-03, 9.9695e-01, 9.9390e-01, 5.8206e-04, 9.9916e-01, 9.9757e-01,\n",
      "        5.7172e-04, 9.9745e-01, 9.9970e-01, 9.9938e-01, 2.3171e-03, 9.9733e-01,\n",
      "        9.0292e-01, 5.4903e-04, 9.6349e-01, 9.9467e-01, 9.5440e-04, 9.9576e-01,\n",
      "        9.5503e-01, 6.6283e-04, 3.4879e-04, 9.9857e-01, 3.2076e-04, 9.9832e-01,\n",
      "        8.3758e-03, 1.3354e-03, 2.9110e-03, 9.9940e-01, 1.2700e-03, 2.9096e-01,\n",
      "        9.9481e-01, 9.9945e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0463, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06724001467227936\n",
      "1180\n",
      "tensor([9.9846e-01, 1.5158e-03, 9.9821e-01, 9.9926e-01, 9.9907e-01, 1.2225e-01,\n",
      "        4.0326e-04, 3.6024e-01, 4.3713e-03, 1.9172e-03, 9.9832e-01, 9.7337e-01,\n",
      "        4.0885e-04, 9.9930e-01, 9.9799e-01, 3.7382e-03, 9.1799e-03, 2.1366e-03,\n",
      "        9.9923e-01, 9.5408e-01, 9.9929e-01, 9.8808e-01, 9.9839e-01, 6.9805e-01,\n",
      "        1.6215e-03, 9.9637e-01, 9.5918e-01, 1.4439e-03, 9.9599e-01, 1.9799e-03,\n",
      "        1.3803e-02, 9.9847e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0353, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06746137142181396\n",
      "1210\n",
      "tensor([9.7553e-01, 8.7186e-01, 2.1609e-03, 9.9177e-03, 2.2719e-03, 9.9889e-01,\n",
      "        9.9351e-01, 3.3918e-04, 4.3560e-04, 3.6365e-03, 8.0282e-03, 9.9233e-01,\n",
      "        9.9851e-01, 9.7926e-01, 9.9651e-01, 9.9503e-01, 9.9797e-01, 9.9841e-01,\n",
      "        9.9874e-01, 9.9899e-01, 9.6056e-01, 6.8075e-03, 5.4368e-03, 8.7666e-01,\n",
      "        3.7154e-04, 7.8948e-04, 9.9887e-01, 9.9895e-01, 9.6465e-01, 1.1439e-03,\n",
      "        9.8546e-01, 5.5252e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0150, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06758475303649902\n",
      "1240\n",
      "tensor([9.9654e-01, 9.9904e-01, 1.4806e-03, 9.9858e-01, 1.4643e-03, 9.9735e-01,\n",
      "        9.9911e-01, 7.6886e-04, 7.0822e-03, 1.6869e-02, 9.9945e-01, 9.9924e-01,\n",
      "        2.5812e-03, 1.0857e-03, 1.0985e-03, 9.9935e-01, 9.9929e-01, 9.9796e-01,\n",
      "        9.6288e-03, 1.3372e-03, 9.8658e-01, 9.9469e-01, 7.1705e-04, 9.6208e-04,\n",
      "        9.9753e-01, 9.9853e-01, 9.9897e-01, 5.0526e-02, 5.7391e-03, 4.0956e-04,\n",
      "        9.9925e-01, 9.9952e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0045, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0671863779425621\n",
      "1270\n",
      "tensor([5.9418e-04, 9.9496e-01, 6.0404e-04, 1.5412e-03, 9.9853e-01, 5.4107e-03,\n",
      "        1.3670e-03, 9.9820e-01, 9.9598e-01, 9.9836e-01, 9.9945e-01, 2.9624e-01,\n",
      "        1.3710e-03, 9.9657e-01, 9.9951e-01, 9.9875e-01, 5.2864e-03, 9.3737e-03,\n",
      "        6.2942e-04, 9.9436e-01, 9.9871e-01, 9.6163e-01, 4.4716e-03, 1.7795e-02,\n",
      "        9.9901e-01, 2.2670e-04, 9.9790e-01, 1.1117e-03, 3.4064e-02, 4.2890e-03,\n",
      "        9.9914e-01, 9.9935e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0160, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06737347692251205\n",
      "1300\n",
      "tensor([1.1541e-01, 9.9877e-01, 2.9649e-03, 1.1186e-03, 9.8901e-01, 9.5932e-01,\n",
      "        9.9786e-01, 9.7791e-01, 9.9467e-01, 8.8713e-02, 2.1611e-03, 9.9473e-01,\n",
      "        3.7145e-03, 4.8567e-01, 9.9931e-01, 9.9853e-01, 9.9884e-01, 5.0261e-03,\n",
      "        1.2784e-03, 9.9669e-01, 9.9875e-01, 1.1983e-03, 9.9675e-01, 2.0571e-03,\n",
      "        1.6993e-02, 9.7146e-01, 9.9945e-01, 9.9755e-01, 4.2845e-04, 9.9666e-01,\n",
      "        9.8374e-01, 7.3336e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0354, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06734275817871094\n",
      "1330\n",
      "tensor([3.1804e-01, 2.0474e-01, 2.6631e-03, 9.3353e-03, 3.5199e-03, 2.1881e-03,\n",
      "        9.9958e-01, 1.7612e-03, 6.3398e-01, 5.1906e-02, 9.3089e-01, 9.9614e-01,\n",
      "        2.1249e-03, 2.5057e-01, 9.9914e-01, 9.9630e-01, 9.9840e-01, 9.4679e-01,\n",
      "        3.4263e-04, 3.3874e-03, 9.8315e-01, 9.9685e-01, 9.9757e-01, 7.8100e-04,\n",
      "        1.2955e-03, 6.2122e-02, 1.3887e-03, 9.9838e-01, 9.9822e-01, 1.6205e-02,\n",
      "        6.9584e-01, 1.5145e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06787951290607452\n",
      "1360\n",
      "tensor([3.2132e-03, 9.3730e-01, 9.9766e-01, 1.4016e-03, 9.9921e-01, 9.7865e-01,\n",
      "        9.9831e-01, 9.7652e-01, 4.7946e-04, 8.7965e-04, 1.5902e-03, 9.9499e-01,\n",
      "        9.8872e-01, 9.6671e-01, 9.9907e-01, 9.9324e-01, 1.3266e-03, 9.9852e-01,\n",
      "        1.1713e-02, 9.9912e-01, 8.4041e-04, 9.9681e-01, 9.9898e-01, 3.2436e-04,\n",
      "        9.6276e-01, 9.9394e-01, 2.2571e-03, 9.9846e-01, 9.9907e-01, 9.8866e-01,\n",
      "        1.5392e-02, 5.6293e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06806929409503937\n",
      "1390\n",
      "tensor([9.9496e-01, 1.2202e-02, 9.8473e-01, 9.1357e-01, 1.1610e-03, 9.9944e-01,\n",
      "        9.7084e-01, 9.9767e-01, 9.9862e-01, 2.7757e-03, 1.3279e-03, 9.9940e-01,\n",
      "        5.0313e-04, 4.0428e-02, 6.1409e-03, 6.8678e-04, 7.2045e-04, 1.7416e-02,\n",
      "        2.2449e-03, 9.9908e-01, 3.9081e-03, 9.9748e-01, 9.9893e-01, 6.6159e-04,\n",
      "        1.8502e-03, 9.8803e-01, 5.7988e-04, 8.0801e-02, 9.7878e-01, 9.2356e-03,\n",
      "        9.9837e-01, 9.9889e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0117, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06799401342868805\n",
      "1420\n",
      "tensor([2.9039e-03, 9.9467e-01, 9.8795e-01, 9.9007e-01, 8.2498e-03, 4.7653e-04,\n",
      "        9.9941e-01, 1.4839e-03, 2.2684e-03, 1.3088e-01, 4.5970e-04, 7.0717e-04,\n",
      "        4.6105e-04, 9.9859e-01, 1.0420e-03, 1.0480e-02, 9.9925e-01, 6.3047e-01,\n",
      "        9.9771e-01, 9.9750e-01, 1.0628e-03, 9.9288e-01, 6.1724e-04, 9.9955e-01,\n",
      "        8.8125e-04, 3.7980e-01, 9.9682e-01, 9.9844e-01, 5.8167e-04, 7.4599e-04,\n",
      "        9.9503e-01, 6.1530e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0517, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06761930137872696\n",
      "1450\n",
      "tensor([9.5596e-01, 9.9548e-01, 3.3606e-04, 1.0366e-03, 5.4283e-03, 9.9562e-01,\n",
      "        9.9809e-01, 9.8763e-01, 3.2638e-04, 9.9845e-01, 5.3134e-02, 9.9836e-01,\n",
      "        9.9758e-01, 3.8513e-04, 9.9874e-01, 9.4429e-01, 9.9928e-01, 7.5348e-02,\n",
      "        1.5646e-03, 9.9140e-01, 3.4233e-02, 1.0716e-03, 1.6641e-03, 9.5400e-01,\n",
      "        1.1481e-03, 9.9818e-01, 4.4215e-02, 5.2108e-04, 9.9658e-01, 9.7399e-01,\n",
      "        8.3359e-02, 1.8434e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0167, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06788143515586853\n",
      "1480\n",
      "tensor([9.9152e-01, 6.6046e-04, 9.9897e-01, 9.9794e-01, 9.9680e-01, 9.9330e-01,\n",
      "        7.7800e-04, 7.9843e-04, 1.6225e-03, 9.9923e-01, 9.8937e-01, 9.9917e-01,\n",
      "        9.9786e-01, 1.2725e-03, 9.9928e-01, 9.9932e-01, 6.2921e-04, 9.6095e-04,\n",
      "        1.0122e-03, 1.2082e-02, 1.4879e-03, 9.9550e-01, 4.7995e-04, 2.1154e-03,\n",
      "        7.1341e-04, 9.5087e-01, 8.5504e-01, 9.9827e-01, 6.2582e-03, 2.1980e-02,\n",
      "        6.2775e-02, 9.9836e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0116, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06800111383199692\n",
      "1510\n",
      "tensor([9.9819e-01, 7.9093e-04, 8.5738e-04, 9.8725e-01, 9.9930e-01, 3.0583e-02,\n",
      "        9.3016e-04, 9.9889e-01, 9.9562e-01, 9.3052e-01, 9.9976e-01, 9.9938e-01,\n",
      "        4.6730e-04, 9.8203e-01, 1.3600e-01, 2.2188e-01, 2.3023e-03, 1.1931e-03,\n",
      "        9.9890e-01, 1.6994e-01, 6.3574e-01, 9.9905e-01, 9.9946e-01, 9.9914e-01,\n",
      "        1.1195e-03, 9.9827e-01, 3.4323e-04, 9.9922e-01, 9.9934e-01, 5.7841e-04,\n",
      "        1.2480e-03, 7.7958e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0399, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06772266328334808\n",
      "1540\n",
      "tensor([9.9899e-01, 2.6489e-03, 9.9947e-01, 6.2178e-04, 9.9924e-01, 4.5693e-04,\n",
      "        7.5196e-04, 1.0472e-03, 6.0841e-03, 9.9934e-01, 4.0488e-04, 9.5650e-01,\n",
      "        4.6176e-04, 9.8414e-01, 1.1481e-03, 9.9859e-01, 5.5267e-04, 3.2507e-03,\n",
      "        2.1832e-03, 6.5109e-04, 9.9924e-01, 2.9076e-03, 3.6205e-04, 9.9814e-01,\n",
      "        9.9794e-01, 9.9937e-01, 1.1941e-03, 5.5663e-04, 4.8077e-04, 9.9976e-01,\n",
      "        9.8917e-01, 9.9761e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1000, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06724011898040771\n",
      "1570\n",
      "tensor([9.9837e-01, 9.9895e-01, 9.9319e-01, 4.6224e-04, 1.7816e-03, 9.9958e-01,\n",
      "        8.4637e-04, 8.9807e-04, 1.8234e-03, 9.9900e-01, 9.9957e-01, 8.0639e-04,\n",
      "        9.8002e-01, 9.9934e-01, 6.2337e-04, 2.3520e-03, 9.9941e-01, 9.9349e-01,\n",
      "        1.0451e-02, 9.9818e-01, 9.9572e-01, 1.1199e-03, 9.9386e-01, 8.8401e-04,\n",
      "        1.2672e-03, 9.9832e-01, 7.5524e-04, 9.9901e-01, 1.4240e-03, 9.9810e-01,\n",
      "        9.0981e-04, 9.9682e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0027, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06736767292022705\n",
      "1600\n",
      "tensor([9.8367e-01, 5.3667e-04, 9.4420e-04, 7.1064e-03, 9.9825e-01, 9.9538e-01,\n",
      "        9.9958e-01, 1.5883e-01, 1.0921e-02, 1.3090e-02, 9.7891e-01, 1.2099e-03,\n",
      "        2.6667e-04, 1.1148e-03, 2.0523e-03, 9.9916e-01, 6.2737e-04, 9.9875e-01,\n",
      "        9.9883e-01, 4.1098e-01, 9.9115e-01, 3.1664e-04, 9.9897e-01, 1.4226e-03,\n",
      "        8.5481e-04, 1.1918e-02, 2.3469e-03, 9.7867e-01, 9.9910e-01, 9.9953e-01,\n",
      "        4.6286e-04, 9.9314e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0264, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06708776950836182\n",
      "1630\n",
      "tensor([9.9942e-01, 9.9389e-01, 9.9780e-01, 5.7718e-04, 2.0149e-01, 1.3202e-02,\n",
      "        9.2995e-04, 4.7145e-02, 9.9914e-01, 9.9818e-01, 9.9674e-01, 1.1474e-03,\n",
      "        1.4806e-01, 7.1638e-02, 2.8408e-02, 7.5972e-01, 9.9887e-01, 2.8696e-01,\n",
      "        9.9750e-01, 9.9896e-01, 9.9892e-01, 7.4260e-04, 5.8817e-01, 6.8006e-02,\n",
      "        6.8327e-03, 9.2128e-03, 9.9523e-01, 7.7500e-03, 1.7877e-01, 9.7505e-01,\n",
      "        9.7043e-04, 9.5015e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1285, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06721187382936478\n",
      "1660\n",
      "tensor([2.1245e-02, 4.4855e-04, 6.5440e-03, 9.9545e-01, 9.9458e-01, 9.9788e-01,\n",
      "        1.5366e-02, 9.2783e-01, 4.0045e-04, 8.4858e-02, 9.9840e-01, 8.4502e-04,\n",
      "        1.0894e-03, 9.9875e-01, 7.5523e-04, 9.6508e-01, 3.2130e-03, 5.6108e-03,\n",
      "        9.9845e-01, 1.0203e-03, 5.5540e-04, 5.4754e-03, 9.7001e-01, 9.9851e-01,\n",
      "        9.9720e-01, 9.9184e-01, 1.1609e-03, 9.9620e-01, 9.9701e-01, 9.9770e-01,\n",
      "        9.9373e-01, 1.2726e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0110, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06678418815135956\n",
      "1690\n",
      "tensor([5.4090e-03, 1.3834e-03, 9.9920e-01, 1.4047e-03, 9.9900e-01, 1.5649e-03,\n",
      "        1.0785e-03, 1.3428e-03, 9.9898e-01, 9.9064e-01, 1.2617e-03, 9.9814e-01,\n",
      "        6.7384e-03, 9.9967e-01, 8.9891e-01, 9.9905e-01, 3.0115e-03, 9.9716e-01,\n",
      "        9.8883e-01, 9.9955e-01, 9.9875e-01, 1.9897e-03, 5.2057e-02, 9.9941e-01,\n",
      "        9.9797e-01, 1.0721e-03, 9.9887e-01, 3.7288e-04, 4.2037e-01, 1.0771e-03,\n",
      "        9.9784e-01, 9.9927e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0341, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06684622168540955\n",
      "1720\n",
      "tensor([9.9719e-01, 9.2639e-01, 9.3182e-01, 1.6165e-03, 1.2922e-03, 9.9892e-01,\n",
      "        7.2386e-04, 9.9533e-01, 4.0221e-03, 9.8365e-01, 9.9941e-01, 9.9701e-01,\n",
      "        9.9902e-01, 9.9767e-01, 9.9941e-01, 1.9418e-03, 3.3489e-04, 6.8993e-04,\n",
      "        9.8823e-01, 3.5716e-04, 3.9657e-04, 8.4920e-04, 9.9778e-01, 1.6107e-03,\n",
      "        9.9750e-01, 9.9894e-01, 3.7448e-02, 9.8081e-01, 8.5636e-01, 2.9104e-02,\n",
      "        9.7293e-02, 9.9763e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1270, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06682506203651428\n",
      "1750\n",
      "tensor([7.3027e-03, 1.1680e-02, 9.9900e-01, 4.5106e-03, 4.4911e-04, 8.9951e-02,\n",
      "        9.8906e-01, 9.9907e-01, 1.0717e-03, 1.8624e-02, 1.4585e-02, 9.9866e-01,\n",
      "        1.5368e-03, 1.7377e-01, 1.4766e-03, 9.9966e-01, 1.2908e-03, 1.8923e-03,\n",
      "        1.2164e-03, 6.2235e-04, 9.9932e-01, 1.7072e-03, 9.9551e-01, 9.9933e-01,\n",
      "        2.2722e-03, 9.9858e-01, 2.3675e-03, 9.0818e-01, 9.9732e-01, 9.7450e-01,\n",
      "        9.9198e-01, 9.9300e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1301, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06692624092102051\n",
      "1780\n",
      "tensor([8.7717e-04, 5.1740e-04, 9.8663e-01, 1.0591e-03, 1.7472e-03, 9.9797e-01,\n",
      "        2.7667e-01, 9.8776e-01, 5.1097e-03, 9.9762e-01, 3.5543e-04, 9.9915e-01,\n",
      "        3.1933e-03, 9.9794e-01, 7.4662e-04, 9.5938e-01, 9.5422e-01, 5.7618e-03,\n",
      "        9.9166e-01, 9.6455e-01, 4.8651e-04, 9.8338e-01, 9.9805e-01, 9.0242e-04,\n",
      "        9.8895e-04, 9.9567e-01, 8.4007e-04, 9.9846e-01, 9.9874e-01, 9.9827e-01,\n",
      "        4.7739e-04, 4.3695e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0183, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06695549190044403\n",
      "1810\n",
      "tensor([9.9896e-01, 9.9901e-01, 9.9885e-01, 2.6213e-02, 2.9341e-01, 4.3545e-04,\n",
      "        6.6159e-03, 5.7914e-04, 4.4262e-03, 7.6076e-04, 9.3632e-04, 8.3695e-03,\n",
      "        9.9900e-01, 1.4287e-02, 9.9834e-01, 9.8843e-01, 9.7774e-01, 3.8861e-04,\n",
      "        9.9861e-01, 9.9869e-01, 3.0837e-03, 2.0404e-03, 3.6420e-04, 5.0486e-03,\n",
      "        1.8224e-03, 1.1489e-03, 9.9974e-01, 2.2091e-03, 9.9711e-01, 9.9948e-01,\n",
      "        2.3329e-03, 2.4792e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0149, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06689921021461487\n",
      "1840\n",
      "tensor([3.0772e-03, 5.7886e-02, 9.9527e-01, 9.9956e-01, 8.0544e-04, 3.8275e-02,\n",
      "        9.9902e-01, 9.9904e-01, 9.9175e-01, 7.4342e-01, 1.0256e-03, 2.8679e-03,\n",
      "        4.9907e-04, 1.1031e-03, 9.9854e-01, 9.9754e-01, 6.7700e-04, 3.1792e-03,\n",
      "        8.2434e-03, 9.1992e-02, 2.2107e-02, 9.9877e-01, 5.1527e-03, 1.3751e-03,\n",
      "        5.7326e-03, 9.4841e-04, 6.9653e-04, 1.2335e-03, 3.2893e-04, 9.9911e-01,\n",
      "        2.9879e-04, 9.9928e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1986, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06681347638368607\n",
      "1870\n",
      "tensor([5.1320e-04, 2.4504e-02, 6.4629e-03, 9.9407e-01, 9.9867e-01, 9.5842e-01,\n",
      "        3.7694e-04, 5.3311e-04, 2.0334e-03, 9.9423e-01, 9.9918e-01, 7.8896e-04,\n",
      "        2.5064e-02, 9.9662e-01, 3.4984e-03, 1.8548e-02, 9.9067e-01, 9.9528e-01,\n",
      "        9.1754e-01, 9.9614e-01, 6.3294e-04, 9.9757e-01, 8.6646e-01, 6.8686e-03,\n",
      "        6.6841e-04, 2.5463e-03, 5.7096e-04, 1.7913e-03, 9.9759e-01, 1.2972e-01,\n",
      "        1.1266e-02, 2.2725e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0175, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06687904894351959\n",
      "1900\n",
      "tensor([1.4321e-03, 9.7904e-01, 9.7857e-01, 2.8994e-03, 9.2163e-04, 3.1700e-04,\n",
      "        1.8549e-02, 9.9751e-01, 4.3469e-01, 9.4062e-01, 9.9780e-01, 2.9171e-03,\n",
      "        9.9938e-01, 1.1737e-03, 7.7063e-04, 7.4661e-04, 9.9958e-01, 1.4689e-03,\n",
      "        9.9098e-01, 9.9842e-01, 1.7751e-03, 1.9461e-03, 9.9779e-01, 9.9891e-01,\n",
      "        9.9850e-01, 9.9917e-01, 4.0392e-02, 9.9798e-01, 9.0692e-01, 2.6818e-03,\n",
      "        9.9944e-01, 5.8987e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2288, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06699539721012115\n",
      "1930\n",
      "tensor([9.9860e-01, 8.3558e-03, 1.0401e-01, 5.9322e-01, 9.9902e-01, 8.9754e-04,\n",
      "        1.7655e-03, 9.9888e-01, 9.9759e-01, 1.9289e-02, 9.9897e-01, 9.7428e-01,\n",
      "        9.9886e-01, 9.6325e-01, 1.1117e-03, 9.2626e-01, 5.8606e-03, 9.9766e-01,\n",
      "        1.2412e-02, 1.8019e-03, 7.2343e-02, 9.9802e-01, 9.6919e-01, 1.1462e-03,\n",
      "        6.3285e-01, 9.9944e-01, 9.9776e-01, 9.9814e-01, 9.9771e-01, 5.7921e-03,\n",
      "        2.4031e-03, 9.9910e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0443, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06675966084003448\n",
      "1960\n",
      "tensor([9.9937e-01, 9.9866e-01, 2.7332e-03, 2.4583e-04, 9.4160e-04, 4.0545e-01,\n",
      "        8.2894e-04, 9.9936e-01, 9.9913e-01, 9.9652e-01, 9.9868e-01, 9.9856e-01,\n",
      "        9.9936e-01, 9.9966e-01, 9.9891e-01, 3.7118e-04, 9.9430e-01, 1.0188e-03,\n",
      "        1.0419e-02, 8.0008e-04, 9.9859e-01, 2.5501e-02, 9.9545e-01, 6.3332e-03,\n",
      "        9.9938e-01, 9.9836e-01, 9.9940e-01, 4.8867e-01, 5.9815e-04, 9.9945e-01,\n",
      "        9.9926e-01, 2.2674e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1662, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06632427126169205\n",
      "1990\n",
      "tensor([9.9821e-01, 9.9966e-01, 9.9838e-01, 3.6877e-04, 3.9268e-03, 9.9941e-01,\n",
      "        4.6946e-04, 1.8882e-03, 9.9925e-01, 7.3845e-04, 1.4232e-03, 9.9720e-01,\n",
      "        9.9901e-01, 2.4935e-03, 1.1123e-02, 9.9027e-01, 9.9817e-01, 2.5972e-03,\n",
      "        9.9904e-01, 9.9932e-01, 6.1885e-04, 3.2987e-03, 9.9255e-01, 1.1483e-03,\n",
      "        8.9659e-04, 9.9806e-01, 9.9909e-01, 8.2802e-03, 1.0926e-03, 9.9927e-01,\n",
      "        9.9924e-01, 9.9487e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1755, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06651381403207779\n",
      "2020\n",
      "tensor([4.4810e-04, 2.0848e-03, 9.9907e-01, 1.2619e-03, 9.9914e-01, 3.4141e-03,\n",
      "        1.2417e-03, 6.2237e-02, 9.9895e-01, 9.9901e-01, 1.6684e-03, 4.0320e-04,\n",
      "        1.5656e-03, 7.3554e-04, 9.8886e-01, 9.8693e-01, 9.9889e-01, 9.7917e-04,\n",
      "        9.0359e-04, 9.9577e-01, 9.9940e-01, 6.5010e-04, 5.7462e-03, 9.9309e-01,\n",
      "        2.0102e-03, 9.9581e-01, 2.8642e-02, 9.9821e-01, 6.3963e-04, 9.9861e-01,\n",
      "        9.9924e-01, 9.9882e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0052, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06616266816854477\n",
      "2050\n",
      "tensor([9.9831e-01, 9.9913e-01, 1.4456e-02, 1.0517e-03, 1.2981e-03, 7.5146e-01,\n",
      "        6.1257e-04, 5.2868e-04, 2.9158e-01, 9.9924e-01, 9.9463e-01, 3.0965e-03,\n",
      "        1.5652e-03, 9.9973e-01, 1.0390e-03, 4.3093e-03, 2.5094e-03, 3.7638e-03,\n",
      "        9.9253e-02, 1.1902e-03, 9.9966e-01, 9.9948e-01, 9.9887e-01, 2.8385e-03,\n",
      "        2.0537e-03, 6.8589e-04, 9.9910e-01, 9.9873e-01, 8.7811e-04, 3.1211e-04,\n",
      "        9.8696e-01, 5.7230e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0253, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.066014364361763\n",
      "2080\n",
      "tensor([2.0979e-03, 9.9925e-01, 9.5748e-01, 9.8299e-01, 9.9963e-01, 3.5037e-03,\n",
      "        9.9811e-01, 9.9630e-01, 9.9942e-01, 1.1117e-03, 4.3098e-02, 9.9868e-01,\n",
      "        3.2003e-03, 9.9921e-01, 3.6427e-02, 4.5156e-04, 2.1405e-03, 1.9975e-03,\n",
      "        9.9709e-01, 7.3796e-02, 9.9944e-01, 9.9335e-01, 3.1949e-04, 9.9902e-01,\n",
      "        4.4439e-03, 9.9891e-01, 4.6140e-03, 9.9978e-01, 9.5344e-01, 9.9897e-01,\n",
      "        7.5562e-04, 6.4328e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0098, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06582394242286682\n",
      "2110\n",
      "tensor([1.4856e-03, 4.7361e-03, 9.9788e-01, 9.8760e-01, 2.1554e-03, 9.9622e-01,\n",
      "        1.2982e-03, 2.0047e-03, 9.9950e-01, 9.9917e-01, 6.2212e-03, 9.9820e-01,\n",
      "        2.1077e-03, 9.9805e-01, 1.6544e-03, 9.9735e-01, 9.9936e-01, 3.4606e-04,\n",
      "        9.2132e-01, 1.2771e-03, 9.9952e-01, 8.3951e-04, 4.1773e-03, 9.9856e-01,\n",
      "        8.0568e-03, 9.9702e-01, 8.2671e-03, 1.2465e-03, 9.9881e-01, 6.7924e-01,\n",
      "        1.1894e-03, 9.9792e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0172, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06582381576299667\n",
      "2140\n",
      "tensor([5.5602e-03, 9.9832e-01, 9.9835e-01, 7.1110e-02, 2.1082e-02, 2.0471e-03,\n",
      "        9.9797e-01, 7.5260e-04, 1.5932e-03, 9.8073e-04, 3.2525e-02, 9.9906e-01,\n",
      "        9.9766e-01, 2.5622e-03, 6.6489e-03, 9.9951e-01, 1.9086e-03, 9.9836e-01,\n",
      "        5.1441e-03, 9.8647e-01, 9.9636e-01, 1.3598e-02, 7.1474e-04, 9.9900e-01,\n",
      "        6.6288e-03, 3.7879e-03, 1.1646e-02, 9.9605e-01, 2.1915e-03, 2.8345e-02,\n",
      "        6.3237e-02, 4.8728e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0116, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06605123728513718\n",
      "2170\n",
      "tensor([2.2431e-03, 9.7974e-01, 9.7235e-01, 9.9926e-01, 9.9902e-01, 9.9870e-01,\n",
      "        9.9884e-01, 9.9840e-01, 9.8233e-01, 4.3526e-04, 2.0452e-02, 1.3700e-03,\n",
      "        9.9818e-01, 3.9129e-01, 3.4839e-04, 9.9910e-01, 4.8319e-03, 3.1073e-02,\n",
      "        9.9912e-01, 2.0324e-02, 2.4220e-01, 1.4380e-03, 7.6470e-04, 3.7811e-04,\n",
      "        9.9457e-01, 1.0918e-03, 2.4015e-03, 2.2843e-02, 9.5881e-01, 9.9774e-01,\n",
      "        2.5219e-03, 9.5395e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0688, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06591830402612686\n",
      "2200\n",
      "tensor([9.9684e-01, 9.9920e-01, 3.7171e-03, 4.4070e-04, 9.9940e-01, 9.9759e-01,\n",
      "        9.9779e-01, 9.9747e-01, 9.9711e-01, 1.4700e-03, 1.5406e-03, 9.1854e-01,\n",
      "        4.7234e-03, 2.1779e-02, 1.2559e-03, 9.9949e-01, 9.9914e-01, 9.3608e-04,\n",
      "        7.8944e-04, 9.9844e-01, 5.9889e-02, 9.9860e-01, 7.7945e-04, 6.6208e-04,\n",
      "        9.9814e-01, 9.9581e-01, 6.3742e-01, 2.4662e-02, 9.9613e-01, 9.9832e-01,\n",
      "        9.9777e-01, 9.9201e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1927, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06598106771707535\n",
      "2230\n",
      "tensor([9.9934e-01, 2.1336e-02, 9.9844e-01, 8.1178e-04, 4.4798e-04, 9.9893e-01,\n",
      "        9.4675e-01, 5.1887e-03, 9.9927e-01, 5.3657e-04, 9.9880e-01, 9.9190e-01,\n",
      "        4.9970e-01, 2.7897e-04, 9.9811e-01, 3.9921e-03, 8.5716e-04, 9.9660e-01,\n",
      "        9.9876e-01, 9.2725e-01, 4.1702e-04, 9.8651e-01, 5.0478e-01, 9.9906e-01,\n",
      "        4.0339e-04, 3.9069e-03, 2.3758e-04, 7.5137e-04, 9.9492e-01, 2.3339e-03,\n",
      "        1.7466e-03, 3.9904e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0515, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06605391204357147\n",
      "2260\n",
      "tensor([9.6819e-02, 4.1722e-01, 8.5063e-03, 9.9909e-01, 9.9897e-01, 7.9733e-01,\n",
      "        9.9930e-01, 8.7090e-04, 3.3293e-04, 9.9969e-01, 9.9138e-03, 1.6045e-01,\n",
      "        9.9949e-01, 3.0781e-03, 9.9894e-01, 2.8438e-01, 9.9529e-01, 1.3456e-02,\n",
      "        9.9747e-01, 1.6788e-03, 9.9924e-01, 9.9966e-01, 4.1135e-03, 2.5390e-03,\n",
      "        7.9475e-04, 9.8514e-01, 8.6975e-03, 2.9606e-02, 1.4206e-02, 1.9187e-01,\n",
      "        7.0503e-01, 9.9934e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2189, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06626052409410477\n",
      "2290\n",
      "tensor([4.1806e-04, 8.9915e-03, 7.7897e-04, 9.9886e-01, 1.7903e-02, 9.8767e-01,\n",
      "        9.5728e-01, 5.8234e-04, 9.9935e-01, 9.7878e-01, 9.9506e-01, 9.9765e-01,\n",
      "        9.9748e-01, 9.9856e-01, 8.2443e-01, 9.9839e-01, 9.9932e-01, 9.9948e-01,\n",
      "        9.8132e-01, 1.4903e-02, 9.9782e-01, 7.0673e-01, 1.0415e-01, 2.9528e-03,\n",
      "        6.5604e-01, 9.9039e-01, 9.9440e-01, 9.0381e-04, 9.9733e-01, 9.9360e-01,\n",
      "        9.9889e-01, 9.9949e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0394, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06650573760271072\n",
      "2320\n",
      "tensor([1.0375e-02, 9.9937e-01, 2.7313e-01, 9.9804e-01, 3.0224e-03, 9.9845e-01,\n",
      "        9.4623e-01, 9.7762e-01, 9.7792e-01, 9.9807e-01, 1.3770e-03, 9.4886e-01,\n",
      "        1.2073e-03, 9.9871e-01, 5.4936e-04, 9.9932e-01, 9.9955e-01, 9.9900e-01,\n",
      "        3.5609e-03, 9.9972e-01, 9.9170e-01, 9.9809e-01, 6.3240e-03, 2.9724e-02,\n",
      "        9.9886e-01, 9.8913e-01, 9.9929e-01, 2.0961e-03, 9.9577e-01, 1.0363e-02,\n",
      "        9.9944e-01, 9.9933e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0181, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06663751602172852\n",
      "2350\n",
      "tensor([9.9939e-01, 9.9947e-01, 1.3339e-03, 1.0540e-03, 1.7384e-03, 2.2067e-02,\n",
      "        9.9938e-01, 9.9949e-01, 1.2853e-01, 9.9904e-01, 9.9427e-01, 1.0574e-03,\n",
      "        7.4796e-04, 6.4192e-04, 1.6311e-03, 2.1203e-03, 9.9805e-01, 1.2657e-03,\n",
      "        9.7980e-04, 9.9922e-01, 1.6253e-03, 9.9943e-01, 9.9935e-01, 9.9917e-01,\n",
      "        9.9747e-01, 9.9558e-01, 9.9910e-01, 9.9964e-01, 1.1357e-03, 9.8772e-01,\n",
      "        9.9858e-01, 4.9513e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1439, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06663578003644943\n",
      "2380\n",
      "tensor([7.9096e-04, 8.1388e-04, 5.0851e-01, 9.9804e-01, 9.9715e-01, 9.9920e-01,\n",
      "        9.4323e-03, 9.9905e-01, 9.9827e-01, 6.1123e-01, 1.2123e-03, 9.9939e-01,\n",
      "        1.0877e-01, 1.7414e-03, 6.8547e-04, 9.9729e-01, 5.6151e-01, 9.9926e-01,\n",
      "        9.9812e-01, 2.2083e-03, 8.4286e-01, 9.9950e-01, 1.9024e-02, 9.9611e-01,\n",
      "        9.9937e-01, 9.9906e-01, 4.5863e-04, 9.9936e-01, 7.5416e-03, 9.9884e-01,\n",
      "        9.9932e-01, 1.9043e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0656, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06634331494569778\n",
      "2410\n",
      "tensor([9.9162e-01, 1.3896e-02, 9.9925e-01, 1.0604e-03, 7.2152e-04, 9.9635e-01,\n",
      "        9.9910e-01, 4.6897e-04, 1.9549e-04, 3.7151e-04, 8.2172e-04, 9.9934e-01,\n",
      "        9.8439e-01, 1.1737e-03, 7.7499e-04, 1.7322e-01, 5.0435e-03, 6.8147e-04,\n",
      "        7.5986e-04, 7.1837e-04, 8.7316e-01, 5.0490e-03, 3.4231e-04, 9.9924e-01,\n",
      "        1.6553e-02, 4.3486e-01, 9.9895e-01, 1.1908e-01, 2.2467e-03, 9.9816e-01,\n",
      "        9.9423e-01, 9.9861e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0919, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06639835238456726\n",
      "2440\n",
      "tensor([1.1160e-02, 5.2340e-03, 3.7342e-02, 9.9427e-01, 9.9751e-01, 9.9769e-01,\n",
      "        1.3764e-03, 6.0806e-04, 9.3705e-01, 9.9547e-01, 8.5545e-04, 2.0583e-03,\n",
      "        8.5698e-03, 3.8219e-04, 1.7391e-03, 9.8473e-01, 4.3026e-01, 8.7716e-04,\n",
      "        9.8396e-01, 1.0943e-03, 9.9381e-01, 3.9551e-02, 9.9938e-01, 2.5104e-03,\n",
      "        9.9017e-01, 7.9268e-03, 9.7835e-01, 9.9588e-01, 1.9954e-04, 2.3709e-03,\n",
      "        9.9605e-01, 1.9284e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0265, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06674166023731232\n",
      "2470\n",
      "tensor([9.9580e-01, 3.4225e-04, 9.9882e-01, 2.0000e-03, 9.9503e-01, 2.1447e-01,\n",
      "        9.9859e-01, 9.9932e-01, 9.2166e-01, 9.9846e-01, 9.9786e-01, 6.8713e-04,\n",
      "        6.9687e-04, 3.8638e-03, 9.9359e-01, 9.9926e-01, 1.1798e-03, 2.3660e-04,\n",
      "        3.7188e-04, 9.9628e-01, 9.9817e-01, 9.0844e-04, 2.9671e-04, 9.9618e-01,\n",
      "        9.9926e-01, 9.6339e-01, 9.9884e-01, 9.9847e-01, 5.0536e-04, 9.9587e-01,\n",
      "        8.0431e-04, 2.5277e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0137, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06658311188220978\n",
      "2500\n",
      "tensor([5.8340e-02, 9.9954e-01, 9.9856e-01, 6.4008e-04, 9.9917e-01, 9.9753e-01,\n",
      "        6.2844e-04, 9.9870e-01, 3.8866e-01, 1.1711e-03, 1.3273e-03, 9.5411e-01,\n",
      "        9.9686e-01, 9.9295e-01, 9.9758e-01, 4.1975e-04, 1.4227e-03, 7.9049e-04,\n",
      "        1.0884e-02, 1.4042e-03, 9.9937e-01, 9.9530e-01, 7.0366e-04, 1.0240e-03,\n",
      "        8.8950e-04, 2.5752e-01, 8.9433e-01, 4.0861e-03, 7.5332e-04, 9.9919e-01,\n",
      "        4.8779e-02, 6.1004e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06654888391494751\n",
      "2530\n",
      "tensor([9.2275e-03, 9.9334e-01, 9.9225e-01, 9.7593e-01, 9.8548e-01, 2.7164e-02,\n",
      "        9.9947e-01, 2.7006e-03, 9.9929e-01, 5.2927e-04, 1.9031e-02, 9.9925e-01,\n",
      "        6.3253e-02, 1.1595e-03, 9.9926e-01, 9.9938e-01, 2.8457e-04, 8.3643e-04,\n",
      "        9.9351e-01, 9.9493e-01, 9.9813e-01, 9.9918e-01, 9.9925e-01, 9.9246e-01,\n",
      "        9.9944e-01, 1.3118e-03, 9.6873e-01, 1.3254e-03, 5.8914e-04, 9.9853e-01,\n",
      "        8.0402e-01, 8.9949e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0144, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06674585491418839\n",
      "2560\n",
      "tensor([9.9742e-01, 9.9887e-01, 6.0371e-04, 6.8786e-01, 1.8546e-03, 6.6167e-03,\n",
      "        6.3084e-04, 2.8352e-02, 9.8070e-01, 9.9947e-01, 1.0021e-03, 9.9812e-01,\n",
      "        9.3178e-03, 9.9908e-01, 4.8588e-04, 9.8638e-01, 8.4820e-04, 9.9441e-01,\n",
      "        9.9171e-01, 1.8319e-01, 9.9889e-01, 9.9948e-01, 2.5150e-03, 8.2786e-01,\n",
      "        3.5828e-02, 9.9940e-01, 8.5865e-01, 7.6832e-01, 9.9893e-01, 8.0867e-01,\n",
      "        7.3113e-03, 9.9902e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06682790070772171\n",
      "2590\n",
      "tensor([4.6571e-04, 3.9901e-04, 6.9321e-04, 9.9939e-01, 9.9956e-01, 9.9670e-01,\n",
      "        9.9855e-01, 7.7704e-04, 9.9865e-01, 9.9944e-01, 5.0802e-04, 9.1111e-01,\n",
      "        2.7168e-04, 9.9872e-01, 9.9908e-01, 9.9968e-01, 9.9789e-01, 2.4382e-02,\n",
      "        3.5737e-04, 4.6251e-04, 5.1091e-04, 9.7419e-01, 5.6461e-04, 9.9898e-01,\n",
      "        9.9946e-01, 9.6186e-01, 9.9967e-01, 1.0046e-03, 9.9667e-01, 6.1830e-03,\n",
      "        9.9860e-01, 8.9464e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0102, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0665251761674881\n",
      "2620\n",
      "tensor([9.9888e-01, 8.6863e-04, 9.9917e-01, 8.9263e-04, 9.9815e-01, 2.4659e-03,\n",
      "        9.9936e-01, 2.0562e-03, 5.8915e-01, 4.2486e-04, 9.9641e-01, 9.9793e-01,\n",
      "        1.3907e-03, 6.9040e-04, 9.8436e-01, 9.9735e-01, 1.0494e-03, 5.2033e-04,\n",
      "        9.9948e-01, 3.5933e-04, 1.3747e-03, 1.3102e-03, 9.9913e-01, 9.9908e-01,\n",
      "        9.9483e-01, 9.9401e-03, 9.9947e-01, 6.4766e-04, 9.9827e-01, 9.9914e-01,\n",
      "        1.3433e-03, 6.7519e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0186, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06639209389686584\n",
      "2650\n",
      "tensor([9.9477e-01, 1.0103e-03, 6.8505e-03, 9.9402e-01, 9.7444e-01, 9.7923e-01,\n",
      "        9.5821e-04, 1.9584e-03, 9.9974e-01, 9.9888e-01, 7.8408e-03, 1.3338e-02,\n",
      "        5.7125e-04, 9.9506e-01, 9.1123e-04, 9.9741e-01, 2.7757e-03, 9.9708e-01,\n",
      "        4.1589e-03, 6.5640e-03, 7.2418e-04, 9.9659e-01, 3.3931e-01, 9.9645e-01,\n",
      "        9.9875e-01, 9.9936e-01, 9.9803e-01, 5.7528e-04, 9.9932e-01, 9.8979e-01,\n",
      "        9.7931e-01, 7.8244e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0388, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0662844181060791\n",
      "2680\n",
      "tensor([9.9924e-01, 9.8681e-01, 9.9374e-01, 9.9193e-01, 9.9609e-01, 9.9872e-01,\n",
      "        9.9937e-01, 1.6220e-03, 2.9523e-03, 9.9205e-01, 9.2952e-01, 9.9951e-01,\n",
      "        9.9737e-01, 4.8939e-04, 5.6952e-01, 1.9188e-03, 2.4572e-04, 9.9203e-01,\n",
      "        1.1881e-03, 9.9573e-01, 9.9663e-01, 9.9927e-01, 5.4802e-04, 9.9623e-01,\n",
      "        9.9751e-01, 4.8100e-04, 9.9869e-01, 4.5094e-03, 9.9931e-01, 9.9891e-01,\n",
      "        1.0468e-01, 8.2333e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0348, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06602177768945694\n",
      "2710\n",
      "tensor([2.9516e-02, 9.9942e-01, 9.9962e-01, 8.0304e-04, 3.7635e-04, 2.1326e-04,\n",
      "        9.9344e-01, 9.9909e-01, 9.9880e-01, 4.6086e-04, 6.8815e-01, 8.0353e-04,\n",
      "        9.9965e-01, 9.9724e-01, 2.9549e-01, 7.9525e-04, 1.8145e-03, 9.9908e-01,\n",
      "        9.9762e-01, 1.8065e-03, 9.9847e-01, 5.3327e-04, 9.9932e-01, 2.1219e-04,\n",
      "        9.9353e-01, 9.9958e-01, 3.8020e-04, 2.4675e-04, 7.9646e-04, 9.8833e-01,\n",
      "        8.5602e-04, 1.5192e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0251, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06587766855955124\n",
      "2740\n",
      "tensor([6.3254e-04, 9.9945e-01, 1.3169e-03, 9.9921e-01, 9.9876e-01, 9.9943e-01,\n",
      "        1.7497e-02, 9.9931e-01, 9.9889e-01, 2.7572e-03, 2.5290e-01, 5.5932e-02,\n",
      "        5.9850e-04, 9.9978e-01, 9.9870e-01, 6.7576e-02, 9.9922e-01, 2.2807e-03,\n",
      "        1.8254e-03, 9.9925e-01, 5.1186e-04, 9.9755e-01, 3.0216e-04, 6.2922e-04,\n",
      "        9.9972e-01, 9.9560e-01, 9.9906e-01, 1.2050e-03, 1.4190e-03, 9.9962e-01,\n",
      "        9.5888e-01, 4.5036e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0346, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06577319651842117\n",
      "2770\n",
      "tensor([5.1753e-04, 5.1060e-04, 6.9829e-02, 9.9895e-01, 2.7065e-04, 9.9428e-01,\n",
      "        1.4380e-03, 9.9403e-01, 9.9934e-01, 4.8615e-04, 3.0944e-04, 8.6675e-01,\n",
      "        1.1528e-03, 1.9983e-03, 9.9739e-01, 9.9766e-01, 2.1290e-03, 7.5620e-01,\n",
      "        1.1113e-03, 3.6749e-01, 9.0030e-02, 9.9903e-01, 9.9968e-01, 9.9882e-01,\n",
      "        9.9790e-01, 1.1626e-03, 9.9828e-01, 4.2895e-04, 9.9929e-01, 7.6160e-04,\n",
      "        9.9672e-01, 9.9776e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0341, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0658409520983696\n",
      "2800\n",
      "tensor([9.9932e-01, 2.0396e-03, 1.2086e-03, 1.1693e-03, 9.9856e-01, 3.7205e-04,\n",
      "        7.6879e-02, 9.8385e-01, 5.2147e-04, 9.9832e-01, 9.9821e-01, 9.9724e-01,\n",
      "        4.9191e-04, 5.4514e-04, 9.9111e-01, 1.4183e-03, 2.4477e-03, 5.7593e-04,\n",
      "        6.1710e-01, 9.9194e-01, 2.4975e-04, 9.9882e-01, 1.8237e-02, 9.9977e-01,\n",
      "        6.1559e-03, 5.3584e-04, 4.5206e-01, 8.5589e-04, 9.9351e-01, 9.9294e-01,\n",
      "        9.2068e-04, 8.9611e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0488, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0657515898346901\n",
      "2830\n",
      "tensor([9.9815e-01, 9.3538e-01, 1.8688e-01, 9.9840e-01, 8.0187e-04, 3.9206e-04,\n",
      "        6.4430e-03, 2.4754e-04, 1.3394e-02, 2.7813e-04, 5.7497e-04, 2.2912e-03,\n",
      "        6.3526e-04, 9.9318e-01, 1.2444e-03, 5.2633e-04, 5.1347e-04, 7.6673e-04,\n",
      "        5.5082e-04, 2.9456e-03, 9.9827e-01, 1.2531e-03, 9.9798e-01, 9.9776e-01,\n",
      "        9.9477e-01, 9.9906e-01, 9.7967e-01, 1.8056e-01, 9.9576e-01, 2.7779e-03,\n",
      "        3.9923e-04, 9.9522e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1386, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06569672375917435\n",
      "2860\n",
      "tensor([9.9881e-01, 9.8400e-01, 9.9941e-01, 9.9518e-01, 9.9712e-01, 9.9779e-01,\n",
      "        2.6007e-03, 2.9945e-04, 8.4293e-04, 3.2087e-03, 9.9760e-01, 9.9901e-01,\n",
      "        4.2683e-04, 9.6506e-01, 9.9892e-01, 9.9934e-01, 6.2466e-04, 4.7924e-04,\n",
      "        1.3056e-04, 9.9756e-01, 9.9904e-01, 9.9971e-01, 1.7085e-03, 1.8646e-03,\n",
      "        1.0843e-02, 9.9910e-01, 9.9926e-01, 9.9931e-01, 2.0552e-03, 1.5761e-03,\n",
      "        4.6636e-04, 1.9577e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0032, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06578080356121063\n",
      "2890\n",
      "tensor([8.7891e-04, 9.9614e-01, 9.9981e-01, 8.7401e-03, 9.0524e-01, 3.7480e-01,\n",
      "        9.9782e-01, 3.5365e-03, 3.5867e-04, 9.8865e-01, 4.1780e-04, 1.0185e-03,\n",
      "        9.0269e-04, 9.9565e-01, 5.0967e-04, 9.9573e-01, 2.5208e-02, 3.3561e-03,\n",
      "        5.6376e-04, 9.8745e-01, 8.2390e-04, 1.1716e-03, 9.9764e-01, 9.9549e-01,\n",
      "        2.4233e-04, 3.7964e-04, 1.0813e-03, 8.8820e-02, 9.9934e-01, 6.8015e-04,\n",
      "        9.6152e-01, 4.7349e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0657377764582634\n",
      "2920\n",
      "tensor([9.9936e-01, 1.7547e-01, 8.9229e-01, 9.3444e-01, 5.1911e-02, 2.0273e-03,\n",
      "        9.3141e-01, 1.6015e-02, 3.3995e-03, 9.9891e-01, 4.8016e-02, 9.9899e-01,\n",
      "        9.9942e-01, 9.9219e-01, 9.9758e-01, 9.9733e-01, 7.6701e-01, 9.9939e-01,\n",
      "        9.9269e-01, 4.4437e-03, 1.3587e-03, 1.0369e-03, 2.6201e-04, 9.9260e-01,\n",
      "        9.9889e-01, 1.3399e-01, 1.5993e-03, 9.9817e-01, 1.3453e-03, 9.9474e-01,\n",
      "        9.9839e-01, 9.9799e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0323, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06567208468914032\n",
      "2950\n",
      "tensor([2.0328e-03, 9.8678e-01, 5.3709e-04, 8.1479e-01, 9.9620e-01, 3.2753e-03,\n",
      "        4.1015e-03, 3.9119e-03, 9.9810e-01, 6.5452e-03, 9.9847e-01, 9.9668e-01,\n",
      "        8.9970e-01, 2.4768e-01, 9.9835e-01, 9.7274e-01, 1.2625e-03, 2.5509e-04,\n",
      "        9.9745e-01, 3.3085e-04, 4.5728e-04, 4.9839e-04, 9.7512e-01, 7.9749e-01,\n",
      "        3.1363e-03, 1.3585e-03, 9.9231e-01, 5.0920e-02, 7.3036e-02, 9.8923e-01,\n",
      "        1.0104e-03, 5.0887e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06562454253435135\n",
      "2980\n",
      "tensor([9.9759e-01, 4.6461e-04, 3.7222e-04, 4.9784e-04, 9.9646e-01, 4.1836e-04,\n",
      "        9.9958e-01, 1.9180e-04, 5.5603e-04, 9.9769e-01, 1.4338e-03, 9.9817e-01,\n",
      "        9.9944e-01, 4.9014e-03, 6.9841e-04, 9.9962e-01, 3.3814e-04, 3.9974e-04,\n",
      "        9.9792e-01, 9.9884e-01, 9.9961e-01, 9.9733e-01, 9.9767e-01, 9.9678e-01,\n",
      "        9.9887e-01, 9.8297e-01, 9.9943e-01, 2.2138e-01, 9.9916e-01, 2.4517e-04,\n",
      "        5.4796e-04, 9.9636e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3417, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06561608612537384\n",
      "3010\n",
      "tensor([7.4022e-03, 5.3724e-04, 9.9364e-01, 8.6664e-01, 8.5035e-04, 7.4372e-04,\n",
      "        9.9761e-01, 5.2612e-02, 8.8215e-02, 9.9761e-01, 9.9427e-01, 3.7503e-04,\n",
      "        2.7309e-03, 9.8846e-01, 9.9587e-01, 7.6697e-02, 9.9065e-01, 5.9310e-04,\n",
      "        5.3196e-03, 7.3568e-04, 9.9863e-01, 9.9772e-01, 9.8662e-01, 6.5883e-01,\n",
      "        6.5554e-04, 5.1137e-04, 2.3397e-04, 2.6330e-04, 1.5720e-03, 5.3077e-04,\n",
      "        9.9905e-01, 4.2944e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0272, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.065602608025074\n",
      "3040\n",
      "tensor([9.9753e-01, 9.9908e-01, 5.4412e-04, 1.0918e-03, 5.2936e-01, 9.9932e-01,\n",
      "        3.1841e-03, 9.9701e-01, 8.8584e-01, 9.9844e-01, 9.9955e-01, 1.1472e-03,\n",
      "        1.7461e-02, 1.4793e-03, 1.4182e-01, 9.9899e-01, 5.1966e-04, 8.9733e-04,\n",
      "        9.9857e-01, 9.9936e-01, 3.9776e-04, 8.2375e-04, 5.1512e-04, 8.6811e-04,\n",
      "        9.9756e-01, 5.0862e-04, 9.9644e-01, 4.1392e-03, 9.9905e-01, 4.6638e-02,\n",
      "        4.1367e-03, 9.9949e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0317, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06551063805818558\n",
      "3070\n",
      "tensor([9.9833e-01, 5.7785e-01, 9.9945e-01, 9.9710e-01, 2.4251e-04, 6.3739e-01,\n",
      "        9.1186e-01, 3.2040e-04, 9.9945e-01, 9.9931e-01, 7.0481e-04, 9.9925e-01,\n",
      "        9.9503e-01, 3.2617e-01, 7.6860e-04, 5.4793e-04, 9.9949e-01, 9.9567e-01,\n",
      "        9.9903e-01, 8.4191e-01, 9.9937e-01, 9.9789e-01, 9.9910e-01, 9.9840e-01,\n",
      "        1.0478e-03, 9.9944e-01, 9.9919e-01, 9.9903e-01, 9.9736e-01, 1.2666e-03,\n",
      "        9.9938e-01, 9.7462e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0537, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06541463732719421\n",
      "3100\n",
      "tensor([1.2981e-03, 9.9815e-01, 2.1267e-04, 2.9427e-03, 9.9960e-01, 9.9941e-01,\n",
      "        3.9303e-04, 1.0706e-02, 9.9892e-01, 9.0390e-01, 9.9948e-01, 8.2079e-04,\n",
      "        2.5035e-03, 7.5091e-01, 1.3610e-03, 4.1390e-04, 3.1077e-03, 3.0445e-01,\n",
      "        9.9271e-01, 1.9833e-04, 9.9768e-01, 9.9868e-01, 6.2686e-02, 9.5443e-01,\n",
      "        9.9969e-01, 9.9959e-01, 9.9862e-01, 1.2654e-02, 6.0736e-01, 9.9935e-01,\n",
      "        2.4450e-03, 2.5639e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1778, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06572482734918594\n",
      "3130\n",
      "tensor([7.2076e-04, 1.2002e-03, 4.4309e-04, 9.9963e-01, 8.2544e-04, 1.0810e-02,\n",
      "        1.8999e-03, 9.9051e-01, 2.5006e-03, 9.9844e-01, 9.9770e-01, 4.7139e-04,\n",
      "        8.2711e-04, 9.9915e-01, 9.9614e-01, 9.1324e-01, 3.7695e-04, 6.9885e-04,\n",
      "        9.9846e-01, 9.8530e-01, 9.9739e-01, 9.4685e-04, 9.9952e-01, 6.5346e-04,\n",
      "        2.3451e-03, 7.6417e-04, 8.2287e-04, 9.9968e-01, 9.9898e-01, 9.9947e-01,\n",
      "        1.5444e-03, 9.9543e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0051, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0656416043639183\n",
      "3160\n",
      "tensor([9.9704e-01, 9.9907e-01, 9.9940e-01, 9.6346e-01, 9.9488e-01, 9.9401e-01,\n",
      "        2.7904e-02, 1.8547e-03, 9.9951e-01, 7.0709e-04, 6.7585e-03, 7.6904e-04,\n",
      "        8.7959e-03, 2.7488e-03, 9.5229e-01, 9.9264e-01, 9.9198e-01, 9.9797e-01,\n",
      "        1.3329e-03, 2.6261e-03, 9.5687e-03, 9.9873e-01, 5.2901e-03, 8.9281e-01,\n",
      "        9.2393e-04, 9.8792e-01, 2.3184e-03, 1.1063e-02, 9.9841e-01, 9.9491e-01,\n",
      "        7.8866e-04, 9.6493e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0117, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06555825471878052\n",
      "3190\n",
      "tensor([9.9930e-01, 5.1021e-04, 9.9803e-01, 5.9764e-04, 9.3054e-04, 9.9852e-01,\n",
      "        9.5624e-04, 9.9441e-01, 1.0059e-03, 9.9958e-01, 7.7098e-04, 6.5713e-04,\n",
      "        9.9906e-01, 9.9964e-01, 1.0313e-03, 2.2329e-04, 9.9906e-01, 1.4012e-03,\n",
      "        9.9867e-01, 8.2590e-04, 9.9962e-01, 5.5347e-01, 1.1058e-03, 9.9202e-01,\n",
      "        2.4653e-02, 1.2971e-03, 9.9702e-01, 9.9901e-01, 9.9915e-01, 9.9847e-01,\n",
      "        9.9964e-01, 3.8509e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0274, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06548024713993073\n",
      "3220\n",
      "tensor([9.9951e-01, 1.8678e-03, 9.9561e-01, 9.9682e-01, 9.9959e-01, 9.9932e-01,\n",
      "        9.9933e-01, 9.9918e-01, 6.2386e-02, 9.9050e-01, 9.9893e-01, 5.3345e-03,\n",
      "        2.6966e-03, 9.9950e-01, 2.1589e-01, 9.6820e-01, 9.3885e-01, 4.9068e-04,\n",
      "        9.9157e-01, 8.5538e-04, 9.9824e-01, 9.9926e-01, 9.9429e-01, 9.9959e-01,\n",
      "        8.2219e-03, 9.9948e-01, 4.2354e-04, 5.1068e-01, 1.5996e-02, 9.9893e-01,\n",
      "        1.1043e-03, 8.0861e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06534692645072937\n",
      "3250\n",
      "tensor([9.9923e-01, 9.9920e-01, 9.9784e-01, 8.2097e-04, 1.5996e-03, 4.5557e-04,\n",
      "        1.0121e-02, 9.9658e-01, 9.9727e-01, 7.2558e-01, 9.9946e-01, 1.0797e-03,\n",
      "        9.9879e-01, 9.0084e-01, 2.9978e-02, 9.9866e-01, 9.9339e-01, 9.9881e-01,\n",
      "        7.2338e-04, 4.6112e-04, 3.4059e-04, 1.5933e-03, 9.9694e-01, 1.2780e-03,\n",
      "        9.9963e-01, 9.9890e-01, 5.7282e-04, 1.6898e-03, 9.9522e-01, 1.5193e-01,\n",
      "        3.1847e-03, 9.9637e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0516, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06537573784589767\n",
      "3280\n",
      "tensor([1.0412e-02, 9.9916e-01, 9.9900e-01, 9.9913e-01, 9.9724e-01, 9.9820e-01,\n",
      "        9.9895e-01, 9.9937e-01, 9.9946e-01, 9.9942e-01, 9.6068e-01, 9.9974e-01,\n",
      "        5.4863e-04, 1.0321e-03, 1.2053e-03, 2.6619e-01, 4.8631e-03, 1.2351e-03,\n",
      "        1.0018e-03, 1.4339e-03, 9.9595e-01, 9.9901e-01, 9.9963e-01, 7.0476e-04,\n",
      "        1.2063e-03, 5.2189e-03, 9.9677e-01, 9.0217e-01, 7.5327e-01, 9.9892e-01,\n",
      "        9.9912e-01, 8.1423e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1593, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06511038541793823\n",
      "3310\n",
      "tensor([8.7852e-01, 1.3785e-01, 8.3009e-01, 9.6671e-01, 9.9810e-01, 5.0249e-02,\n",
      "        2.5990e-03, 2.0758e-03, 9.9921e-01, 1.6512e-03, 1.6214e-03, 9.9928e-01,\n",
      "        9.9939e-01, 9.9868e-01, 1.1424e-03, 1.9407e-01, 2.4296e-03, 1.6405e-03,\n",
      "        1.5539e-02, 1.6892e-03, 9.9888e-01, 9.9863e-01, 9.9869e-01, 9.9911e-01,\n",
      "        9.1445e-01, 9.9768e-01, 9.9861e-01, 9.9597e-01, 1.1219e-03, 9.8873e-01,\n",
      "        3.8666e-04, 9.9928e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0286, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06520478427410126\n",
      "3340\n",
      "tensor([5.6278e-02, 1.1902e-03, 9.9547e-01, 9.9687e-01, 9.9838e-01, 3.0426e-03,\n",
      "        9.3595e-03, 9.6995e-01, 9.9917e-01, 6.5424e-03, 9.9888e-01, 2.5016e-03,\n",
      "        8.9372e-04, 9.9769e-01, 8.0366e-04, 2.5614e-03, 3.1199e-01, 5.0562e-03,\n",
      "        7.6679e-01, 8.8936e-02, 1.0177e-01, 1.1320e-03, 9.9928e-01, 9.9897e-01,\n",
      "        2.3355e-03, 3.7415e-04, 4.7342e-02, 9.9798e-01, 3.1974e-04, 4.6255e-04,\n",
      "        9.9939e-01, 9.8304e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1638, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06512421369552612\n",
      "3370\n",
      "tensor([1.0080e-02, 1.2763e-03, 3.5219e-03, 9.9623e-01, 9.9422e-01, 9.9847e-01,\n",
      "        1.3388e-03, 3.3510e-04, 1.0620e-03, 1.7198e-03, 9.5466e-01, 1.9401e-03,\n",
      "        6.8561e-04, 1.3910e-03, 9.9965e-01, 2.1807e-03, 6.0409e-04, 9.9741e-01,\n",
      "        8.0476e-04, 9.9099e-01, 9.9805e-01, 9.9881e-01, 5.3823e-02, 9.1674e-01,\n",
      "        9.9926e-01, 2.1401e-03, 4.4059e-02, 6.7391e-01, 1.1890e-03, 9.9898e-01,\n",
      "        6.5157e-04, 9.9386e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2493, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06509558856487274\n",
      "3400\n",
      "tensor([9.5950e-04, 2.6150e-03, 1.0138e-03, 9.9896e-01, 9.9888e-01, 9.6696e-03,\n",
      "        9.9710e-01, 9.8377e-01, 9.9873e-01, 2.2480e-03, 9.9851e-01, 9.9628e-01,\n",
      "        9.9733e-01, 9.9762e-01, 4.3921e-04, 2.9437e-02, 4.8326e-01, 9.8725e-01,\n",
      "        9.9795e-01, 9.9889e-01, 4.5935e-03, 2.2953e-03, 9.9835e-01, 9.9944e-01,\n",
      "        1.0731e-03, 9.1189e-04, 1.6265e-03, 9.5142e-01, 2.3507e-03, 9.9767e-01,\n",
      "        1.8919e-03, 9.9386e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0260, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06493428349494934\n",
      "3430\n",
      "tensor([1.0647e-02, 9.9712e-01, 9.9408e-01, 8.5650e-03, 6.3363e-02, 4.5548e-04,\n",
      "        8.4373e-04, 1.0690e-03, 9.9963e-01, 9.9158e-01, 5.0318e-03, 1.6202e-03,\n",
      "        4.0558e-04, 9.9777e-01, 9.9921e-01, 9.9761e-01, 9.9353e-01, 9.9819e-01,\n",
      "        3.6518e-04, 1.2146e-03, 9.9917e-01, 9.9961e-01, 8.3866e-01, 9.9726e-01,\n",
      "        9.9884e-01, 1.2433e-02, 9.9905e-01, 2.0593e-03, 1.7652e-03, 1.8553e-03,\n",
      "        9.9914e-01, 9.9654e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0619, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0647774487733841\n",
      "3460\n",
      "tensor([3.8199e-03, 1.4954e-02, 1.3297e-03, 3.3465e-01, 9.9914e-01, 9.9787e-01,\n",
      "        5.0404e-03, 1.4927e-03, 9.9778e-01, 1.3989e-02, 9.9723e-01, 9.9814e-01,\n",
      "        9.9922e-01, 5.1194e-01, 2.9881e-03, 9.9158e-01, 1.2223e-03, 9.9619e-01,\n",
      "        9.8368e-01, 9.9827e-01, 9.9920e-01, 1.0905e-03, 5.6275e-04, 9.9765e-01,\n",
      "        9.9941e-01, 9.7112e-01, 8.8175e-04, 2.1469e-03, 9.9757e-01, 9.9892e-01,\n",
      "        3.9326e-03, 2.5619e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0593, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06474408507347107\n",
      "3490\n",
      "tensor([7.7517e-01, 9.7695e-01, 9.9901e-01, 2.2990e-03, 9.9889e-01, 1.3196e-03,\n",
      "        9.9601e-01, 1.2062e-03, 1.5125e-03, 4.5277e-01, 9.9853e-01, 9.4511e-04,\n",
      "        1.7261e-03, 4.8323e-04, 9.9850e-01, 6.4143e-04, 8.0760e-04, 9.7913e-01,\n",
      "        9.9912e-01, 1.1692e-03, 8.5471e-04, 6.4310e-04, 6.5835e-04, 6.1648e-02,\n",
      "        9.9625e-01, 1.5624e-03, 2.9295e-03, 2.7569e-03, 5.1176e-04, 1.4062e-03,\n",
      "        1.1743e-03, 6.2538e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06457318365573883\n",
      "3520\n",
      "tensor([6.0974e-01, 1.2906e-03, 1.0688e-03, 1.0467e-03, 9.9893e-01, 8.3909e-03,\n",
      "        5.3477e-04, 1.2323e-03, 9.9941e-01, 9.9615e-01, 1.4742e-02, 9.9807e-01,\n",
      "        4.3918e-04, 5.4580e-04, 1.9462e-03, 9.9798e-01, 9.9721e-01, 4.0326e-03,\n",
      "        9.9543e-01, 8.1929e-01, 7.2745e-04, 2.4588e-03, 2.8486e-03, 1.2061e-03,\n",
      "        5.0550e-04, 1.3556e-02, 9.9818e-01, 9.9944e-01, 1.7946e-03, 3.5503e-04,\n",
      "        9.9456e-01, 9.9869e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06451521813869476\n",
      "3550\n",
      "tensor([9.9774e-01, 6.9109e-02, 8.7831e-04, 1.4162e-03, 1.4132e-03, 9.9894e-01,\n",
      "        4.5304e-03, 2.7835e-03, 1.4021e-03, 9.9928e-01, 3.4588e-01, 2.6210e-03,\n",
      "        2.9451e-02, 2.2627e-03, 1.9621e-03, 9.9897e-01, 9.4597e-04, 4.4639e-03,\n",
      "        1.8893e-03, 2.9665e-03, 2.7446e-01, 1.9506e-03, 1.5524e-03, 9.9781e-01,\n",
      "        9.9436e-01, 1.8138e-02, 9.8944e-01, 9.5735e-01, 9.9886e-01, 8.4780e-03,\n",
      "        6.9231e-03, 9.9454e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0309, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06466282904148102\n",
      "3580\n",
      "tensor([9.9937e-01, 9.9546e-01, 9.9916e-01, 9.9473e-01, 9.9880e-01, 9.9907e-01,\n",
      "        9.8913e-01, 3.1509e-03, 9.9736e-01, 7.5068e-04, 9.9922e-01, 9.8411e-01,\n",
      "        9.9893e-01, 7.8432e-03, 2.5292e-01, 9.9827e-01, 5.5941e-04, 9.9930e-01,\n",
      "        1.1483e-02, 9.9898e-01, 9.9801e-01, 1.5933e-03, 9.9643e-01, 5.3455e-02,\n",
      "        9.9938e-01, 9.9904e-01, 9.9864e-01, 8.5296e-01, 9.9884e-01, 9.9926e-01,\n",
      "        4.6229e-04, 9.9717e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0185, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06454683095216751\n",
      "3610\n",
      "tensor([2.1772e-03, 8.0991e-03, 9.9767e-01, 1.4859e-03, 9.9789e-01, 2.1877e-02,\n",
      "        9.9871e-01, 1.1199e-03, 9.9835e-01, 4.4107e-04, 4.6712e-03, 9.9939e-01,\n",
      "        9.9929e-01, 9.9802e-01, 6.7693e-03, 9.9969e-01, 6.7180e-03, 3.6304e-03,\n",
      "        9.9909e-01, 9.9830e-01, 9.9977e-01, 5.8742e-03, 2.7832e-03, 9.9909e-01,\n",
      "        2.0470e-03, 9.9941e-01, 6.0558e-04, 6.5140e-04, 9.9866e-01, 3.2461e-01,\n",
      "        9.9907e-01, 9.9714e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0151, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06449464708566666\n",
      "3640\n",
      "tensor([1.8129e-03, 6.0049e-04, 9.9940e-01, 1.6885e-02, 9.9903e-01, 9.9580e-01,\n",
      "        1.3186e-02, 9.9814e-01, 4.2629e-03, 9.6409e-01, 9.9849e-01, 9.9755e-01,\n",
      "        9.9093e-01, 3.2498e-01, 9.7563e-01, 1.1911e-03, 9.9920e-01, 6.3115e-03,\n",
      "        9.9651e-01, 2.3431e-03, 9.9930e-01, 7.0282e-02, 9.9959e-01, 6.0964e-02,\n",
      "        9.9551e-01, 9.7390e-01, 1.3393e-01, 9.9897e-01, 9.9776e-01, 4.2042e-03,\n",
      "        9.9837e-01, 9.9428e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0266, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0645219013094902\n",
      "3670\n",
      "tensor([9.9806e-01, 1.0212e-03, 9.9849e-01, 5.6372e-04, 9.9906e-01, 1.8436e-02,\n",
      "        4.3736e-03, 2.7835e-04, 9.9939e-01, 2.0904e-03, 3.1794e-03, 6.9593e-02,\n",
      "        2.4109e-03, 4.7495e-03, 4.4192e-04, 1.1415e-03, 2.5233e-03, 9.0781e-04,\n",
      "        1.8407e-01, 1.7443e-03, 1.2690e-03, 1.3297e-03, 9.9904e-01, 9.9762e-01,\n",
      "        5.6299e-04, 9.8305e-04, 9.9967e-01, 9.9676e-01, 9.9787e-01, 9.9828e-01,\n",
      "        6.0261e-03, 1.1335e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0108, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06437066942453384\n",
      "3700\n",
      "tensor([1.2203e-03, 9.9821e-01, 9.9496e-01, 9.9938e-01, 2.2119e-03, 1.6256e-03,\n",
      "        9.8116e-01, 7.4797e-03, 1.7567e-01, 8.9986e-01, 9.9860e-01, 1.4977e-03,\n",
      "        9.9908e-01, 1.0732e-03, 9.9963e-01, 9.9950e-01, 6.4546e-04, 3.0409e-03,\n",
      "        4.5124e-03, 9.9808e-01, 9.9925e-01, 9.9798e-01, 2.3222e-03, 6.9594e-04,\n",
      "        9.9677e-01, 9.9900e-01, 9.8648e-04, 9.9280e-01, 9.9780e-01, 2.1248e-02,\n",
      "        4.0421e-03, 2.6559e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0643186941742897\n",
      "3730\n",
      "tensor([9.9925e-01, 9.8495e-04, 1.0942e-02, 3.0019e-03, 2.4923e-03, 9.8368e-03,\n",
      "        2.3817e-03, 1.1401e-02, 3.0542e-02, 8.4169e-04, 9.9014e-01, 9.5638e-01,\n",
      "        9.9703e-01, 9.9592e-01, 9.8994e-01, 1.0901e-02, 9.9590e-01, 9.9363e-01,\n",
      "        9.9636e-01, 9.6829e-01, 9.9939e-01, 9.9943e-01, 5.3591e-04, 9.0983e-02,\n",
      "        3.1346e-03, 9.9948e-01, 9.9895e-01, 9.9158e-01, 2.2652e-02, 4.2525e-02,\n",
      "        2.9118e-03, 9.8493e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0124, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06424335390329361\n",
      "3760\n",
      "tensor([9.9715e-01, 8.1715e-04, 8.3322e-01, 2.8076e-02, 9.9536e-01, 1.7804e-01,\n",
      "        9.9853e-01, 9.9932e-01, 9.9891e-01, 9.9518e-01, 9.9922e-01, 9.9307e-01,\n",
      "        5.8404e-02, 1.0051e-03, 4.9404e-02, 5.9236e-03, 9.9381e-01, 9.9560e-01,\n",
      "        9.9885e-01, 9.9746e-01, 4.8601e-04, 9.9756e-01, 9.6664e-04, 9.9815e-01,\n",
      "        9.9269e-01, 9.6437e-04, 9.9930e-01, 1.1233e-03, 9.9939e-01, 4.6785e-02,\n",
      "        6.0646e-03, 9.9072e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0201, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0642763152718544\n",
      "3790\n",
      "tensor([2.0649e-01, 2.5136e-02, 9.9897e-01, 8.9905e-04, 9.9876e-01, 9.9660e-01,\n",
      "        2.8117e-03, 9.9927e-01, 8.7445e-01, 5.2827e-04, 3.6202e-04, 9.9936e-01,\n",
      "        9.9804e-01, 9.9891e-01, 9.5534e-01, 9.9407e-01, 1.5549e-02, 9.9651e-01,\n",
      "        9.9341e-01, 1.4867e-03, 1.4064e-03, 3.6907e-02, 7.4156e-03, 9.9772e-01,\n",
      "        9.9935e-01, 1.5362e-03, 2.6454e-03, 9.8279e-01, 8.0020e-04, 7.8829e-01,\n",
      "        1.5666e-02, 7.6551e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1213, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06429611891508102\n",
      "3820\n",
      "tensor([2.8356e-01, 9.7440e-01, 9.9906e-01, 1.7796e-03, 8.7357e-04, 7.6463e-04,\n",
      "        6.3083e-02, 3.5538e-03, 4.6108e-01, 8.3531e-04, 4.0083e-02, 8.8297e-04,\n",
      "        9.9904e-01, 9.9902e-01, 9.9911e-01, 9.9762e-01, 9.9775e-01, 9.9871e-01,\n",
      "        9.9921e-01, 9.9950e-01, 1.8759e-03, 6.0033e-03, 4.5243e-02, 9.9817e-01,\n",
      "        9.9802e-01, 9.9775e-01, 9.9932e-01, 8.4031e-04, 9.0770e-01, 9.5343e-01,\n",
      "        9.9653e-01, 9.9923e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0411, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06421123445034027\n",
      "3850\n",
      "tensor([9.9844e-01, 1.5042e-02, 9.6291e-01, 2.0825e-03, 9.9726e-01, 9.9840e-01,\n",
      "        6.2686e-04, 3.2896e-01, 3.8863e-03, 6.8998e-03, 9.9969e-01, 9.9104e-01,\n",
      "        7.5071e-04, 9.9865e-01, 9.3207e-04, 1.5064e-03, 1.0667e-03, 9.4453e-01,\n",
      "        9.9946e-01, 9.9492e-01, 9.9949e-01, 7.3851e-04, 1.6750e-03, 9.8866e-01,\n",
      "        9.9963e-01, 9.9721e-01, 1.0080e-03, 1.3776e-03, 7.0585e-03, 9.9944e-01,\n",
      "        9.6919e-01, 9.9930e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0190, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06413589417934418\n",
      "3880\n",
      "tensor([9.9584e-01, 2.1974e-03, 4.1288e-01, 1.4125e-03, 1.0529e-03, 9.9821e-01,\n",
      "        4.7282e-03, 1.2379e-02, 9.9882e-01, 9.9813e-01, 9.9800e-01, 9.9757e-01,\n",
      "        8.3884e-03, 9.9891e-01, 6.8434e-01, 3.9931e-04, 9.3669e-01, 2.6420e-03,\n",
      "        9.9870e-01, 9.9626e-01, 9.7252e-01, 9.9632e-01, 9.8673e-01, 9.9845e-01,\n",
      "        9.9937e-01, 9.9915e-01, 1.1238e-03, 9.9964e-01, 1.4168e-03, 1.5335e-03,\n",
      "        1.5691e-01, 1.0468e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0502, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06415875256061554\n",
      "3910\n",
      "tensor([4.6730e-03, 9.9831e-01, 9.9689e-01, 1.4862e-03, 9.9959e-01, 9.9934e-01,\n",
      "        9.9027e-01, 1.0562e-03, 9.9907e-01, 9.9907e-01, 9.9900e-01, 1.4414e-03,\n",
      "        1.4980e-03, 9.9937e-01, 1.0983e-02, 9.9937e-01, 8.3389e-01, 5.5760e-04,\n",
      "        9.9790e-01, 3.2234e-03, 9.9746e-01, 5.7168e-03, 9.1263e-03, 4.2734e-03,\n",
      "        9.9759e-01, 4.2745e-04, 1.9236e-02, 7.3197e-03, 7.4213e-04, 9.9746e-01,\n",
      "        9.9849e-01, 9.9901e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0089, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0641157254576683\n",
      "3940\n",
      "tensor([5.3890e-04, 9.9627e-01, 9.9896e-01, 9.9813e-01, 3.0112e-03, 1.7883e-02,\n",
      "        1.7311e-03, 9.9767e-01, 5.9379e-04, 9.7840e-04, 5.6018e-03, 7.8671e-01,\n",
      "        9.4901e-01, 1.5428e-03, 9.0071e-02, 4.2543e-04, 9.9969e-01, 1.7374e-03,\n",
      "        9.9836e-01, 1.4121e-03, 9.9692e-01, 1.6366e-03, 1.0921e-03, 9.9358e-01,\n",
      "        9.9671e-01, 9.9584e-01, 9.9929e-01, 1.3218e-02, 2.8153e-02, 9.9856e-01,\n",
      "        9.9832e-01, 7.1856e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0259, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06405927985906601\n",
      "3970\n",
      "tensor([3.8933e-03, 4.7851e-03, 9.8016e-01, 8.9142e-01, 9.8545e-01, 9.9706e-01,\n",
      "        3.4660e-03, 2.4562e-03, 7.0854e-03, 8.1317e-03, 1.2258e-03, 9.9861e-01,\n",
      "        5.5673e-02, 3.5326e-01, 9.9789e-01, 9.2650e-01, 9.9921e-01, 1.2750e-02,\n",
      "        1.4926e-02, 2.4687e-03, 3.3227e-03, 9.9832e-01, 9.8241e-01, 3.4924e-03,\n",
      "        5.1586e-01, 9.2355e-04, 7.0454e-03, 1.1089e-03, 2.4916e-03, 9.9977e-01,\n",
      "        3.4469e-03, 8.9660e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06408707797527313\n",
      "4000\n",
      "tensor([5.0301e-04, 3.5229e-04, 1.8440e-02, 9.9625e-01, 5.9181e-04, 8.8643e-04,\n",
      "        9.9953e-01, 1.6388e-01, 9.9540e-01, 1.3805e-03, 3.1615e-03, 9.9525e-01,\n",
      "        9.9792e-01, 9.9685e-01, 9.9972e-01, 3.6476e-01, 9.0769e-04, 9.9802e-01,\n",
      "        1.2182e-02, 1.3587e-03, 6.4488e-03, 3.9991e-03, 9.9549e-01, 2.7374e-03,\n",
      "        9.9933e-01, 3.1512e-04, 9.9820e-01, 2.0239e-03, 9.9717e-01, 9.9807e-01,\n",
      "        3.8320e-04, 9.9356e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0228, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0640626847743988\n",
      "4030\n",
      "tensor([9.3146e-04, 1.4196e-03, 9.9965e-01, 2.6888e-03, 9.9913e-01, 9.9905e-01,\n",
      "        9.9812e-01, 3.1647e-03, 9.1299e-01, 9.9555e-01, 1.5060e-03, 8.5422e-03,\n",
      "        1.0533e-03, 9.9758e-01, 3.2907e-03, 6.7262e-04, 1.7452e-02, 1.1603e-01,\n",
      "        8.3935e-04, 3.2864e-03, 4.1086e-03, 3.9256e-03, 6.3518e-01, 1.6760e-03,\n",
      "        9.9763e-01, 9.9968e-01, 9.9769e-01, 3.1884e-03, 5.9312e-04, 8.8156e-03,\n",
      "        9.9961e-01, 6.5455e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.3020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06405341625213623\n",
      "4060\n",
      "tensor([9.9778e-01, 9.9965e-01, 2.1695e-01, 1.2406e-03, 9.8942e-01, 2.5722e-03,\n",
      "        9.9916e-01, 1.0220e-02, 2.8344e-01, 2.0947e-02, 9.9928e-01, 1.4545e-03,\n",
      "        1.0837e-03, 9.9941e-01, 9.9948e-01, 9.9905e-01, 9.9923e-01, 9.9840e-01,\n",
      "        3.0188e-01, 9.8635e-01, 8.8756e-04, 1.8068e-03, 9.9915e-01, 9.9932e-01,\n",
      "        5.3460e-04, 2.6909e-03, 5.5993e-02, 6.4644e-03, 9.9929e-01, 9.9915e-01,\n",
      "        1.0096e-03, 5.9848e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0357, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06394103169441223\n",
      "4090\n",
      "tensor([9.0540e-03, 9.9457e-01, 9.9949e-01, 1.5000e-03, 9.9250e-01, 9.9960e-01,\n",
      "        9.9761e-01, 9.9592e-01, 4.2992e-02, 2.6888e-04, 9.9711e-01, 9.9943e-01,\n",
      "        7.1134e-04, 4.7849e-03, 9.9867e-01, 9.8195e-01, 9.9904e-01, 1.1658e-03,\n",
      "        9.9799e-01, 9.9411e-01, 7.0756e-02, 9.9941e-01, 2.2845e-02, 8.4611e-04,\n",
      "        9.9907e-01, 7.2595e-02, 9.9835e-01, 9.9829e-01, 3.4141e-03, 8.0431e-04,\n",
      "        9.9909e-01, 7.9751e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0093, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06390200555324554\n",
      "4120\n",
      "tensor([9.9747e-01, 9.9376e-01, 9.9843e-01, 8.1583e-04, 1.9083e-02, 9.8778e-01,\n",
      "        9.1292e-01, 7.2397e-04, 3.2306e-03, 4.3757e-03, 1.5198e-02, 5.4233e-03,\n",
      "        9.9595e-01, 9.9393e-01, 9.9739e-01, 4.9068e-03, 9.9936e-01, 1.5694e-03,\n",
      "        4.2130e-04, 9.9332e-01, 3.9152e-03, 2.8981e-04, 9.2024e-04, 9.9359e-01,\n",
      "        6.1690e-04, 1.6884e-03, 7.3689e-01, 9.8811e-01, 6.0514e-04, 9.9910e-01,\n",
      "        5.8035e-03, 9.9805e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0166, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06390763074159622\n",
      "4150\n",
      "tensor([5.1888e-03, 9.9961e-01, 2.9987e-03, 9.9619e-01, 1.1741e-01, 9.9890e-01,\n",
      "        9.9480e-01, 1.0762e-03, 9.9927e-01, 5.1517e-04, 1.0226e-03, 8.3668e-01,\n",
      "        4.5651e-02, 7.4208e-01, 3.9030e-01, 1.6873e-03, 1.2483e-03, 9.9762e-01,\n",
      "        9.9770e-01, 6.0917e-03, 1.0207e-02, 1.2622e-03, 6.0458e-04, 7.7216e-04,\n",
      "        1.2502e-03, 1.2058e-02, 9.9951e-01, 9.9652e-01, 1.6781e-03, 9.9955e-01,\n",
      "        9.9967e-01, 5.0222e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0520, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06385362893342972\n",
      "4180\n",
      "tensor([9.9770e-01, 8.7315e-04, 1.8026e-03, 9.9923e-01, 6.6159e-04, 5.9668e-03,\n",
      "        3.7339e-04, 9.9749e-01, 9.9970e-01, 9.6762e-01, 9.9956e-01, 9.0844e-04,\n",
      "        1.3682e-03, 9.9702e-01, 9.9800e-01, 1.5403e-02, 9.9740e-01, 9.4879e-04,\n",
      "        9.9982e-01, 9.7301e-01, 1.9296e-04, 4.6691e-04, 4.8830e-04, 1.2889e-03,\n",
      "        7.9307e-01, 9.9322e-01, 9.9914e-01, 2.1395e-01, 8.6666e-04, 9.1196e-01,\n",
      "        6.7101e-04, 5.6034e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0619, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06368586421012878\n",
      "4210\n",
      "tensor([9.0601e-03, 9.9470e-01, 9.9920e-01, 4.3923e-03, 6.5814e-04, 4.1518e-04,\n",
      "        1.7660e-03, 4.7530e-04, 9.4407e-04, 9.9937e-01, 9.4212e-04, 9.9928e-01,\n",
      "        1.6601e-03, 5.8527e-04, 6.0912e-04, 9.9964e-01, 9.9896e-01, 4.9288e-01,\n",
      "        9.9916e-01, 9.9972e-01, 9.9977e-01, 9.9976e-01, 9.9852e-04, 9.9906e-01,\n",
      "        9.9826e-01, 1.4561e-03, 4.3690e-04, 7.9628e-04, 9.9787e-01, 9.9922e-01,\n",
      "        7.7123e-04, 9.9939e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0226, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06350240856409073\n",
      "4240\n",
      "tensor([9.9858e-01, 3.1867e-03, 9.9932e-01, 9.9966e-01, 9.9920e-01, 7.4149e-01,\n",
      "        2.1699e-03, 1.1753e-02, 9.9826e-01, 8.2314e-01, 9.9833e-01, 9.9836e-01,\n",
      "        1.3224e-02, 9.9876e-01, 1.0543e-03, 6.9854e-04, 9.9968e-01, 1.6994e-03,\n",
      "        9.9965e-01, 8.5101e-04, 9.9960e-01, 5.1271e-03, 9.7807e-01, 1.4320e-02,\n",
      "        9.9939e-01, 1.6053e-03, 8.9102e-01, 9.9852e-01, 9.9335e-01, 1.9171e-03,\n",
      "        9.9634e-01, 6.8850e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0703, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06344307214021683\n",
      "4270\n",
      "tensor([9.7979e-01, 3.9777e-02, 3.1533e-03, 9.3778e-04, 5.7182e-04, 8.4169e-04,\n",
      "        1.0055e-03, 9.9781e-01, 3.9482e-03, 2.2380e-02, 8.9490e-04, 9.9886e-01,\n",
      "        9.9946e-01, 9.9770e-01, 5.0241e-04, 3.5751e-03, 9.9885e-01, 9.9282e-01,\n",
      "        3.0674e-03, 9.9940e-01, 3.9799e-03, 9.9674e-01, 9.9934e-01, 9.9946e-01,\n",
      "        9.9906e-01, 2.5848e-02, 3.3121e-03, 2.7496e-03, 1.1089e-02, 2.7999e-04,\n",
      "        2.7190e-02, 9.9914e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.2377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06336995214223862\n",
      "4300\n",
      "tensor([9.9333e-01, 9.8806e-01, 9.9911e-01, 9.9928e-01, 8.6795e-01, 9.9893e-01,\n",
      "        9.9908e-01, 9.9960e-01, 9.9590e-01, 1.7563e-02, 9.9932e-01, 4.3920e-04,\n",
      "        9.9835e-01, 7.3283e-04, 9.2144e-04, 9.9948e-01, 1.0109e-03, 6.7576e-04,\n",
      "        9.9798e-01, 2.9773e-04, 4.0420e-03, 2.0220e-02, 9.9945e-01, 5.8598e-01,\n",
      "        9.8499e-01, 1.0089e-02, 9.9773e-01, 2.7891e-03, 7.5784e-03, 9.9954e-01,\n",
      "        9.9961e-01, 9.9831e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0248, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06327148526906967\n",
      "4330\n",
      "tensor([9.9641e-01, 9.9827e-01, 9.9849e-01, 4.0902e-03, 9.9061e-01, 2.2140e-03,\n",
      "        4.3938e-04, 2.0230e-02, 9.8002e-01, 9.9414e-01, 9.9963e-01, 5.8364e-03,\n",
      "        9.9863e-01, 8.2521e-04, 8.2880e-04, 4.1607e-01, 9.9760e-01, 8.8700e-04,\n",
      "        4.5565e-04, 2.2221e-02, 1.3955e-02, 6.5022e-04, 1.3326e-01, 9.9922e-01,\n",
      "        6.7262e-03, 9.9832e-01, 9.9952e-01, 1.6570e-03, 9.6909e-01, 9.9973e-01,\n",
      "        9.9761e-01, 4.6818e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0370, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06325502693653107\n",
      "4360\n",
      "tensor([2.9931e-03, 1.1222e-02, 3.0510e-03, 9.9945e-01, 1.4996e-03, 5.5701e-01,\n",
      "        7.4555e-02, 2.5490e-03, 9.9935e-01, 1.1203e-02, 2.0361e-01, 1.5007e-03,\n",
      "        1.7072e-03, 9.9599e-01, 9.9334e-01, 9.9146e-01, 9.8100e-01, 9.3885e-01,\n",
      "        4.0079e-03, 7.5350e-01, 4.8829e-03, 9.9677e-01, 2.0301e-03, 1.2709e-02,\n",
      "        2.7879e-02, 9.9979e-01, 9.9350e-01, 9.9960e-01, 9.9948e-01, 9.8669e-01,\n",
      "        6.3556e-04, 9.9973e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0506, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0632619857788086\n",
      "4390\n",
      "tensor([9.9968e-01, 9.8189e-01, 5.3137e-04, 9.6498e-01, 9.9438e-01, 3.9273e-04,\n",
      "        4.2764e-04, 9.9947e-01, 3.1069e-02, 1.1696e-03, 9.9500e-01, 1.0027e-03,\n",
      "        3.8847e-04, 9.9914e-01, 9.9751e-01, 2.5314e-02, 7.7509e-04, 9.9955e-01,\n",
      "        1.3944e-03, 2.5842e-03, 9.9783e-01, 7.2884e-01, 9.9823e-01, 5.6797e-04,\n",
      "        9.9976e-01, 1.9896e-03, 9.9916e-01, 1.7338e-02, 9.9852e-01, 5.3385e-04,\n",
      "        7.2639e-04, 9.9846e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0150, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06336693465709686\n",
      "4420\n",
      "tensor([3.0232e-04, 9.4225e-01, 1.6352e-01, 3.9102e-01, 4.4944e-03, 9.9349e-01,\n",
      "        4.9049e-04, 1.3850e-03, 9.9904e-01, 4.1475e-03, 9.9839e-01, 9.9900e-01,\n",
      "        9.7631e-01, 9.8767e-01, 4.2862e-04, 9.9849e-01, 8.1194e-01, 1.3131e-02,\n",
      "        6.1849e-04, 9.9864e-01, 9.9752e-01, 9.9932e-01, 6.3178e-04, 3.0232e-03,\n",
      "        3.1995e-03, 1.1366e-02, 9.9967e-01, 9.9307e-01, 5.2430e-04, 5.9958e-03,\n",
      "        7.5874e-04, 3.9697e-02], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0480, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.0632123276591301\n",
      "4450\n",
      "tensor([2.2692e-04, 4.3916e-03, 9.9872e-01, 1.5656e-03, 9.9845e-01, 9.9963e-01,\n",
      "        2.6832e-04, 6.2278e-04, 9.9904e-01, 6.5186e-03, 9.9951e-01, 9.9927e-01,\n",
      "        9.8937e-01, 9.9939e-01, 9.9924e-01, 9.7385e-01, 2.5865e-02, 9.5447e-04,\n",
      "        9.9926e-01, 9.9904e-01, 9.9780e-01, 9.8870e-01, 5.1092e-03, 1.6325e-03,\n",
      "        9.9838e-01, 2.1674e-02, 2.7957e-02, 9.9796e-01, 2.8767e-01, 3.2513e-03,\n",
      "        5.8543e-03, 9.9788e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0160, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06325114518404007\n",
      "4480\n",
      "tensor([9.9934e-01, 9.9459e-01, 9.9757e-01, 4.6428e-04, 3.5011e-04, 9.9960e-01,\n",
      "        5.4033e-04, 1.0116e-03, 9.9926e-01, 9.9413e-01, 9.9564e-01, 6.6683e-04,\n",
      "        7.7543e-04, 5.0121e-04, 9.9041e-01, 9.9963e-01, 6.7739e-04, 4.3347e-03,\n",
      "        3.9749e-04, 9.9918e-01, 9.9971e-01, 9.9744e-01, 4.5882e-04, 4.9626e-04,\n",
      "        4.7190e-04, 3.4415e-04, 9.9957e-01, 9.9940e-01, 3.0142e-04, 1.8440e-03,\n",
      "        9.3084e-03, 1.1646e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06316284090280533\n",
      "4510\n",
      "tensor([1.0631e-03, 3.0667e-03, 8.1338e-04, 9.9703e-01, 5.9040e-04, 9.9863e-01,\n",
      "        9.9895e-01, 9.9949e-01, 3.7641e-02, 1.8574e-03, 9.9774e-01, 9.9918e-01,\n",
      "        9.9960e-01, 8.9891e-04, 9.2971e-01, 9.9801e-01, 1.1961e-03, 9.9875e-01,\n",
      "        9.7624e-01, 8.4114e-03, 7.8091e-04, 5.4604e-04, 9.9909e-01, 9.9128e-01,\n",
      "        9.9960e-01, 6.7906e-04, 9.9769e-01, 7.5235e-02, 6.7363e-04, 3.6567e-04,\n",
      "        1.8458e-02, 9.9787e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06314751505851746\n",
      "4540\n",
      "tensor([9.9880e-01, 7.6543e-03, 3.1168e-03, 2.2165e-04, 3.2247e-04, 8.3097e-04,\n",
      "        9.9917e-01, 9.9900e-01, 9.9945e-01, 6.1903e-04, 9.9723e-01, 3.9479e-04,\n",
      "        1.2944e-03, 3.9512e-02, 9.9767e-01, 4.4586e-02, 9.7639e-01, 5.7661e-04,\n",
      "        3.4989e-03, 9.9540e-01, 1.4152e-02, 7.8346e-04, 6.5785e-03, 9.9724e-01,\n",
      "        7.6223e-01, 1.6492e-03, 8.3278e-02, 9.9821e-01, 9.9913e-01, 9.9688e-01,\n",
      "        9.1654e-03, 9.9824e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0170, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06327517330646515\n",
      "4570\n",
      "tensor([9.9934e-01, 5.4862e-04, 9.9186e-03, 9.9947e-01, 1.5229e-03, 9.9879e-01,\n",
      "        5.2683e-04, 9.9981e-01, 3.5711e-04, 9.9632e-01, 9.8551e-01, 2.0589e-03,\n",
      "        9.9940e-01, 1.9486e-02, 5.6591e-02, 9.4365e-01, 7.8025e-02, 9.9921e-01,\n",
      "        2.6572e-03, 9.9266e-01, 9.9276e-01, 4.0057e-03, 6.8859e-04, 1.4661e-03,\n",
      "        2.7526e-02, 9.9501e-01, 9.9840e-01, 8.2296e-04, 9.0964e-04, 9.9850e-01,\n",
      "        9.9758e-01, 9.9950e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06324314326047897\n",
      "4600\n",
      "tensor([8.2795e-01, 5.6247e-03, 9.9873e-01, 3.3268e-03, 9.4169e-04, 9.9922e-01,\n",
      "        6.9202e-04, 1.2313e-03, 9.9789e-01, 3.4187e-03, 7.0720e-02, 2.3681e-03,\n",
      "        9.9955e-01, 9.9949e-01, 1.6921e-03, 9.9976e-01, 9.9923e-01, 1.2121e-03,\n",
      "        2.7062e-03, 9.9957e-01, 9.9911e-01, 9.9887e-01, 9.9891e-01, 3.2252e-04,\n",
      "        5.0647e-04, 9.9465e-01, 4.4243e-04, 9.9915e-01, 3.6736e-04, 1.1996e-03,\n",
      "        9.9848e-01, 4.4030e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06313506513834\n",
      "4630\n",
      "tensor([9.9861e-01, 9.9944e-01, 8.5015e-04, 4.0334e-01, 9.9187e-01, 9.9952e-01,\n",
      "        8.2422e-04, 9.9917e-01, 9.9939e-01, 9.9939e-01, 2.6340e-02, 7.7483e-01,\n",
      "        9.4163e-01, 9.9759e-01, 9.9830e-01, 9.2074e-01, 9.9953e-01, 9.9887e-01,\n",
      "        9.9641e-01, 9.1363e-03, 9.9894e-01, 2.2944e-04, 9.8468e-01, 2.7860e-04,\n",
      "        9.9314e-01, 4.2019e-01, 9.9878e-01, 9.9944e-01, 8.9005e-02, 2.7526e-01,\n",
      "        9.9869e-01, 4.9492e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1121, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06300193071365356\n",
      "4660\n",
      "tensor([3.6139e-01, 1.0744e-03, 1.3706e-02, 1.0465e-03, 9.9433e-01, 9.9953e-01,\n",
      "        1.2749e-03, 9.9925e-01, 9.9791e-01, 9.9963e-01, 5.6333e-01, 9.9786e-01,\n",
      "        1.0109e-03, 9.9946e-01, 9.9930e-01, 9.9946e-01, 9.9938e-01, 6.6496e-04,\n",
      "        6.2338e-04, 9.9594e-01, 9.9789e-01, 9.9873e-01, 9.8508e-02, 9.9716e-01,\n",
      "        9.9901e-01, 1.1177e-03, 4.9612e-04, 1.1788e-03, 9.9885e-01, 4.4754e-04,\n",
      "        3.2858e-04, 9.8081e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0453, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06291279196739197\n",
      "4690\n",
      "tensor([9.9950e-01, 9.9530e-01, 9.6467e-01, 9.7240e-04, 9.9828e-01, 4.3603e-03,\n",
      "        9.9844e-01, 9.9834e-01, 8.5168e-04, 9.9747e-01, 1.2376e-03, 7.8377e-04,\n",
      "        1.0451e-03, 9.9736e-01, 9.0226e-03, 1.8103e-02, 2.1858e-03, 5.4635e-03,\n",
      "        9.9844e-01, 9.9829e-01, 6.1250e-04, 9.9952e-01, 1.0281e-02, 1.3569e-01,\n",
      "        9.0210e-01, 9.9953e-01, 9.6892e-01, 9.9828e-01, 9.9897e-01, 1.8368e-03,\n",
      "        4.7039e-04, 7.1238e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0124, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06285866349935532\n",
      "4720\n",
      "tensor([9.9883e-01, 1.0154e-02, 9.9966e-01, 3.2931e-04, 2.6176e-03, 9.9894e-01,\n",
      "        9.7915e-01, 9.9905e-01, 9.9896e-01, 9.7433e-01, 7.7546e-02, 3.3130e-04,\n",
      "        5.4844e-04, 9.8065e-01, 9.9932e-01, 2.3548e-04, 6.7886e-03, 9.9569e-01,\n",
      "        7.9000e-04, 6.6664e-03, 9.9927e-01, 9.9734e-01, 9.9970e-01, 2.0438e-03,\n",
      "        8.3037e-01, 1.0527e-03, 7.7144e-01, 9.3600e-01, 4.3667e-04, 8.2807e-04,\n",
      "        9.9380e-01, 3.9724e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0996, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06273575872182846\n",
      "4750\n",
      "tensor([0.9990, 0.0020, 0.9993, 0.9935, 0.0012, 0.9196, 0.9990, 0.9993, 0.9992,\n",
      "        0.0011, 0.0016, 0.0011, 0.0012, 0.0011, 0.9970, 0.9997, 0.8857, 0.0015,\n",
      "        0.9970, 0.5290, 0.0098, 0.9969, 0.9995, 0.0185, 0.9548, 0.9981, 0.9947,\n",
      "        0.9111, 0.9284, 0.9930, 0.0174, 0.3872], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1456, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06271956115961075\n",
      "4780\n",
      "tensor([9.9332e-01, 1.8800e-03, 1.5511e-03, 9.9924e-01, 9.6983e-01, 9.9359e-01,\n",
      "        5.4125e-01, 9.5821e-04, 1.7572e-01, 1.6444e-03, 4.8301e-04, 9.9835e-01,\n",
      "        9.9272e-01, 1.3791e-02, 5.6293e-04, 9.9423e-01, 1.4651e-03, 3.9043e-01,\n",
      "        2.8625e-04, 9.9852e-01, 9.9880e-01, 9.9364e-04, 7.1768e-04, 9.9907e-01,\n",
      "        5.1650e-04, 3.4715e-04, 9.9587e-01, 2.8091e-03, 9.9843e-01, 9.6848e-01,\n",
      "        9.9803e-01, 5.2370e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0448, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06272285431623459\n",
      "4810\n",
      "tensor([9.9908e-01, 9.9923e-01, 3.6636e-04, 4.8397e-03, 9.6138e-01, 9.9810e-01,\n",
      "        3.8163e-03, 9.9865e-01, 3.9755e-04, 8.3863e-01, 2.6733e-03, 9.9789e-01,\n",
      "        9.9925e-01, 9.6402e-01, 5.7166e-04, 9.9835e-01, 9.9937e-01, 1.8350e-03,\n",
      "        6.4788e-04, 9.9593e-01, 9.9894e-01, 1.0763e-03, 3.3998e-04, 9.9900e-01,\n",
      "        9.9916e-01, 9.9710e-01, 9.9790e-01, 1.4332e-04, 9.9827e-01, 9.9789e-01,\n",
      "        9.9863e-01, 9.9840e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0093, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06259473413228989\n",
      "4840\n",
      "tensor([9.9744e-01, 9.9903e-01, 2.5854e-04, 9.9875e-01, 9.9265e-01, 9.9689e-01,\n",
      "        9.9476e-01, 9.6148e-04, 9.9881e-01, 9.9925e-01, 9.9952e-01, 1.6616e-04,\n",
      "        3.1788e-04, 9.7770e-01, 9.8926e-01, 3.5709e-04, 9.9926e-01, 3.1781e-03,\n",
      "        9.9894e-01, 9.9575e-01, 1.2710e-03, 9.9933e-01, 9.9875e-01, 9.9855e-01,\n",
      "        3.2559e-03, 9.9865e-01, 9.9768e-01, 9.9335e-01, 9.9935e-01, 9.9925e-01,\n",
      "        9.9654e-01, 7.5604e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0029, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06252841651439667\n",
      "4870\n",
      "tensor([6.4591e-04, 1.2756e-03, 6.8836e-03, 8.8129e-04, 9.9764e-01, 9.9810e-01,\n",
      "        3.0238e-04, 2.9695e-01, 9.7325e-01, 9.9902e-01, 5.2212e-03, 9.9928e-01,\n",
      "        5.1359e-02, 1.8743e-03, 9.9909e-01, 8.4172e-04, 9.9327e-01, 6.4952e-03,\n",
      "        9.9971e-01, 6.5980e-04, 9.8883e-01, 1.1096e-02, 4.8466e-04, 4.3493e-04,\n",
      "        1.0435e-03, 1.5475e-02, 9.9703e-01, 1.9649e-03, 9.9930e-01, 1.3068e-03,\n",
      "        9.9821e-01, 9.9954e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0163, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06244891136884689\n",
      "4900\n",
      "tensor([3.4496e-04, 9.9856e-01, 4.8968e-04, 1.0307e-01, 4.7641e-04, 9.9862e-01,\n",
      "        9.9912e-01, 2.8306e-04, 6.3612e-04, 9.7571e-01, 1.4511e-03, 4.3105e-04,\n",
      "        9.9554e-01, 9.9912e-01, 6.2101e-04, 3.0595e-01, 9.9886e-01, 9.9459e-01,\n",
      "        3.2016e-04, 3.4757e-03, 6.8776e-03, 2.8342e-03, 9.9827e-01, 9.9945e-01,\n",
      "        9.9686e-01, 9.9799e-01, 3.0221e-02, 4.0532e-03, 9.9981e-01, 2.1159e-03,\n",
      "        2.4102e-03, 5.0730e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0857, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.062355078756809235\n",
      "4930\n",
      "tensor([8.2975e-01, 9.9761e-01, 9.9931e-01, 9.9940e-01, 9.9896e-01, 9.9138e-01,\n",
      "        8.4110e-04, 1.3962e-04, 4.7317e-04, 8.8539e-03, 7.5621e-03, 9.9936e-01,\n",
      "        9.9839e-01, 1.6169e-03, 9.9829e-01, 9.9157e-03, 1.3303e-01, 9.9067e-01,\n",
      "        9.9649e-01, 9.5895e-02, 9.9912e-01, 9.9877e-01, 9.7867e-04, 9.9928e-01,\n",
      "        4.7005e-04, 9.9723e-01, 9.9927e-01, 9.9435e-01, 9.9862e-01, 9.8483e-01,\n",
      "        9.2869e-04, 9.9650e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0659, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.062379732728004456\n",
      "4960\n",
      "tensor([4.9290e-03, 9.8703e-01, 9.9953e-01, 9.9909e-01, 9.7560e-01, 3.5730e-04,\n",
      "        1.2412e-01, 9.8894e-01, 3.7571e-04, 9.9852e-01, 9.9966e-01, 9.9940e-01,\n",
      "        9.9833e-01, 7.7258e-03, 3.4289e-03, 4.0071e-04, 5.2196e-03, 9.9686e-01,\n",
      "        5.9220e-04, 9.9111e-03, 6.6285e-04, 9.9926e-01, 3.5825e-04, 7.5512e-01,\n",
      "        9.9901e-01, 2.8677e-04, 1.4437e-04, 3.4104e-03, 9.9953e-01, 4.1854e-04,\n",
      "        1.7068e-03, 9.9834e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0161, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.062190745025873184\n",
      "4990\n",
      "tensor([9.9769e-01, 2.7414e-02, 9.1873e-01, 1.5568e-03, 9.7642e-01, 9.7695e-01,\n",
      "        1.1184e-03, 8.0373e-03, 3.0477e-03, 6.3713e-04, 1.8626e-03, 1.8364e-03,\n",
      "        6.4381e-03, 9.6428e-01, 5.7585e-04, 7.5433e-01, 9.9918e-01, 9.9841e-01,\n",
      "        8.8816e-04, 9.9844e-01, 1.4075e-03, 9.9843e-01, 1.9356e-04, 9.9889e-01,\n",
      "        9.9973e-01, 5.5093e-04, 9.9947e-01, 9.9804e-01, 1.1836e-03, 9.9903e-01,\n",
      "        9.9683e-01, 1.4628e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0164, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06223130226135254\n",
      "Save the weights\n",
      "5020\n",
      "tensor([1.0280e-03, 4.5035e-02, 7.0773e-04, 9.9950e-01, 9.7521e-01, 4.4189e-04,\n",
      "        9.8875e-01, 9.9812e-01, 9.9921e-01, 9.9060e-01, 9.9662e-01, 2.8662e-02,\n",
      "        3.2240e-04, 3.6289e-04, 1.5540e-02, 9.9962e-01, 9.9893e-01, 8.5313e-04,\n",
      "        1.6916e-03, 3.5621e-04, 6.4289e-03, 9.9974e-01, 9.9006e-01, 9.9898e-01,\n",
      "        1.4942e-02, 1.7604e-04, 2.3955e-03, 2.1535e-03, 6.2407e-03, 9.8539e-01,\n",
      "        9.8727e-01, 9.9890e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0070, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06213684007525444\n",
      "5050\n",
      "tensor([9.7147e-01, 9.9970e-01, 4.1219e-02, 5.9186e-01, 9.9942e-01, 9.9968e-01,\n",
      "        9.9189e-01, 1.2823e-01, 2.9791e-02, 1.3393e-04, 4.4885e-04, 3.0593e-03,\n",
      "        9.9940e-01, 3.5908e-04, 9.9814e-01, 9.9921e-01, 9.9886e-01, 9.9918e-01,\n",
      "        6.2381e-03, 3.7512e-04, 9.9941e-01, 9.9775e-01, 9.8337e-04, 9.9901e-01,\n",
      "        9.9956e-01, 9.9972e-01, 9.9934e-01, 1.9719e-03, 9.9943e-01, 8.0707e-04,\n",
      "        1.1934e-03, 1.2494e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1469, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06200306862592697\n",
      "5080\n",
      "tensor([9.9958e-01, 9.9818e-01, 9.9920e-01, 9.9959e-01, 2.6637e-04, 9.7388e-03,\n",
      "        6.1637e-04, 3.5611e-03, 9.9903e-01, 5.7797e-04, 8.2199e-04, 1.1362e-03,\n",
      "        1.2947e-03, 1.2420e-03, 1.3764e-03, 8.8126e-01, 1.0298e-03, 1.1820e-03,\n",
      "        3.2080e-04, 9.9819e-01, 9.9951e-01, 2.4919e-03, 9.0923e-04, 9.9944e-01,\n",
      "        7.5491e-04, 2.8259e-04, 3.2433e-03, 9.9893e-01, 2.6996e-03, 9.9796e-01,\n",
      "        6.2066e-04, 9.9714e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.1844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.061817511916160583\n",
      "5110\n",
      "tensor([3.0623e-03, 3.5886e-04, 9.7833e-01, 9.9835e-01, 9.9974e-01, 3.0731e-03,\n",
      "        9.9910e-01, 5.1158e-04, 9.9929e-01, 9.9934e-01, 9.9764e-01, 9.9860e-01,\n",
      "        9.9505e-01, 9.9872e-01, 9.9742e-01, 1.4448e-03, 5.5558e-04, 9.9908e-01,\n",
      "        9.9941e-01, 1.3391e-01, 9.1044e-04, 3.4359e-04, 9.9960e-01, 6.6756e-04,\n",
      "        1.1660e-02, 9.9967e-01, 2.6268e-03, 1.1710e-03, 9.9890e-01, 9.9479e-01,\n",
      "        5.6809e-04, 1.0961e-03], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0068, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06178614869713783\n",
      "5140\n",
      "tensor([8.7680e-01, 1.2921e-04, 9.9773e-01, 1.4617e-03, 9.6807e-01, 1.1676e-01,\n",
      "        4.0413e-04, 9.8716e-01, 1.7655e-02, 4.2925e-04, 5.2906e-04, 6.8653e-04,\n",
      "        9.9571e-01, 9.9156e-01, 3.3586e-04, 8.6294e-03, 7.7883e-04, 9.9685e-01,\n",
      "        2.7598e-04, 9.9000e-01, 1.1630e-01, 7.2509e-04, 9.6379e-01, 9.9824e-01,\n",
      "        9.9854e-01, 3.8778e-04, 1.5174e-02, 6.1982e-02, 9.9959e-01, 6.3270e-03,\n",
      "        9.9926e-01, 9.9945e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0192, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06169779226183891\n",
      "5170\n",
      "tensor([4.1982e-04, 9.9954e-01, 8.5804e-03, 9.9784e-01, 4.5952e-03, 9.9962e-01,\n",
      "        9.9722e-01, 9.9928e-01, 9.9977e-01, 1.2828e-02, 9.9366e-01, 2.4553e-03,\n",
      "        1.2370e-03, 9.9638e-01, 1.4399e-04, 9.9963e-01, 9.9918e-01, 9.9928e-01,\n",
      "        9.9760e-01, 4.5687e-04, 7.5895e-04, 9.9876e-01, 3.1587e-03, 2.1335e-04,\n",
      "        4.4213e-04, 9.9902e-01, 9.9965e-01, 1.5658e-03, 1.0342e-03, 3.9999e-03,\n",
      "        9.9905e-01, 9.9916e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06156720593571663\n",
      "5200\n",
      "tensor([1.8460e-03, 5.0945e-04, 1.1288e-03, 3.7479e-04, 9.9724e-01, 9.9940e-01,\n",
      "        5.9993e-04, 9.9880e-01, 2.2466e-04, 3.4008e-02, 2.3506e-03, 9.9619e-01,\n",
      "        2.3183e-03, 9.9879e-01, 7.6315e-04, 9.9854e-01, 8.9038e-04, 9.9715e-01,\n",
      "        3.9222e-04, 2.0858e-04, 9.9920e-01, 1.8545e-03, 4.1192e-04, 9.3263e-01,\n",
      "        9.9972e-01, 2.8872e-04, 9.9931e-01, 5.1842e-04, 1.4919e-03, 2.4914e-03,\n",
      "        9.9913e-01, 9.9874e-01], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06146513670682907\n",
      "5230\n",
      "tensor([9.9651e-01, 9.9809e-01, 9.9812e-01, 9.4322e-04, 9.4504e-03, 9.9830e-01,\n",
      "        9.9262e-01, 9.9938e-01, 9.1147e-01, 2.2143e-03, 8.5218e-01, 9.9764e-01,\n",
      "        9.9745e-01, 2.7353e-02, 1.5192e-03, 9.7906e-01, 4.6663e-04, 9.9826e-01,\n",
      "        1.6876e-03, 8.9774e-03, 9.9129e-01, 1.9122e-03, 9.9758e-01, 9.9886e-01,\n",
      "        3.0029e-03, 6.8596e-01, 9.6897e-01, 9.9087e-01, 3.4556e-04, 2.6361e-02,\n",
      "        9.9920e-01, 4.3804e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.061529990285634995\n",
      "5260\n",
      "tensor([1.0516e-03, 2.7669e-01, 8.9204e-04, 9.7692e-04, 9.9742e-01, 3.3304e-03,\n",
      "        9.9907e-01, 8.0135e-04, 8.5468e-01, 2.3021e-03, 9.9909e-01, 9.9882e-01,\n",
      "        6.3534e-01, 1.0879e-01, 1.1260e-02, 4.6292e-04, 9.9741e-01, 1.5042e-03,\n",
      "        8.2136e-04, 9.9877e-01, 6.1963e-04, 9.9789e-01, 1.0129e-03, 4.9322e-04,\n",
      "        9.9855e-01, 9.9910e-01, 9.9904e-01, 1.9260e-02, 5.8411e-04, 1.1939e-03,\n",
      "        9.9959e-01, 3.1909e-04], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "Batch_loss:  tensor(0.0648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Avg_loss: 0.06143990904092789\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-572e222e3d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch_loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avg_loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  avg_loss = 0 \n",
    "  print(\"EPOCH\")\n",
    "  for i, batch in enumerate(loader):\n",
    "    input_ids = batch[0].to('cuda')\n",
    "    attention_mask = batch[1].to('cuda')\n",
    "    target = batch[2].to('cuda')\n",
    "    optimizer.zero_grad()   \n",
    "    #print(question)\n",
    "    #print(encoding)\n",
    "    #get token_ids and attention_mask from encoding\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    #outputs = F.log_softmax(outputs, dim=1)\n",
    "    \n",
    "    outputs = outputs.flatten()\n",
    "    loss = criterion(outputs, target.to(torch.float32))\n",
    "    avg_loss += loss\n",
    "    if i % 30 == 10:\n",
    "      print(i)\n",
    "      print(outputs)\n",
    "      print(target)\n",
    "      print(\"Batch_loss: \", loss)\n",
    "      print(\"Avg_loss: {}\".format(avg_loss/i))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "    if  i == 5000:\n",
    "      print(\"Save the weights\")\n",
    "      torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "      }, \"./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/duoBERT_lr0001{}.tar\".format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7nKlvI8p2SB"
   },
   "source": [
    "## Prediction Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RReDRI6g7oP0"
   },
   "source": [
    "to use the duobert prediction, first run the monoBERT model and predict \"all_results\" on the \"test_df_sample\"; this can then be loaded into the duobert inference functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehYjxma29EqG",
    "outputId": "a4404a09-4552-4f37-a907-bd07686290e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duoBERT(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decision): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_duoBERT('./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/duoBERT_new_lr00011_999.tar')\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "znqavmMoqFHU"
   },
   "outputs": [],
   "source": [
    "from psutil import virtual_memory\n",
    "\n",
    "def get_pairwise_scores(id_list, att_list, model):\n",
    "\n",
    "  output = model(torch.stack(id_list).squeeze().to('cuda'), torch.stack(att_list).squeeze().to('cuda'))\n",
    "\n",
    "  return output.sum()\n",
    "\n",
    "def rank(question_id, df, model):\n",
    "  \"\"\" sum up the scores of each document by comparing it with each other doc and passing it through the model\n",
    "      ----------\n",
    "  \"\"\"\n",
    "  score_dict = dict()\n",
    "  temp_df = df[df['question'] == question_id]\n",
    "  doc_ids = set(temp_df['doc'])\n",
    "  question = temp_df.iloc[0]['question']\n",
    "  for doc in temp_df['doc']:\n",
    "    others = doc_ids - set([doc]) \n",
    "    sum = 0\n",
    "    id_list = list()\n",
    "    att_list = list()\n",
    "    for doc_y in others:\n",
    "      ids, attention_mask = tokenize_duoBERT(question, temp_df['full_doc'][temp_df['doc'] == doc].item(), temp_df['full_doc'][temp_df['doc'] == doc_y].item(), tokenizer)\n",
    "      id_list.append(ids)\n",
    "      att_list.append(attention_mask)\n",
    "    sum += get_pairwise_scores(id_list[0:5], att_list[0:5], model)\n",
    "    #sum += get_pairwise_scores(id_list[5:10], attention_mask[5:10], model)\n",
    "    \n",
    "    score_dict[doc] =sum.item()\n",
    "  return score_dict\n",
    "\n",
    "def rank_list(df_list, model):\n",
    "  \"\"\" Takes a list of dataframes with ranked documents and reranks with the \"rank\" function\n",
    "      ----------\n",
    "  \"\"\"\n",
    "  result_list = list()\n",
    "  for i, df in enumerate(df_list):\n",
    "    df['new_score'] = df['doc'].map(rank(df.iloc[0]['question'], df[0:5], model))\n",
    "    result_list.append(df.sort_values(['new_score'], ascending=False)[0:5])\n",
    "  return result_list\n",
    "\n",
    "def final_ranker(docs, pairwise_scores):\n",
    "# docs -> List of the documents to be sorted\n",
    "# pairwise_scores_rows -> Output dataset from duoBERT. It contains pairwise combinations of all documents, and an importance score per pairwise comparison\n",
    "\n",
    "  # Empty scores dictionary to store the sum scores\n",
    "  scores = {}\n",
    "  for doc in docs:\n",
    "\n",
    "    # Score per doc is initialized\n",
    "    scores[doc] = 0\n",
    "\n",
    "    for row in pairwise_scores:\n",
    "        if row['doc_text_x'] == doc:\n",
    "          # Sum scores calculated\n",
    "          scores[doc] += row['score']\n",
    "\n",
    "  # Order them by their score \n",
    "  scores = dict(sorted(scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "  # We define the final list to return, ranked from most relevant to least\n",
    "  final_list = []\n",
    "  for key, value in scores.items():\n",
    "    final_list.append(key)\n",
    "\n",
    "  \n",
    "  return final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "p6uRoiCo8uy6"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "pairwise_scores = rank_list(all_results, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sF44JdRvJZov",
    "outputId": "b0dc217a-e260-4bde-c2a3-710bdc813791"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1966</td>\n",
       "      <td>41226</td>\n",
       "      <td>5.597218</td>\n",
       "      <td>1</td>\n",
       "      <td>The genocide of Tutsi people by Hutu militia i...</td>\n",
       "      <td>The Tutsi (; ), or Abatutsi, are a population ...</td>\n",
       "      <td>3.842031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bb_1966</td>\n",
       "      <td>17510</td>\n",
       "      <td>5.098068</td>\n",
       "      <td>0</td>\n",
       "      <td>The genocide of Tutsi people by Hutu militia i...</td>\n",
       "      <td>Genocide (From Greek: Γενοκτονία) is the inten...</td>\n",
       "      <td>3.817302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bb_1966</td>\n",
       "      <td>30017</td>\n",
       "      <td>4.016120</td>\n",
       "      <td>0</td>\n",
       "      <td>The genocide of Tutsi people by Hutu militia i...</td>\n",
       "      <td>Genocide is the deliberate and systematic dest...</td>\n",
       "      <td>3.143354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1966</td>\n",
       "      <td>38912</td>\n",
       "      <td>2.125228</td>\n",
       "      <td>1</td>\n",
       "      <td>The genocide of Tutsi people by Hutu militia i...</td>\n",
       "      <td>The Hutu, also known as the Abahutu, are a pop...</td>\n",
       "      <td>2.837613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bb_1966</td>\n",
       "      <td>28671</td>\n",
       "      <td>0.826817</td>\n",
       "      <td>0</td>\n",
       "      <td>The genocide of Tutsi people by Hutu militia i...</td>\n",
       "      <td>Events\\n\\nJanuary\\n\\n* January 1\\n** Cultivars...</td>\n",
       "      <td>2.743052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "3   bb_1966  ...   3.842031\n",
       "43  bb_1966  ...   3.817302\n",
       "14  bb_1966  ...   3.143354\n",
       "4   bb_1966  ...   2.837613\n",
       "31  bb_1966  ...   2.743052\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bb_1972</td>\n",
       "      <td>47011</td>\n",
       "      <td>2.549249</td>\n",
       "      <td>0</td>\n",
       "      <td>What on a bird has a calamus, rachis and barbs?</td>\n",
       "      <td>Barbed wire, also known as barb wire, less oft...</td>\n",
       "      <td>3.841907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bb_1972</td>\n",
       "      <td>60337</td>\n",
       "      <td>-3.442049</td>\n",
       "      <td>0</td>\n",
       "      <td>What on a bird has a calamus, rachis and barbs?</td>\n",
       "      <td>Rattan (from the Malay rotan) is the name for ...</td>\n",
       "      <td>3.487921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bb_1972</td>\n",
       "      <td>46017</td>\n",
       "      <td>5.300384</td>\n",
       "      <td>1</td>\n",
       "      <td>What on a bird has a calamus, rachis and barbs?</td>\n",
       "      <td>Rachis is a biological term for a main axis or...</td>\n",
       "      <td>3.422784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bb_1972</td>\n",
       "      <td>25719</td>\n",
       "      <td>-0.144353</td>\n",
       "      <td>0</td>\n",
       "      <td>What on a bird has a calamus, rachis and barbs?</td>\n",
       "      <td>The emu (Dromaius novaehollandiae) is the seco...</td>\n",
       "      <td>2.735590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1972</td>\n",
       "      <td>29719</td>\n",
       "      <td>-3.116462</td>\n",
       "      <td>0</td>\n",
       "      <td>What on a bird has a calamus, rachis and barbs?</td>\n",
       "      <td>The Eurasian blue tit (Cyanistes caeruleus ) i...</td>\n",
       "      <td>1.329286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "32  bb_1972  ...   3.841907\n",
       "12  bb_1972  ...   3.487921\n",
       "7   bb_1972  ...   3.422784\n",
       "11  bb_1972  ...   2.735590\n",
       "3   bb_1972  ...   1.329286\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb_1979</td>\n",
       "      <td>25965</td>\n",
       "      <td>4.791040</td>\n",
       "      <td>1</td>\n",
       "      <td>Arthroscopy refers to surgery performed on wha...</td>\n",
       "      <td>Surgery (from the  cheirourgikē (composed of χ...</td>\n",
       "      <td>3.746826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bb_1979</td>\n",
       "      <td>39622</td>\n",
       "      <td>0.546637</td>\n",
       "      <td>0</td>\n",
       "      <td>Arthroscopy refers to surgery performed on wha...</td>\n",
       "      <td>Minimally-invasive procedures (also known as m...</td>\n",
       "      <td>3.626589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bb_1979</td>\n",
       "      <td>31135</td>\n",
       "      <td>-2.774645</td>\n",
       "      <td>0</td>\n",
       "      <td>Arthroscopy refers to surgery performed on wha...</td>\n",
       "      <td>Organ transplantation is the moving of an orga...</td>\n",
       "      <td>2.926305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_1979</td>\n",
       "      <td>506</td>\n",
       "      <td>4.859808</td>\n",
       "      <td>1</td>\n",
       "      <td>Arthroscopy refers to surgery performed on wha...</td>\n",
       "      <td>Arthroscopy (also called arthroscopic surgery)...</td>\n",
       "      <td>2.787249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bb_1979</td>\n",
       "      <td>10836</td>\n",
       "      <td>-3.113057</td>\n",
       "      <td>0</td>\n",
       "      <td>Arthroscopy refers to surgery performed on wha...</td>\n",
       "      <td>Cardiovascular (heart) surgery is surgery on t...</td>\n",
       "      <td>2.753747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "9   bb_1979  ...   3.746826\n",
       "5   bb_1979  ...   3.626589\n",
       "29  bb_1979  ...   2.926305\n",
       "0   bb_1979  ...   2.787249\n",
       "10  bb_1979  ...   2.753747\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bb_1988</td>\n",
       "      <td>53395</td>\n",
       "      <td>4.811922</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the Latin term for a reigning queen, o...</td>\n",
       "      <td>Augustus (;Classical Latin spelling and recons...</td>\n",
       "      <td>3.978975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bb_1988</td>\n",
       "      <td>3402</td>\n",
       "      <td>2.030160</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the Latin term for a reigning queen, o...</td>\n",
       "      <td>Mary I (18 February 1516 – 17 November 1558) w...</td>\n",
       "      <td>3.649093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bb_1988</td>\n",
       "      <td>62975</td>\n",
       "      <td>4.513467</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the Latin term for a reigning queen, o...</td>\n",
       "      <td>Elizabeth I (7 September 1533 – 24 March 1603)...</td>\n",
       "      <td>3.602562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bb_1988</td>\n",
       "      <td>35769</td>\n",
       "      <td>2.643804</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the Latin term for a reigning queen, o...</td>\n",
       "      <td>Henry VIII (28 June 1491 – 28 January 1547) wa...</td>\n",
       "      <td>3.562195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bb_1988</td>\n",
       "      <td>12295</td>\n",
       "      <td>2.626196</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the Latin term for a reigning queen, o...</td>\n",
       "      <td>The monarchy of the United Kingdom, commonly r...</td>\n",
       "      <td>3.241958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "46  bb_1988  ...   3.978975\n",
       "38  bb_1988  ...   3.649093\n",
       "13  bb_1988  ...   3.602562\n",
       "33  bb_1988  ...   3.562195\n",
       "8   bb_1988  ...   3.241958\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_199</td>\n",
       "      <td>53893</td>\n",
       "      <td>-0.262293</td>\n",
       "      <td>1</td>\n",
       "      <td>Angelos Epithemiou ex-burger-van proprietor, r...</td>\n",
       "      <td>Daniel Renton Skinner (born 25 January 1973) i...</td>\n",
       "      <td>3.891666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_199</td>\n",
       "      <td>55437</td>\n",
       "      <td>2.338067</td>\n",
       "      <td>0</td>\n",
       "      <td>Angelos Epithemiou ex-burger-van proprietor, r...</td>\n",
       "      <td>Friends is an American television sitcom, crea...</td>\n",
       "      <td>3.645027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bb_199</td>\n",
       "      <td>28226</td>\n",
       "      <td>0.460003</td>\n",
       "      <td>0</td>\n",
       "      <td>Angelos Epithemiou ex-burger-van proprietor, r...</td>\n",
       "      <td>Popular is an American teenage comedy-drama on...</td>\n",
       "      <td>3.475925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bb_199</td>\n",
       "      <td>38741</td>\n",
       "      <td>-0.116815</td>\n",
       "      <td>0</td>\n",
       "      <td>Angelos Epithemiou ex-burger-van proprietor, r...</td>\n",
       "      <td>The British Comedy Awards are an annual awards...</td>\n",
       "      <td>2.493372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bb_199</td>\n",
       "      <td>29334</td>\n",
       "      <td>2.610252</td>\n",
       "      <td>0</td>\n",
       "      <td>Angelos Epithemiou ex-burger-van proprietor, r...</td>\n",
       "      <td>3–2–1 was a popular (and successful) British g...</td>\n",
       "      <td>2.306855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "0    bb_199  ...   3.891666\n",
       "3    bb_199  ...   3.645027\n",
       "44   bb_199  ...   3.475925\n",
       "5    bb_199  ...   2.493372\n",
       "22   bb_199  ...   2.306855\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bb_1994</td>\n",
       "      <td>29776</td>\n",
       "      <td>-1.019057</td>\n",
       "      <td>0</td>\n",
       "      <td>Dame Evelyn Glennie, who is profoundly deaf, i...</td>\n",
       "      <td>Henry Graham Greene  (2 October 1904 – 3 April...</td>\n",
       "      <td>3.829299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bb_1994</td>\n",
       "      <td>30930</td>\n",
       "      <td>-0.114778</td>\n",
       "      <td>0</td>\n",
       "      <td>Dame Evelyn Glennie, who is profoundly deaf, i...</td>\n",
       "      <td>Hearing loss, also known as hearing impairment...</td>\n",
       "      <td>3.759499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bb_1994</td>\n",
       "      <td>4605</td>\n",
       "      <td>-0.972717</td>\n",
       "      <td>0</td>\n",
       "      <td>Dame Evelyn Glennie, who is profoundly deaf, i...</td>\n",
       "      <td>Dame Judith Olivia \"Judi\" Dench,  (born 9 Dece...</td>\n",
       "      <td>2.687468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_1994</td>\n",
       "      <td>46061</td>\n",
       "      <td>4.420423</td>\n",
       "      <td>1</td>\n",
       "      <td>Dame Evelyn Glennie, who is profoundly deaf, i...</td>\n",
       "      <td>Dame Evelyn Elizabeth Ann Glennie, DBE (born 1...</td>\n",
       "      <td>2.548301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bb_1994</td>\n",
       "      <td>57914</td>\n",
       "      <td>-0.056605</td>\n",
       "      <td>0</td>\n",
       "      <td>Dame Evelyn Glennie, who is profoundly deaf, i...</td>\n",
       "      <td>British literature is literature in the Englis...</td>\n",
       "      <td>2.473960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "35  bb_1994  ...   3.829299\n",
       "40  bb_1994  ...   3.759499\n",
       "21  bb_1994  ...   2.687468\n",
       "0   bb_1994  ...   2.548301\n",
       "24  bb_1994  ...   2.473960\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bb_2001</td>\n",
       "      <td>2983</td>\n",
       "      <td>6.399828</td>\n",
       "      <td>1</td>\n",
       "      <td>The mineral, diamond, is naturally what crysta...</td>\n",
       "      <td>A mineral is a naturally occurring chemical co...</td>\n",
       "      <td>3.964266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_2001</td>\n",
       "      <td>28224</td>\n",
       "      <td>6.558377</td>\n",
       "      <td>1</td>\n",
       "      <td>The mineral, diamond, is naturally what crysta...</td>\n",
       "      <td>Diamond ( or) is a metastable allotrope of car...</td>\n",
       "      <td>3.801628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bb_2001</td>\n",
       "      <td>28525</td>\n",
       "      <td>5.747653</td>\n",
       "      <td>0</td>\n",
       "      <td>The mineral, diamond, is naturally what crysta...</td>\n",
       "      <td>In crystallography, crystal structure is a des...</td>\n",
       "      <td>3.118227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bb_2001</td>\n",
       "      <td>43885</td>\n",
       "      <td>5.863828</td>\n",
       "      <td>1</td>\n",
       "      <td>The mineral, diamond, is naturally what crysta...</td>\n",
       "      <td>A crystal or crystalline solid is a solid mate...</td>\n",
       "      <td>1.650063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bb_2001</td>\n",
       "      <td>43196</td>\n",
       "      <td>5.561342</td>\n",
       "      <td>0</td>\n",
       "      <td>The mineral, diamond, is naturally what crysta...</td>\n",
       "      <td>A diamond (from the ancient Greek ἀδάμας – adá...</td>\n",
       "      <td>1.622483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "5   bb_2001  ...   3.964266\n",
       "0   bb_2001  ...   3.801628\n",
       "41  bb_2001  ...   3.118227\n",
       "48  bb_2001  ...   1.650063\n",
       "6   bb_2001  ...   1.622483\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>24318</td>\n",
       "      <td>5.141289</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Medicine (British English; American English) i...</td>\n",
       "      <td>3.812071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>64418</td>\n",
       "      <td>0.982765</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Violence is defined by the World Health Organi...</td>\n",
       "      <td>3.744488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>64674</td>\n",
       "      <td>5.051980</td>\n",
       "      <td>1</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>The Fischer-Saller Scale, named after Eugen Fi...</td>\n",
       "      <td>3.622931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>65141</td>\n",
       "      <td>-0.182845</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Race, as a social construct, is a group of peo...</td>\n",
       "      <td>3.201683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>62797</td>\n",
       "      <td>3.464075</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Eye color or eye colour is a polygenic phenoty...</td>\n",
       "      <td>2.857603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "15  bb_2019  ...   3.812071\n",
       "30  bb_2019  ...   3.744488\n",
       "0   bb_2019  ...   3.622931\n",
       "8   bb_2019  ...   3.201683\n",
       "9   bb_2019  ...   2.857603\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bb_2030</td>\n",
       "      <td>51484</td>\n",
       "      <td>-0.027904</td>\n",
       "      <td>0</td>\n",
       "      <td>Name the former News of the World royal corres...</td>\n",
       "      <td>The original News Corporation or News Corp. wa...</td>\n",
       "      <td>3.948065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_2030</td>\n",
       "      <td>67304</td>\n",
       "      <td>4.811405</td>\n",
       "      <td>1</td>\n",
       "      <td>Name the former News of the World royal corres...</td>\n",
       "      <td>The News of the World was a national red top n...</td>\n",
       "      <td>3.627759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_2030</td>\n",
       "      <td>33082</td>\n",
       "      <td>2.367293</td>\n",
       "      <td>0</td>\n",
       "      <td>Name the former News of the World royal corres...</td>\n",
       "      <td>Watergate was a major political scandal that o...</td>\n",
       "      <td>2.582930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_2030</td>\n",
       "      <td>54141</td>\n",
       "      <td>3.473249</td>\n",
       "      <td>1</td>\n",
       "      <td>Name the former News of the World royal corres...</td>\n",
       "      <td>The News International phone-hacking scandal i...</td>\n",
       "      <td>2.295739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bb_2030</td>\n",
       "      <td>11007</td>\n",
       "      <td>4.556123</td>\n",
       "      <td>0</td>\n",
       "      <td>Name the former News of the World royal corres...</td>\n",
       "      <td>Phone hacking is the practice of intercepting ...</td>\n",
       "      <td>1.950437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "37  bb_2030  ...   3.948065\n",
       "1   bb_2030  ...   3.627759\n",
       "3   bb_2030  ...   2.582930\n",
       "0   bb_2030  ...   2.295739\n",
       "35  bb_2030  ...   1.950437\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_2036</td>\n",
       "      <td>73299</td>\n",
       "      <td>4.433249</td>\n",
       "      <td>1</td>\n",
       "      <td>Under the ABO blood group system, what blood t...</td>\n",
       "      <td>A blood donation occurs when a person voluntar...</td>\n",
       "      <td>3.902734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_2036</td>\n",
       "      <td>66944</td>\n",
       "      <td>5.443734</td>\n",
       "      <td>1</td>\n",
       "      <td>Under the ABO blood group system, what blood t...</td>\n",
       "      <td>A blood type (also called a blood group) is a ...</td>\n",
       "      <td>2.745464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bb_2036</td>\n",
       "      <td>31704</td>\n",
       "      <td>1.660743</td>\n",
       "      <td>0</td>\n",
       "      <td>Under the ABO blood group system, what blood t...</td>\n",
       "      <td>Red blood cells (RBCs), also called erythrocyt...</td>\n",
       "      <td>2.625123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_2036</td>\n",
       "      <td>46250</td>\n",
       "      <td>5.349922</td>\n",
       "      <td>1</td>\n",
       "      <td>Under the ABO blood group system, what blood t...</td>\n",
       "      <td>The ABO blood group system is the most importa...</td>\n",
       "      <td>2.238465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_2036</td>\n",
       "      <td>32084</td>\n",
       "      <td>4.112684</td>\n",
       "      <td>1</td>\n",
       "      <td>Under the ABO blood group system, what blood t...</td>\n",
       "      <td>Blood transfusion is generally the process of ...</td>\n",
       "      <td>1.395283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...  new_score\n",
       "4   bb_2036  ...   3.902734\n",
       "0   bb_2036  ...   2.745464\n",
       "17  bb_2036  ...   2.625123\n",
       "1   bb_2036  ...   2.238465\n",
       "2   bb_2036  ...   1.395283\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pairwise_scores[0])\n",
    "display(pairwise_scores[1])\n",
    "display(pairwise_scores[2])\n",
    "display(pairwise_scores[3])\n",
    "display(pairwise_scores[4])\n",
    "display(pairwise_scores[5])\n",
    "display(pairwise_scores[6])\n",
    "display(pairwise_scores[7])\n",
    "display(pairwise_scores[8])\n",
    "display(pairwise_scores[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DtD4Xgoilmnq"
   },
   "outputs": [],
   "source": [
    "#create dataframe with answers to the questions\n",
    "questionID = list()\n",
    "answers = list()\n",
    "for ele in df['Data']:\n",
    "  questionID.append(ele['QuestionId'])\n",
    "  answers.append(ele['Answer']['Value'])\n",
    "\n",
    "\n",
    "\n",
    "  data = {'questionID': questionID,\n",
    "          'answer': answers,\n",
    "  }\n",
    "answer_df = pd.DataFrame(data, columns=data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "9pJQm3Jfryht",
    "outputId": "ea08efbf-3866-48fb-d1ee-585416f524ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tc_3</td>\n",
       "      <td>York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tc_8</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tc_9</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tc_10</td>\n",
       "      <td>Chicago Bears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tc_11</td>\n",
       "      <td>Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61883</th>\n",
       "      <td>qg_4639</td>\n",
       "      <td>Russia, China, Kyrgyzstan, Uzbekistan, and Tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61884</th>\n",
       "      <td>qg_4642</td>\n",
       "      <td>Barbie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61885</th>\n",
       "      <td>qg_4643</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61886</th>\n",
       "      <td>qg_4646</td>\n",
       "      <td>Bugs Bunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61887</th>\n",
       "      <td>qg_4657</td>\n",
       "      <td>Butterfinger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61888 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      questionID                                             answer\n",
       "0           tc_3                                               York\n",
       "1           tc_8                                           Portugal\n",
       "2           tc_9                                            Chicago\n",
       "3          tc_10                                      Chicago Bears\n",
       "4          tc_11                                             Norway\n",
       "...          ...                                                ...\n",
       "61883    qg_4639  Russia, China, Kyrgyzstan, Uzbekistan, and Tur...\n",
       "61884    qg_4642                                             Barbie\n",
       "61885    qg_4643                                 Theodore Roosevelt\n",
       "61886    qg_4646                                         Bugs Bunny\n",
       "61887    qg_4657                                       Butterfinger\n",
       "\n",
       "[61888 rows x 2 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(answer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "TgEVW3uXtXgt"
   },
   "outputs": [],
   "source": [
    "#add answers to the result dataframe to pass it to the question answering model\n",
    "for df in pairwise_scores:\n",
    "  df['answer'] = df['question'].apply(lambda x: answer_df['answer'][answer_df['questionID'] == df.iloc[0]['question']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kdh0CQKp9dbW"
   },
   "outputs": [],
   "source": [
    "pairwise_scores[0].to_csv('./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/test1.csv')\n",
    "\n",
    "pairwise_scores[7].to_csv('./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/finaltest2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1Lb5eEBiCgV6"
   },
   "outputs": [],
   "source": [
    "for i,df in enumerate(test_sample_list):\n",
    "  df['answer'] = df['question'].apply(lambda x: answer_df['answer'][answer_df['questionID'] == df.iloc[0]['question']])\n",
    "  add_full_doc_texts(df, question_dict, id_title_dict)\n",
    "  add_full_question_texts(df, question_dict)\n",
    "  df[0:5].to_csv('./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/final{}.csv'.format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IG5KDaDuCn-e",
    "outputId": "d5206ed8-f6ff-4cd3-8837-e8fe6d6c1d0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>full_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>26962</td>\n",
       "      <td>19.597762</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Messiah (HWV 56), the English-language oratori...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>27523</td>\n",
       "      <td>18.889829</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>In the Abrahamic religions, Gabriel ( Gavri'el...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>62572</td>\n",
       "      <td>17.887833</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Sola fide (Latin: by faith alone), also known ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>66731</td>\n",
       "      <td>17.275548</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Lamanites  are one of the people described...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>29155</td>\n",
       "      <td>17.145931</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Annunciation (from the Vulgate Latin '),  ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>40194</td>\n",
       "      <td>16.286592</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>In the Hebrew Bible and the Quran, Aaron אַהֲר...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>72235</td>\n",
       "      <td>16.109563</td>\n",
       "      <td>1</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The coat of arms of the BBC was adopted in Mar...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>4651</td>\n",
       "      <td>16.061345</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Beatitudes are eight blessings recounted i...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>29611</td>\n",
       "      <td>15.356243</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Ten Commandments, also known as the Decalo...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>55879</td>\n",
       "      <td>15.248792</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>A doxology (Greek: , from , doxa, \"glory\" and ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>515</td>\n",
       "      <td>14.674418</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Last Judgment, Final Judgment, Day of Judg...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>10292</td>\n",
       "      <td>14.430177</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Purgatorio (; Italian for \"Purgatory\") is the ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>47655</td>\n",
       "      <td>14.339567</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>A sermon is an oration, lecture, or talk by a ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>22885</td>\n",
       "      <td>14.328593</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Lust is an emotion or feeling of intense desir...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>70787</td>\n",
       "      <td>14.323859</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Ham (; Greek Χαμ, Kham; Arabic: , Ḥām, \"hot\" o...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>41231</td>\n",
       "      <td>14.313536</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Epistle to the Romans, often shortened to ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>47643</td>\n",
       "      <td>14.252042</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Ascension of Jesus (anglicized from the Vu...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>49694</td>\n",
       "      <td>14.240548</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>A Requiem or Requiem Mass, also known as Mass ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>36670</td>\n",
       "      <td>14.078645</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The name of God used most often in the Hebrew ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>55332</td>\n",
       "      <td>13.959490</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Passover or Pesach (;  from Hebrew   Pesah, Pe...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>40083</td>\n",
       "      <td>13.893756</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Promised Land (, translit.: Ha'Aretz HaMuv...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>28231</td>\n",
       "      <td>13.729915</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Henry VI, Part 3 (often written as 3 Henry VI)...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>53940</td>\n",
       "      <td>13.673807</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The term Holy Guardian Angel was possibly coin...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>6469</td>\n",
       "      <td>13.560801</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Eight Witnesses were one of the two groups...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>13617</td>\n",
       "      <td>13.549907</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>\"United we stand, divided we fall\" is a phrase...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>46091</td>\n",
       "      <td>13.513039</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Vespers is the sunset evening prayer service i...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>42104</td>\n",
       "      <td>13.396789</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Book of Genesis speaks of the relationship...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>61805</td>\n",
       "      <td>13.265758</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>William Harvey (1 April 1578 – 3 June 1657) wa...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>37986</td>\n",
       "      <td>13.249403</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Nick Bottom is a character in Shakespeare's A ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>45329</td>\n",
       "      <td>13.224242</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>As-salāmu ʿalaykum (,) is a Muslim greeting in...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>50149</td>\n",
       "      <td>13.216488</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>This article presents a list of notable histor...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>24004</td>\n",
       "      <td>13.107384</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Jacob's Ladder (Hebrew: Sulam Yaakov סולם יעקב...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>38283</td>\n",
       "      <td>12.988611</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Salome (;   Salōmē,;  between 62 and 71) was t...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>56182</td>\n",
       "      <td>12.918050</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>This is an alphabetical list of widely used an...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>10217</td>\n",
       "      <td>12.812786</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Charles Howard, 1st Earl of Nottingham (1536 –...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>49903</td>\n",
       "      <td>12.749735</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Rosh Chodesh or Rosh Hodesh (; trans. Beginnin...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>32951</td>\n",
       "      <td>12.748392</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>According to Islam, Muhammad's first revelatio...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>67551</td>\n",
       "      <td>12.717065</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Apocrypha are works, usually written works, th...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>51571</td>\n",
       "      <td>12.697702</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Rastafari is an Abrahamic belief which develop...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>35261</td>\n",
       "      <td>12.543121</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Zion ( Tsiyyon), also transliterated Sion, Say...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>1357</td>\n",
       "      <td>12.515150</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Elijah (, meaning \"My God is Yahu / Jah\"  ) or...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>34383</td>\n",
       "      <td>12.493687</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Simon the Zealot (), Simon, who was called the...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>7659</td>\n",
       "      <td>12.489595</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>In one or more theologies, a guardian angel is...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>16009</td>\n",
       "      <td>12.444338</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The phrase \"the empire on which the sun never ...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>37552</td>\n",
       "      <td>12.442630</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Anointing of the sick, known also by other nam...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>38235</td>\n",
       "      <td>12.372857</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>It is generally agreed that Jesus and his disc...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>29121</td>\n",
       "      <td>12.334124</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Belshazzar's Feast is a cantata by the English...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>33453</td>\n",
       "      <td>12.320745</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Sacramental bread (Latin: hostia), sometimes c...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>24208</td>\n",
       "      <td>12.305402</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>The Golden Legend (Latin: Legenda aurea or Leg...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bb_1905</td>\n",
       "      <td>45643</td>\n",
       "      <td>12.304854</td>\n",
       "      <td>0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>Nephi ( ) is one of the central figures descri...</td>\n",
       "      <td>Nation Shall Speak Peace Unto Nation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...                          full_question\n",
       "0   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "1   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "2   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "3   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "4   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "5   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "6   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "7   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "8   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "9   bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "10  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "11  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "12  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "13  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "14  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "15  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "16  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "17  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "18  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "19  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "20  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "21  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "22  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "23  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "24  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "25  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "26  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "27  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "28  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "29  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "30  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "31  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "32  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "33  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "34  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "35  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "36  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "37  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "38  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "39  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "40  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "41  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "42  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "43  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "44  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "45  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "46  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "47  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "48  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "49  bb_1905  ...  Nation Shall Speak Peace Unto Nation.\n",
       "\n",
       "[50 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>full_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>66058</td>\n",
       "      <td>31.622703</td>\n",
       "      <td>1</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Nullius in verba (Latin for \"on the word of no...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>13420</td>\n",
       "      <td>23.467662</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The President, Council, and Fellows of the Roy...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>39891</td>\n",
       "      <td>13.118247</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Eddie Koiki Mabo (c. 29 June 1936 – 21 January...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>54614</td>\n",
       "      <td>12.655831</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Palm Sunday is a Christian moveable feast that...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>34152</td>\n",
       "      <td>12.331806</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>A figure of speech or rhetorical figure  is fi...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>57746</td>\n",
       "      <td>12.061370</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>In Greek mythology, the Pierian Spring of Mace...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>53305</td>\n",
       "      <td>11.708740</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>An onomatopoeia (,   or chiefly NZ; from the G...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>57677</td>\n",
       "      <td>11.704328</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The Constitutional history of Australia began ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>38166</td>\n",
       "      <td>11.644904</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>A sign is an object, quality, event, or entity...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>46715</td>\n",
       "      <td>11.437795</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Colonization (or colonisation) is an ongoing p...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>25792</td>\n",
       "      <td>11.196741</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Victoria Island (Russ. Остров Виктория; Ostrov...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>65349</td>\n",
       "      <td>11.124531</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>This is a list of territorial disputes over la...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>65968</td>\n",
       "      <td>10.464349</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Works in the public domain are those whose exc...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>68948</td>\n",
       "      <td>10.287023</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Bir Tawil or Bi'r Tawīl ( '  or  ', meaning \"t...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>7502</td>\n",
       "      <td>9.486329</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>One of the main functions of the International...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>42804</td>\n",
       "      <td>9.367418</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Treasure trove is an amount of money or coin, ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>10966</td>\n",
       "      <td>8.978787</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The Group of Seven, also known as the Algonqui...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>57731</td>\n",
       "      <td>8.407157</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The Hala'ib Triangle (also spelled Halayeb ;  ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>72268</td>\n",
       "      <td>8.063557</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>European Australians are citizens or residents...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>61669</td>\n",
       "      <td>8.007226</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Imperialism is a type of advocacy of empire. I...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>30199</td>\n",
       "      <td>7.810760</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The \"51st state\", in post-1959 American politi...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>52605</td>\n",
       "      <td>7.782306</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Indigenous Australians are the Aboriginal and ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>13698</td>\n",
       "      <td>7.366347</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The Torres Strait Islands are a group of at le...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>73050</td>\n",
       "      <td>7.082758</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The history of Western Sahara can be traced ba...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>6144</td>\n",
       "      <td>7.006434</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>A treaty is an agreement under international l...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>69725</td>\n",
       "      <td>7.005124</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Melbourne City Centre (sometimes referred to a...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>32141</td>\n",
       "      <td>6.868276</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Queen Maud Land () is a c. 2.7 million-square-...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>31009</td>\n",
       "      <td>5.888507</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Sovereignty is understood in jurisprudence as ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>27608</td>\n",
       "      <td>5.777343</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>South Australia (abbreviated as SA) is a state...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>22823</td>\n",
       "      <td>5.622284</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Franz Josef Land, Franz Joseph Land or Francis...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>54053</td>\n",
       "      <td>5.450689</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Indigenous people, aboriginal people, or nativ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>39297</td>\n",
       "      <td>5.001149</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>South African contract law is ‘essentially a m...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>4641</td>\n",
       "      <td>4.468822</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Sovereignty over the Falkland Islands (Islas M...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>51550</td>\n",
       "      <td>4.340753</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Gottfried Wilhelm (von) Leibniz (;   or;  ;   ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>9865</td>\n",
       "      <td>4.232082</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Excommunication is an institutional act of rel...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>28185</td>\n",
       "      <td>4.211307</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Sudan ( as-Sūdān, English pronunciation (US), ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>39779</td>\n",
       "      <td>4.130156</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Australia (,,),   officially the Commonwealth ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>37401</td>\n",
       "      <td>4.061147</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Greenland (; ) is an autonomous country within...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>9118</td>\n",
       "      <td>3.671692</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Tycho Brahe, born Tyge Ottesen Brahe (;He adop...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>1007</td>\n",
       "      <td>3.331790</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>McNulty (MacNulty)  is an Irish surname histor...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>3553</td>\n",
       "      <td>2.813258</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Sexuality in ancient Rome, and more broadly, s...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>14624</td>\n",
       "      <td>2.696135</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The history of Australia refers to the history...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>22873</td>\n",
       "      <td>1.944718</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>English land law is the law of real property i...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>59451</td>\n",
       "      <td>1.363273</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Word games  (also called word game puzzles) ar...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>31486</td>\n",
       "      <td>1.348820</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>The Moby Project is a collection of public-dom...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>4251</td>\n",
       "      <td>1.348205</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>A root, or a root word, is a word that does no...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>73735</td>\n",
       "      <td>1.342406</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>This is a list of English language words of We...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>71541</td>\n",
       "      <td>1.334926</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>In general usage, a thesaurus is a reference w...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>7624</td>\n",
       "      <td>1.333466</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Pneumonoultramicroscopicsilicovolcanoconiosis ...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bb_1909</td>\n",
       "      <td>13619</td>\n",
       "      <td>1.332505</td>\n",
       "      <td>0</td>\n",
       "      <td>The Royal Society</td>\n",
       "      <td>Profanity, as defined by Merriam-Webster, is \"...</td>\n",
       "      <td>Nullius in verba. (On the word of no one.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  ...                               full_question\n",
       "0   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "1   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "2   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "3   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "4   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "5   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "6   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "7   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "8   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "9   bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "10  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "11  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "12  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "13  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "14  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "15  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "16  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "17  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "18  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "19  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "20  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "21  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "22  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "23  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "24  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "25  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "26  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "27  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "28  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "29  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "30  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "31  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "32  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "33  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "34  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "35  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "36  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "37  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "38  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "39  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "40  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "41  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "42  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "43  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "44  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "45  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "46  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "47  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "48  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "49  bb_1909  ...  Nullius in verba. (On the word of no one.)\n",
       "\n",
       "[50 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_sample_list[0])\n",
    "display(test_sample_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "OJP-zZClRhoW",
    "outputId": "3458a0f0-fbd9-4a7c-aec9-a722c49680db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>doc</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>full_question</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>new_score</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>24318</td>\n",
       "      <td>5.141289</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Medicine (British English; American English) i...</td>\n",
       "      <td>3.812071</td>\n",
       "      <td>Hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>64418</td>\n",
       "      <td>0.982765</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Violence is defined by the World Health Organi...</td>\n",
       "      <td>3.744488</td>\n",
       "      <td>Hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>64674</td>\n",
       "      <td>5.051980</td>\n",
       "      <td>1</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>The Fischer-Saller Scale, named after Eugen Fi...</td>\n",
       "      <td>3.622931</td>\n",
       "      <td>Hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>65141</td>\n",
       "      <td>-0.182845</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Race, as a social construct, is a group of peo...</td>\n",
       "      <td>3.201683</td>\n",
       "      <td>Hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb_2019</td>\n",
       "      <td>62797</td>\n",
       "      <td>3.464075</td>\n",
       "      <td>0</td>\n",
       "      <td>The FischerSaller scale, used in anthropology...</td>\n",
       "      <td>Eye color or eye colour is a polygenic phenoty...</td>\n",
       "      <td>2.857603</td>\n",
       "      <td>Hair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question    doc  ...  new_score  answer\n",
       "15  bb_2019  24318  ...   3.812071    Hair\n",
       "30  bb_2019  64418  ...   3.744488    Hair\n",
       "0   bb_2019  64674  ...   3.622931    Hair\n",
       "8   bb_2019  65141  ...   3.201683    Hair\n",
       "9   bb_2019  62797  ...   2.857603    Hair\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pairwise_scores[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdXjJWLTUZzy",
    "outputId": "8e5fc328-7eba-40da-aeed-afccc0c7c085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p@k - monoBERT:  0.4\n",
      "ap@k - monoBERT:  0.4\n",
      "p@k - monoBERT:  0.3\n",
      "ap@k - monoBERT:  0.45\n",
      "p@k - monoBERT:  0.23333333333333334\n",
      "ap@k - monoBERT:  0.4833333333333333\n",
      "p@k - monoBERT:  0.2625\n",
      "ap@k - monoBERT:  0.4499999999999999\n",
      "p@k - monoBERT:  0.29000000000000004\n",
      "ap@k - monoBERT:  0.4685416666666667\n",
      "R-precision - monoBERT:  0.31250000000000006\n",
      "AR-precision - monoBERT:  0.4624999999999999\n"
     ]
    }
   ],
   "source": [
    "#evaluate duoBERT\n",
    "for i in range(1, 6):\n",
    "  MPK_duoBERT = meanPrecisions(pairwise_scores, prep_question_test, k=i, PType='P@K')\n",
    "  print(\"p@k - monoBERT: \", MPK_duoBERT)\n",
    "  MAPK_duoBERT = meanPrecisions(pairwise_scores, prep_question_test, k=i, PType='AP@K')\n",
    "  print(\"ap@k - monoBERT: \", MAPK_duoBERT)\n",
    "MRPrecision_duoBERT = meanPrecisions(pairwise_scores, prep_question_test, k=5, PType='R-Precision')\n",
    "print(\"R-precision - monoBERT: \", MRPrecision_duoBERT)\n",
    "MARPrecision_duoBERT = meanPrecisions(pairwise_scores, prep_question_test, k=5, PType='AR-Precision')\n",
    "print(\"AR-precision - monoBERT: \", MARPrecision_duoBERT)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3pdNCZTM_F_d",
    "zrfpoGVLDHl4"
   ],
   "machine_shape": "hm",
   "name": "imformation_retrieval_probabilistic.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03d8a040dd3940a7acf0f56b0ba268ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9732f147c6a64e48920aa4e348c264f5",
      "placeholder": "​",
      "style": "IPY_MODEL_873b9b5892a44d1389bdd7ebf218c3ea",
      "value": " 1.36M/1.36M [00:03&lt;00:00, 358kB/s]"
     }
    },
    "07fadfbf86c74e86858d3ce5dd7a45a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dc14bd7e9224c318d6cab6d4c79528d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "140820e5d1964f32b7a5e527887b9f17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "172d9e49e6a643f3be2900a4ff3907bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ede5e11dff9949d9a8eafad5b7f7d92c",
       "IPY_MODEL_03d8a040dd3940a7acf0f56b0ba268ce"
      ],
      "layout": "IPY_MODEL_07fadfbf86c74e86858d3ce5dd7a45a5"
     }
    },
    "1aef7dfcd17b40f69f3feceb0f5759ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3bf9956f8c94f05b45173085fb50272",
      "placeholder": "​",
      "style": "IPY_MODEL_27920eb5dc2c435d989248bc218dce10",
      "value": " 331M/331M [00:09&lt;00:00, 33.4MB/s]"
     }
    },
    "27920eb5dc2c435d989248bc218dce10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3499a5f52a5e4255a9665e7d04801e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "36d9cd91683344d58c7f4723148e0317": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a5de4010a84493f9e582a125114b55e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3d769057db0e4e9ba9e99cf11fcf9d06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3e0c25b4d7b04c2d8191d4124c367a5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea990de26a164481bc765f0e40abbc50",
       "IPY_MODEL_5b9ce03bcd974e258db06a44d694fc40"
      ],
      "layout": "IPY_MODEL_b159100d944348c78fdc36b8f16be12c"
     }
    },
    "41ab387cdaff4f038261b3f85e9355bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43ad62528cf1438a9d9c1e585e4ca4ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4af7df11ca27409c84b3fd05e2d80b0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d5fd0ca1a7942ccb8009403cc823d22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59eeda1f0d324da1aba459951a7453cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b9ce03bcd974e258db06a44d694fc40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c984e45490224458b3f3fef0049c994a",
      "placeholder": "​",
      "style": "IPY_MODEL_41ab387cdaff4f038261b3f85e9355bf",
      "value": " 480/480 [00:00&lt;00:00, 3.26kB/s]"
     }
    },
    "72eecb5c27304be5a9011e56723a857d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59eeda1f0d324da1aba459951a7453cf",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a5de4010a84493f9e582a125114b55e",
      "value": 456318
     }
    },
    "7bc4bcdcc68f408fa880d56513469d9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72eecb5c27304be5a9011e56723a857d",
       "IPY_MODEL_d7d9501551f845e8bedcc20729eabb5c"
      ],
      "layout": "IPY_MODEL_0dc14bd7e9224c318d6cab6d4c79528d"
     }
    },
    "7d01fc7f4fa340fdb7f5f0c67a186f0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "868a0285280a44faa3aee4e65b44ae56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b41697e64a74750878290b6aea66bb1",
       "IPY_MODEL_f3a186e9567849e59ea539a91f0c2748"
      ],
      "layout": "IPY_MODEL_9528fee6a0274ae6b9a612713b330cf0"
     }
    },
    "873b9b5892a44d1389bdd7ebf218c3ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b41697e64a74750878290b6aea66bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4af7df11ca27409c84b3fd05e2d80b0c",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d769057db0e4e9ba9e99cf11fcf9d06",
      "value": 898823
     }
    },
    "9528fee6a0274ae6b9a612713b330cf0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9732f147c6a64e48920aa4e348c264f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a539328b2681470981654b562f4c90ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a916913ea81c4fc5bf54ebb4cc03341b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b159100d944348c78fdc36b8f16be12c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3bf9956f8c94f05b45173085fb50272": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c984e45490224458b3f3fef0049c994a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9e682ab03e84ddd80fbdb1f684049e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3da69bca30a452d90c54cfd02ac92e2",
       "IPY_MODEL_1aef7dfcd17b40f69f3feceb0f5759ff"
      ],
      "layout": "IPY_MODEL_ca0def8c27b64971a843b6dd58498838"
     }
    },
    "ca0def8c27b64971a843b6dd58498838": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7d9501551f845e8bedcc20729eabb5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a916913ea81c4fc5bf54ebb4cc03341b",
      "placeholder": "​",
      "style": "IPY_MODEL_7d01fc7f4fa340fdb7f5f0c67a186f0b",
      "value": " 456k/456k [00:00&lt;00:00, 1.40MB/s]"
     }
    },
    "e3da69bca30a452d90c54cfd02ac92e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a539328b2681470981654b562f4c90ad",
      "max": 331070498,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8a2f9d4e04d4acb87a3766c31b6ac1e",
      "value": 331070498
     }
    },
    "ea990de26a164481bc765f0e40abbc50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d5fd0ca1a7942ccb8009403cc823d22",
      "max": 480,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ecdd6e27940e47a2a01b2b466a1177d8",
      "value": 480
     }
    },
    "ecdd6e27940e47a2a01b2b466a1177d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ede5e11dff9949d9a8eafad5b7f7d92c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43ad62528cf1438a9d9c1e585e4ca4ab",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3499a5f52a5e4255a9665e7d04801e5a",
      "value": 1355863
     }
    },
    "f3a186e9567849e59ea539a91f0c2748": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36d9cd91683344d58c7f4723148e0317",
      "placeholder": "​",
      "style": "IPY_MODEL_140820e5d1964f32b7a5e527887b9f17",
      "value": " 899k/899k [00:04&lt;00:00, 203kB/s]"
     }
    },
    "f8a2f9d4e04d4acb87a3766c31b6ac1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
