{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3793,
     "status": "ok",
     "timestamp": 1623665087729,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "V6TWogv-xSS3",
    "outputId": "f76b5bc4-8fc7-4f69-d205-c06128e14c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Imports here\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import zipfile\n",
    "import os\n",
    "!pip install transformers\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xgSOtoJsF5S"
   },
   "source": [
    "Open the json training-data and store them in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57K8DwHkzD3w"
   },
   "outputs": [],
   "source": [
    "# Store the paths to the training file and the wikipedia paragraphs (evidence)\n",
    "path = r'./gdrive/MyDrive/Information_Retrieval_Project'\n",
    "wikiTrain = path + '/qa/wikipedia-train.json'\n",
    "evidencePath = path + '/evaluation/wikipedia.zip'\n",
    "verifiedPath = path + '/qa/verified-wikipedia-dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO0p6vo0bMQ3"
   },
   "outputs": [],
   "source": [
    "# Open the training file\n",
    "with open(wikiTrain, 'r', encoding='utf-8') as jsonFile:\n",
    "    data = json.load(jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1623659795871,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "pibhxKiZyrMq",
    "outputId": "54db52af-304f-4eb6-f12d-1ef7656f69c4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Judi_Dench.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the file opens\n",
    "answer = data[\"Data\"][0][\"Answer\"]\n",
    "question = data[\"Data\"][0][\"Question\"]\n",
    "answerFileName = data[\"Data\"][0][\"EntityPages\"][1][\"Filename\"]\n",
    "answerFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFHJ7j9cytBJ"
   },
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile(evidencePath, 'r')\n",
    "dataArray = np.array(data[\"Data\"])\n",
    "\n",
    "questionArray = np.zeros(len(dataArray), dtype='object')\n",
    "answerArray = np.zeros(len(dataArray), dtype='object')\n",
    "answerFileArray = np.zeros(len(dataArray), dtype='object')\n",
    "\n",
    "i = 0\n",
    "# Read the Question, Answers + Paragraphs and store them in an array each\n",
    "for item in dataArray:\n",
    "    questionArray[i] = item[\"Question\"]\n",
    "    answerArray[i] = item[\"Answer\"][\"Value\"]\n",
    "    filePath = item[\"EntityPages\"][0][\"Filename\"]\n",
    "    \n",
    "    # Read the Paragraph (if the File exists)\n",
    "    try:        \n",
    "      paragraph = archive.read('wikipedia/' + filePath).decode(\"utf-8\")\n",
    "      answerFileArray[i] = paragraph\n",
    "    except KeyError:\n",
    "      answerFileArray[i] = \"NAN\"   \n",
    "    i += 1       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAqn0q93sPx9"
   },
   "source": [
    "**3 Methods to:**\n",
    "1. get a pre-trained model\n",
    "2. answer a question given a model (from 1.) + tokenizer (from 1.) + question + paragraph which contains the answer\n",
    "3. use 2. but can take multiple paragraphs (paragraphArray) per question as parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLwYSN_OswKi"
   },
   "source": [
    "Test the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jegkPN58XCP"
   },
   "outputs": [],
   "source": [
    "# get a pre-trained model\n",
    "def getModel():\n",
    "    #Model\n",
    "    model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "    #Tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "    return model,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "4321b91e13bd4072b5348131f0a22804",
      "3b28e538e9624d51824420c1b92c6c05",
      "59ffaef46ca8499d9957e85c27fb3bfb",
      "a481053d79a54f5a81f2cc5bfdb46abf",
      "3733d7f65639420588250531f49f7df6",
      "9037eb92b01445d4a2d72362fffbbefd",
      "2acd78c35ba348d38df4c0797334ad62",
      "8458fb10ca3145758b0ceff71add1858",
      "822c4c8b61de4b6588591c0f9938bcc7",
      "f03e74d228294767abaaf8708844dc7b",
      "e59e184146114c0c8fe048f397c24b76",
      "9ebe5efc1de04370ba7253a4b2b85c97",
      "a44aadba618c4869905ed836708c33e5",
      "f1984461492849cc9ce8c00b7e54ae07",
      "c64baac2b3194c63bfccdd0d8f24d965",
      "707f8697fddb41dba20756484247012d",
      "ed07fa2a2a654f388937c879e0b546ec",
      "f7fb0f8c87d14271bf0b5787f6486f11",
      "9e1437bbca934f78b2bd09f673b1d96f",
      "2f26fa2677f04776b407b3dfde4164fa",
      "33913cb896ad4c2cbfc8fabd2a7c9540",
      "89731e5e10134c498d366cdaf7cfd4b0",
      "c369d6836a6f4f568944f253dc4414b0",
      "60ba28ac44234dc6aa14d57bf7242165",
      "32e1208d843241c88cc294d9b33c7b54",
      "98ba678642da4b649acdc42b5e155bf3",
      "6c7461492a6c46d4ba01a43a9e604eed",
      "f251cba1350842a0b27b1c4f41e5e5b7",
      "0f2e06f7a54f4eba99d237b15928e24a",
      "4edf2d70f11347b9a8d71da86f36d395",
      "87c6ff3617de44b3b1b916debf2de2c6",
      "d60a1a8e29a54803a6ac752400708397",
      "cb2f2003cc4248abb0d9a3c6d0cd0136",
      "794dda0c64f349e4b7ac7a49b4f5b9ac",
      "547a22665d9b4bc4af47fab0572c8d8c",
      "21f008faac4f460d909e5ed966ae68b9",
      "707a4f70f375442eb7b4fe977d14c49b",
      "55fdaa97509f474e8d6e596105c3addc",
      "b707499dac294f58947c24ab63a878c3",
      "8998977b272a444b9adafaef60bcaee0"
     ]
    },
    "executionInfo": {
     "elapsed": 31230,
     "status": "ok",
     "timestamp": 1623659855467,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "gq0PjwpU2mKu",
    "outputId": "b045feb5-1854-4cd1-b5bb-a58a08a61147"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4321b91e13bd4072b5348131f0a22804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822c4c8b61de4b6588591c0f9938bcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed07fa2a2a654f388937c879e0b546ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e1208d843241c88cc294d9b33c7b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2f2003cc4248abb0d9a3c6d0cd0136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the pretained model + tokenizer\n",
    "model, tokenizer = getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBAYizjO88OJ"
   },
   "outputs": [],
   "source": [
    "def questionAnswering(model, tokenizer, question, paragraph, numOverflow = 3, returnStartEndValues = False):\n",
    "    encoding = tokenizer.encode_plus(question, paragraph, max_length=512, truncation='only_second', return_overflowing_tokens=True, add_special_tokens=True)\n",
    "\n",
    "    # get the type of bert model to be able to compare later\n",
    "    bertModel = type(BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad'))\n",
    "\n",
    "    try:\n",
    "        # gives a TypeError when we only have one token (no overflow)\n",
    "        # The only time this might be a problem is when we would have only one single token and\n",
    "        # only one value inside this token, which is impossible because of the words that Bert adds\n",
    "        # while tokenizing the question and the paragraph\n",
    "        lenEntries = len(encoding['input_ids'][0])\n",
    "\n",
    "        # OverflowTokens Exist -> Change the length\n",
    "        numberTokens = len(encoding['input_ids'])\n",
    "    except TypeError:\n",
    "        # Set the tokens to one to use the foor loop only once\n",
    "        numberTokens = 1\n",
    "\n",
    "    # Limit number of overflowTokens to reduce computing time\n",
    "    if numberTokens > numOverflow:\n",
    "        numberTokens = numOverflow\n",
    "\n",
    "    # empty Arrays to store overflow scoring values\n",
    "    startValues = np.empty(0)\n",
    "    endValues = np.empty(0)\n",
    "\n",
    "    # go through every token, calculate the appropriate scores and append them to start/endValues\n",
    "    # Bert is limited to one token with 512 entries at a time\n",
    "    for i in range(numberTokens):\n",
    "        if numberTokens != 1:\n",
    "            tokens = encoding['input_ids'][i]\n",
    "            sentence_embedding = encoding['token_type_ids'][i]\n",
    "            attention_mask = encoding['attention_mask'][i]\n",
    "        else:\n",
    "            tokens = encoding['input_ids'][0]\n",
    "            sentence_embedding = encoding['token_type_ids'][0]\n",
    "            attention_mask = encoding['attention_mask'][0]\n",
    "\n",
    "        if isinstance(model, bertModel):\n",
    "          output = model(input_ids=torch.tensor([tokens]), attention_mask=torch.tensor([attention_mask]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "          startValues = np.append(startValues, output.start_logits.detach().numpy()[0])\n",
    "          endValues = np.append(endValues, output.end_logits.detach().numpy()[0])          \n",
    "        else:\n",
    "          output = model(input_ids=torch.tensor([tokens]), attention_mask=torch.tensor([attention_mask]))\n",
    "          startValues = np.append(startValues, output[0].detach().numpy()[0])\n",
    "          endValues = np.append(endValues, output[1].detach().numpy()[0])\n",
    "\n",
    "    # find the absolute position of start and end index\n",
    "    start_index = np.argmax(startValues)\n",
    "    startValue = np.amax(startValues)\n",
    "    end_index = np.argmax(endValues)\n",
    "    endValue = np.amax(endValues)\n",
    "    \n",
    "\n",
    "    # if overflow tokens exist:\n",
    "    if numberTokens != 1:\n",
    "        # Find the correct start and end tokens (only the tokens not the position)\n",
    "        overflowNrStart = int(start_index / 512)\n",
    "        overflowNrEnd = int(end_index / 512)\n",
    "\n",
    "        # Find the correct position in the token\n",
    "        answerStart = start_index % 512\n",
    "        answerEnd = end_index % 512\n",
    "\n",
    "        # get the answer from the corresponding tokens and format for better reading\n",
    "        answer = ' '.join(tokenizer.convert_ids_to_tokens(encoding['input_ids'][overflowNrStart][answerStart:answerEnd + 1]))\n",
    "        answer = answer.replace(' ##', '')\n",
    "        if returnStartEndValues == True:\n",
    "          return (answer, startValue, endValue)\n",
    "        else:    \n",
    "          return (answer)\n",
    "    else:\n",
    "        # get the answer from the corresponding tokens and format for better reading\n",
    "        answer = ' '.join(tokenizer.convert_ids_to_tokens(encoding['input_ids'][0][start_index:end_index + 1]))\n",
    "        answer = answer.replace(' ##', '')\n",
    "        if returnStartEndValues == True:\n",
    "          return (answer, startValue, endValue)\n",
    "        else:    \n",
    "          return (answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4686,
     "status": "ok",
     "timestamp": 1623616837399,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "7PizYAeF_3yQ",
    "outputId": "35ae9c71-820a-43f5-85e5-1b47ab9c26e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'sample data'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are machine learning models based on?\"\n",
    "paragraph= \"\"\"\n",
    "Machine learning (ML) is the study of computer algorithms that improve automatically through experience. \n",
    "It is seen as a part of artificial intelligence.\n",
    "Machine learning algorithms build a model based on sample data,  as \"training data\", \n",
    "in order to make predictions or decisions without being explicitly programmed to do so. \n",
    "Machine learning algorithms are used in a wide variety of applications, \n",
    "such as email filtering and computer vision, \n",
    "where it is difficult or unfeasible to develop conven algorithms to perform the needed tasks.\n",
    "\"\"\"\n",
    "questionAnswering(model, tokenizer, question, paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C4H5Qn8s5G8"
   },
   "source": [
    "Create a function that can work with multiple paragraphs (files) per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJ6ZGFhV2cyh"
   },
   "outputs": [],
   "source": [
    "# give multiple paragraphs for the same question and return the answer with the highest score\n",
    "def multipleQuestionAnswering(model, tokenizer, question, paragraphArray, numOverflow = 3, returnStartEndValues = False):\n",
    "  # check if paragraphArray is in fact an array or just a single paragraph\n",
    "  # if only a single paragraph: change nothing from normal questionAnswering\n",
    "  if isinstance(paragraphArray, str):\n",
    "      return (questionAnswering(model, tokenizer, question, paragraphArray, numOverflow, returnStartEndValues))       \n",
    "  \n",
    "  paragraphs = len(paragraphArray)\n",
    "  answerArray = np.zeros(paragraphs, dtype=\"object\")\n",
    "  startValuesArray = np.zeros(paragraphs)\n",
    "  endValuesArray = np.zeros(paragraphs)\n",
    "  i = 0\n",
    "  # answer the same question for each of the paragraphs\n",
    "  for paragraph in paragraphArray:\n",
    "    # check if another paragraph exists. 0 = no more paragraphs\n",
    "    if paragraph == 0:\n",
    "      break\n",
    "    answer, startValue, endValue = questionAnswering(model, tokenizer, question, paragraph, numOverflow, returnStartEndValues=True)\n",
    "    answerArray[i] = answer\n",
    "    startValuesArray[i] = startValue\n",
    "    endValuesArray[i] = endValue\n",
    "    i += 1\n",
    "\n",
    "  #print(startValuesArray)\n",
    "  #print(endValuesArray)\n",
    "  # it doesn't matter if searching in the start- or endvalues array\n",
    "  # return the answer with the highest score\n",
    "  if returnStartEndValues == True:\n",
    "    return (answerArray[np.argmax(startValuesArray)], np.amax(startValuesArray), np.amax(endValuesArray))\n",
    "  else:    \n",
    "    return (answerArray[np.argmax(startValuesArray)])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muPH0yE0_8Je"
   },
   "source": [
    "Store multiple files per question in a separate array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 35619,
     "status": "ok",
     "timestamp": 1623660000745,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "7Jkx6vxnhV8w",
    "outputId": "061cc311-e1e1-48a7-f181-a03c99435fe8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Dame Judith Olivia \"Judi\" Dench,  (born 9 December 1934)  is an English actress and author.  Dench m'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change numberFileArray to be able to multiple paragraphs per question/answer\n",
    "# Limit number of paragraphs to 5 per question/answer\n",
    "maxParagraphs = 5\n",
    "# create first entry in multipleAnswerFileArray \n",
    "# each entry has to be the same length (maxParagraphs) in order to \n",
    "# store a 1D-Array in a 2D-Array\n",
    "multipleAnswerFileArray = np.zeros((len(dataArray) , maxParagraphs), dtype='object')\n",
    "\n",
    "j = 0\n",
    "for item in dataArray:\n",
    "  currentParagraphs = np.zeros(maxParagraphs, dtype='object')\n",
    "  i = 0\n",
    "  for file in (item[\"EntityPages\"]):\n",
    "    # Read the Paragraph (if the File exists) and save in array\n",
    "    try:        \n",
    "      multipleAnswerFileArray[j][i] = archive.read('wikipedia/' + file[\"Filename\"]).decode(\"utf-8\")\n",
    "    except KeyError:\n",
    "      multipleAnswerFileArray[j][i] = \"NAN\"  \n",
    "\n",
    "\n",
    "    i += 1\n",
    "    # if maximum no of paragraphs is reached:\n",
    "    # do not continue inner for loop\n",
    "    if i == maxParagraphs:\n",
    "      break\n",
    "  # stack the array with the current paragraphs with all others      \n",
    "  j += 1\n",
    "\n",
    "#show the seconds paragraph (textfile) of the first question\n",
    "multipleAnswerFileArray[0][1][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7na9RNbes7P8"
   },
   "source": [
    "Fine-tune a pretrained Bert model (DistilBert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11019,
     "status": "ok",
     "timestamp": 1623660011761,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "cvcx6Kg8oKSc",
    "outputId": "cb2d4a9d-9b90-449b-c78b-a07b0b73ba26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed entries: 19494\n"
     ]
    }
   ],
   "source": [
    "# Train own model\n",
    "\n",
    "# Create another array to store both the Start and End of the Answer inside each Answer\n",
    "numberAnswers = len(answerArray)\n",
    "answerStartEndArray = np.empty((numberAnswers, 3), dtype=object)\n",
    "deleteArray = np.empty(0, dtype=np.int32)\n",
    "\n",
    "counter = 0\n",
    "for i in range(numberAnswers):\n",
    "  paragraph = answerFileArray[i].lower()\n",
    "  answer = answerArray[i].lower().strip()\n",
    "  answerStart = paragraph.find(\" \" + answer + \" \")\n",
    "  answerEnd = answerStart + len(\" \" + answer + \" \")\n",
    "  if answerStart < 0:\n",
    "    counter += 1 \n",
    "    deleteArray = np.append(deleteArray, i)\n",
    "  else:\n",
    "    answerStartEndArray[i][0] = answer\n",
    "    answerStartEndArray[i][1] = answerStart\n",
    "    answerStartEndArray[i][2] = answerEnd\n",
    "\n",
    "print(\"Removed entries: \" + str(counter))\n",
    "#remove entries, where the answer was not found in the text from all three arrays\n",
    "answerStartEndArray = np.delete(answerStartEndArray, deleteArray, 0)\n",
    "questionDelArray = np.delete(questionArray, deleteArray)\n",
    "multipleAnswerFileDelArray = np.delete(multipleAnswerFileArray, deleteArray, 0)\n",
    "answerFileDelArray = np.delete(answerFileArray, deleteArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CYvJ9D-_gsW"
   },
   "outputs": [],
   "source": [
    "# When using Bert as above, Colab does not have enough RAM (the kernel closes after 20 seconds or so)\n",
    "def getDistilBertModel():\n",
    "  model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad', torchscript=True)\n",
    "  tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "  return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCn4lu4FAF8s"
   },
   "source": [
    "Function to:\n",
    "1. tokenize the paragraph + question\n",
    "2. Find for each question the bucket (with 512 tokens) that contains the answer\n",
    "   to the question\n",
    "   returns tokenized questions-paragraphs to use for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJZbMgnX_hTs"
   },
   "outputs": [],
   "source": [
    "def tokenizeRightBucket(tokenizer, paragraphs, questions, answers):\n",
    "\n",
    "  # tokenize the paragraph + question\n",
    "  # train_encodings               -> 1 bucket for each question, truncated to 512 tokens\n",
    "  # train_encodings_overflow      -> x buckets for each question, each bucket truncated to 512 tokens\n",
    "  # train_encodings_non_truncated -> 1 bucket for each question, x amount of tokens (non-truncated)\n",
    "  train_encodings = tokenizer(paragraphs.tolist(), questions.tolist(), padding=True, truncation=True)\n",
    "  train_encodings_Overflow = tokenizer(paragraphs.tolist(), questions.tolist(), padding=True, truncation=True, max_length=512, return_overflowing_tokens=True)\n",
    "  train_encodings_non_Truncated = tokenizer(paragraphs.tolist(), questions.tolist(), padding=False)\n",
    "\n",
    "  \n",
    "  # save the length of each question (to know where to start)\n",
    "  lastBucket = 0\n",
    "  maxLen = len(train_encodings_Overflow['input_ids'])\n",
    "\n",
    "  # Go through every question and save only the bucket (the paragraph) with the answer to the question\n",
    "  for i in range(len(train_encodings['input_ids'])):\n",
    "\n",
    "    # Special Tokens that occur in each bucket: 101 = CLS, 102 = SEP\n",
    "    # Tokens for Paragraph = Find the first use of the SEP\n",
    "    SepToken = train_encodings['input_ids'][i].index(102)\n",
    "    # Get the total Number of Paragraph Tokens (without the SEP/CLS tokens and without the question)\n",
    "    NoTokens = train_encodings_non_Truncated['input_ids'][i].index(102) - 1\n",
    "    # Get the total Number of buckets needed (to be later added to lastBucket)\n",
    "    NoBuckets = int(NoTokens / SepToken)\n",
    "    \n",
    "    # Search the token inside the whole paragraph which represents the answer\n",
    "    # tokenize the answer to know which token to look for\n",
    "    # Searching for only the first token is not enough\n",
    "    # Example: Right answer = Joan Rivers, but seraching only for Joan\n",
    "    # Joan Alexandra is found, therefore search for all answer tokens\n",
    "    tokenizedAnswer = tokenizer(answers[i][0], answers[i][0])['input_ids']\n",
    "    # tokenized Answer looks something like this then: [CLS] joan rivers [SEP] joan rivers [SEP]\n",
    "    # search for the tokens on position 1 and stop on the [SEP] token (number 102)\n",
    "    # If there are multiple tokens in the answer they have to be exactly 1 position away from each other\n",
    "    # in the non_truncated list in order to ensure that the correct answer is found and not some partly\n",
    "    # correct string\n",
    "    # Offset to give a start where to look for the answer\n",
    "    answerSepPosition = tokenizedAnswer.index(102)\n",
    "    tokenOffset = 0\n",
    "    currentStart = 0 \n",
    "    j = 1\n",
    "    while j < answerSepPosition:\n",
    "        # check if end is reached\n",
    "        if j + 1 == answerSepPosition:\n",
    "          break\n",
    "        # save the start Position  \n",
    "        if j == 1:\n",
    "          currentStart = tokenOffset\n",
    "        currentPosition = train_encodings_non_Truncated['input_ids'][i].index(tokenizedAnswer[j], tokenOffset)\n",
    "        #Set tokenOffset to the current Position to not find any previous mentions of the next position\n",
    "        tokenOffset = currentPosition + 1\n",
    "        nextPosition = train_encodings_non_Truncated['input_ids'][i].index(tokenizedAnswer[j + 1], tokenOffset)\n",
    "        # if the next answer part does not follow directly the first part: wrong answer found\n",
    "        if not currentPosition + 1 == nextPosition:\n",
    "          j = 1\n",
    "        else:  \n",
    "          j += 1\n",
    "    # set Offset to the start of the answer token\n",
    "    tokenOffset = currentStart\n",
    "\n",
    "    # get the index of the answer Token\n",
    "    tokenPosition = train_encodings_non_Truncated['input_ids'][i].index(tokenizedAnswer[1], tokenOffset)\n",
    "    bucketNo = int(tokenPosition / SepToken)\n",
    "    tokenPositionCorrected = tokenPosition - bucketNo * SepToken\n",
    "    tokenPositionCorrected = tokenPositionCorrected + bucketNo\n",
    "\n",
    "    # check if the calculated bucket has indeed the right token(s)\n",
    "    # Very rarely the bucket is slightly off\n",
    "    correction = 0\n",
    "    try:\n",
    "      j = 1\n",
    "      while j < answerSepPosition:\n",
    "        test = train_encodings_Overflow['input_ids'][bucketNo + lastBucket].index(tokenizedAnswer[j])\n",
    "        j += 1\n",
    "    except ValueError:\n",
    "      try:\n",
    "        j = 1\n",
    "        while j < answerSepPosition:\n",
    "          test = train_encodings_Overflow['input_ids'][bucketNo + lastBucket].index(tokenizedAnswer[j])\n",
    "          j += 1\n",
    "        correction = -1    \n",
    "      except ValueError:\n",
    "        try:\n",
    "          j = 1\n",
    "          while j < answerSepPosition:\n",
    "            test = train_encodings_Overflow['input_ids'][bucketNo + lastBucket].index(tokenizedAnswer[j])\n",
    "            j += 1\n",
    "          correction = 1  \n",
    "        except ValueError:\n",
    "          #do nothing for now (entry will be removed later)\n",
    "          correction = 0\n",
    "    \n",
    "    # replace the first bucket with the bucket that contains the answer (for both the input_ids and attention_mask)\n",
    "    #print(tokenizer.decode(train_encodings_Overflow['input_ids'][bucketNo + lastBucket][tokenPositionCorrected]))\n",
    "    train_encodings['input_ids'][i] = train_encodings_Overflow['input_ids'][bucketNo + lastBucket + correction]\n",
    "    train_encodings['attention_mask'][i] = train_encodings_Overflow['attention_mask'][bucketNo + lastBucket + correction]\n",
    "\n",
    "    #Increase the bucket count accordingly\n",
    "    lastBucket += NoBuckets + 1 \n",
    "\n",
    "    # check if the calculated lastBucket is really the last Bucket (the calculation is very slightly off rarely which can can cause problems)\n",
    "    # save the tokens for the current question and compare them with the tokens in the next bucket\n",
    "    # if they are the same: they belong to the same question\n",
    "    # if not: different (exit loop)\n",
    "    if lastBucket < maxLen:\n",
    "      # Because of the overflowing tokens, the separation token is not in the same spot for all of them\n",
    "      sepTokenOverflow = train_encodings_Overflow['input_ids'][lastBucket - 1].index(102)\n",
    "      currentQuestion = train_encodings_Overflow['input_ids'][lastBucket - 1][sepTokenOverflow:]\n",
    "      endReached = False\n",
    "      while not endReached:\n",
    "        #Same for overflowBucket\n",
    "        sepTokenOverflowNextBucket = train_encodings_Overflow['input_ids'][lastBucket].index(102)\n",
    "        \n",
    "        # Find the start of the padding token (and therefore the end of the question at one position before that)\n",
    "        # This is only relevant for the nextBucket, because if a padding exists in the previous bucket, then\n",
    "        # this bucket is definitely the end of the question and no further check is needed.\n",
    "        try:\n",
    "          questionEndNextBucket = train_encodings_Overflow['input_ids'][lastBucket].index(0)\n",
    "        except ValueError:\n",
    "          # it might be possible that there is no padding but still it is the end of the question\n",
    "          # if the tokens take up exactly 512 slots in the bucket -> then the length of the bucket\n",
    "          # is the end of the question\n",
    "          questionEndNextBucket = len(train_encodings_Overflow['input_ids'][lastBucket])\n",
    "\n",
    "        questionNextBucket = train_encodings_Overflow['input_ids'][lastBucket][sepTokenOverflowNextBucket:questionEndNextBucket]\n",
    "        #questionNextBucket[0] -> Padding (discard)\n",
    "        if currentQuestion == questionNextBucket and questionNextBucket[0] != 0:\n",
    "          lastBucket += 1\n",
    "        else: \n",
    "          endReached = True\n",
    "  return train_encodings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bn0njtXVAT7k"
   },
   "source": [
    " Add the start and end position of the answer to the train encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBnEeAUf_qVl"
   },
   "outputs": [],
   "source": [
    "#\n",
    "def add_token_positions(encodings, answers):\n",
    "    # initialize lists to contain the token indices of answer start/end\n",
    "    start_positions = np.zeros(len(encodings['input_ids']), dtype=object)\n",
    "    end_positions = np.zeros(len(encodings['input_ids']), dtype=object)\n",
    "    deleteArray = []\n",
    "    for i in range(len(answers)):\n",
    "        # tokenize the answer to know which token to look for\n",
    "        tokenizedAnswer = tokenizer(answers[i][0], answers[i][0])['input_ids']\n",
    "        sepTokenAnswer = tokenizedAnswer.index(102)\n",
    "        sepTokenQuestion = encodings['input_ids'][i].index(102)\n",
    "        \n",
    "        tokenOffset = 0\n",
    "        currentStart = 0 \n",
    "        j = 1\n",
    "        try:\n",
    "          while j < sepTokenAnswer:\n",
    "              # check if end is reached\n",
    "              if j + 1 == sepTokenAnswer:\n",
    "                break\n",
    "              if j == 1:\n",
    "                currentStart = tokenOffset\n",
    "              currentPosition = encodings['input_ids'][i].index(tokenizedAnswer[j], tokenOffset)\n",
    "              #Set tokenOffset to the current Position to not find any previous mentions of the next position\n",
    "              tokenOffset = currentPosition + 1\n",
    "\n",
    "              # it may happen that nextPosition is not part of the bucket anymore\n",
    "              # Since only one bucket can be used at a time -> rest of the answer has to be discarded\n",
    "              if (j + tokenOffset + 1) >= sepTokenQuestion:\n",
    "                break\n",
    "\n",
    "              nextPosition = encodings['input_ids'][i].index(tokenizedAnswer[j + 1], tokenOffset)\n",
    "              # if the next answer part does not follow directly the first part: wrong answer found\n",
    "              if not currentPosition + 1 == nextPosition:\n",
    "                j = 1\n",
    "              else:  \n",
    "                j += 1\n",
    "          tokenOffset = currentStart\n",
    "          # find out how many tokens are used for the answer\n",
    "          answerNoTokens = sepTokenAnswer - 2\n",
    "          \n",
    "          # append start/end token position using char_to_token method\n",
    "          start_positions[i] = encodings['input_ids'][i].index(tokenizedAnswer[1], tokenOffset)   #encodings.char_to_token(i, answers[i][1])\n",
    "\n",
    "          # if greater than 512: return to 511 (maximum index)\n",
    "          end_positions[i] = start_positions[i] + answerNoTokens\n",
    "          if end_positions[i] >= sepTokenQuestion:\n",
    "            end_positions[i] = sepTokenQuestion - 1\n",
    "        except ValueError:\n",
    "          # if it hasn't been found: discard this entry\n",
    "          # this happen in about 10 - 20 cases per 5000 questions\n",
    "          start_positions[i] = 0\n",
    "          end_positions[i] = 0\n",
    "          deleteArray.append(i)                 \n",
    "\n",
    "    # update our encodings object with the new token-based start/end positions\n",
    "    encodings.update({'start_positions': start_positions.tolist(), 'end_positions': end_positions.tolist()})\n",
    "    # delete the entries where the question was not found in the assigned bucket\n",
    "    # this happens roughly in 1 of 500 questions\n",
    "    for value in deleteArray:\n",
    "      del encodings['input_ids'][value]\n",
    "      del encodings['attention_mask'][value]\n",
    "      del encodings['start_positions'][value]\n",
    "      del encodings['end_positions'][value]\n",
    "      answers = np.delete(answers, value, 0)      \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-WXTHZmAX4S"
   },
   "source": [
    "Define a class Dataset for the tokenized Questions+Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1N1kqoM_0UW"
   },
   "outputs": [],
   "source": [
    "class QuestionAnswerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7rloDg4AbQV"
   },
   "source": [
    "Train the Distilbert with the correct token inside the 512 token length paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eg9ZNvBmy6vt"
   },
   "outputs": [],
   "source": [
    "def modelTraining(model, train_dataset, batchSize=32):\n",
    "  # setup GPU/CPU\n",
    "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "  # move model over to detected device\n",
    "  model.to(device)\n",
    "  # activate training mode of model\n",
    "  model.train()\n",
    "  # initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
    "  optim = AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "  # initialize data loader for training data\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "  for epoch in range(1):\n",
    "      # set model to train mode\n",
    "      model.train()# setup loop (we use tqdm for the progress bar)\n",
    "      loop = tqdm(train_loader, leave=True)\n",
    "      for batch in loop:\n",
    "          # initialize calculated gradients (from prev step)\n",
    "          optim.zero_grad()\n",
    "          # pull all the tensor batches required for training\n",
    "          input_ids = batch['input_ids'].to(device)\n",
    "          attention_mask = batch['attention_mask'].to(device)\n",
    "          start_positions = batch['start_positions'].to(device)\n",
    "          end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "          # train model on batch and return outputs (incl. loss)\n",
    "          outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                          start_positions=start_positions,\n",
    "                          end_positions=end_positions)\n",
    "          \n",
    "          # extract loss\n",
    "          loss = outputs[0]\n",
    "          # calculate loss for every parameter that needs grad update\n",
    "          loss.backward()\n",
    "          # update parameters\n",
    "          optim.step()\n",
    "          # print relevant info to progress bar\n",
    "          loop.set_description(f'Epoch {epoch}')\n",
    "          loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHAqb4sABIRb"
   },
   "source": [
    "Train the model using above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asMd5H6KuI0O"
   },
   "outputs": [],
   "source": [
    "def trainModel (model, tokenizer, train_Paragraph, train_Question, train_Answer):\n",
    "\n",
    "  # Tokenize the Question + Paragraphs\n",
    "  train_encodings = tokenizeRightBucket(tokenizer, train_Paragraph, train_Question, train_Answer)\n",
    "\n",
    "  # Search for the Token inside the tokenized Paragraphs (if they are not truncated)\n",
    "  train_AnswerCorrected = add_token_positions(train_encodings, train_Answer)\n",
    "\n",
    "  # build datasets for both our training and validation sets\n",
    "  train_dataset = QuestionAnswerDataset(train_encodings)\n",
    "\n",
    "  # train the model\n",
    "  modelTraining(model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaxrtV4aiiJd"
   },
   "outputs": [],
   "source": [
    "size = 0.05\n",
    "train_Question, test_Question = train_test_split(questionDelArray, test_size=size, shuffle=False)\n",
    "train_Answer, test_Answer = train_test_split(answerStartEndArray, test_size=size, shuffle=False)\n",
    "multiple_Train_Paragraph, multiple_Test_Paragraph = train_test_split(multipleAnswerFileDelArray, test_size=size, shuffle=False)\n",
    "train_Paragraph, test_Paragraph = train_test_split(answerFileDelArray, test_size=size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "a5b644c4f6204bf6ae396940996dacfd",
      "0acbc1b390e54d1a9160ce23b7a13280",
      "f2015d2652d446b3a814827194c8d4f7",
      "627d151b53ad45e2b717a3ec7e05fdce",
      "f951b3beeb07474caf59515937cf0546",
      "c58f6219e5234ae880e24f307027e6c5",
      "b3e1e8955523470d829b4ae175a34c28",
      "bb3c30655b4645b593910942cb10a9c6",
      "eb77933723584f648b507eab6a8c5d21",
      "e166f74d0d914944b80499ef1b942991",
      "4f1f28081e5e43849feacbd359954d4c",
      "22e60c8cd21642ccaa67ac72aff5dc23",
      "26a9aea9f6d04642b8de0bae16a435cf",
      "1c7876b377c34776a8cbc4ee50ececf6",
      "08d85022435f4567845c2e864e6df42c",
      "b9ec5ddb87204626bb994ce17c35ef7c"
     ]
    },
    "executionInfo": {
     "elapsed": 15591,
     "status": "ok",
     "timestamp": 1623616903731,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "PuTr2S3VecFE",
    "outputId": "d4a14b8a-bbda-4664-d688-a12b3676a623"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b644c4f6204bf6ae396940996dacfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb77933723584f648b507eab6a8c5d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=265481570.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Switch to DistilBert\n",
    "model, tokenizer = getDistilBertModel()\n",
    "\n",
    "# Get the latest Model\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('./gdrive/MyDrive/Information_Retrieval_Project/bertQA/', local_files_only = True, torchscript=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67570,
     "status": "ok",
     "timestamp": 1623501624470,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "u6fZaaPLrgaF",
    "outputId": "5ee34e04-0923-4952-c3be-a80cb30c90a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (17444 > 512). Running this sequence through the model will result in indexing errors\n",
      "Epoch 0: 100%|██████████| 156/156 [24:51<00:00,  9.56s/it, loss=0.594]\n",
      "Epoch 0: 100%|██████████| 156/156 [27:25<00:00, 10.55s/it, loss=0.0783]\n",
      "Epoch 0: 100%|██████████| 156/156 [29:27<00:00, 11.33s/it, loss=0.257]\n",
      "Epoch 0: 100%|██████████| 156/156 [32:39<00:00, 12.56s/it, loss=0.0621]\n",
      "Epoch 0: 100%|██████████| 156/156 [33:54<00:00, 13.04s/it, loss=0.47]\n",
      "Epoch 0: 100%|██████████| 156/156 [34:24<00:00, 13.23s/it, loss=0.518]\n",
      "Epoch 0: 100%|██████████| 156/156 [33:48<00:00, 13.00s/it, loss=0.218]\n",
      "Epoch 0: 100%|██████████| 156/156 [34:09<00:00, 13.14s/it, loss=0.535]\n",
      "Epoch 0: 100%|██████████| 9/9 [01:54<00:00, 12.72s/it, loss=0.518]\n"
     ]
    }
   ],
   "source": [
    "# because of RAM limitations only 5000 entries are safe to train at a time\n",
    "# therefore train the model on 5000 entries, then the next 5000 and so on\n",
    "# Also saves the  model after 5000 steps \n",
    "# (in case Colab disconnects you the amount of data lost in reduced)\n",
    "stepSize = 5000\n",
    "startTraining = 0\n",
    "endTraining = startTraining + stepSize\n",
    "numberQuestions = len(train_Paragraph)\n",
    "while startTraining < numberQuestions:\n",
    "  trainModel(model, tokenizer, train_Paragraph[startTraining:endTraining], train_Question[startTraining:endTraining], train_Answer[startTraining:endTraining])\n",
    "  startTraining += stepSize\n",
    "  endTraining += stepSize\n",
    "  model.save_pretrained('./gdrive/MyDrive/Information_Retrieval_Project/bertQA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa9jTC7NdI3g"
   },
   "source": [
    "**Test different models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmFBNWWXDelq"
   },
   "outputs": [],
   "source": [
    "# Test the Bert with 1 Text-input per Question\n",
    "# Show the first 10 Question / Answer Pairs when using 1 paragraph per question\n",
    "# Since these are in the training Data: Just for testing purposes!!\n",
    "bertModel = getModel()[0]\n",
    "distilBertModel = model\n",
    "\n",
    "for question in enumerate(questionArray[:10]):\n",
    "    print(\"Question: \" + str(question[1]))\n",
    "\n",
    "    # Test the Bert with 1 Text-input per Question\n",
    "    print(\"1 Input Answer: \" + str(questionAnswering(bertModel, tokenizer, question[1], answerFileArray[question[0]])))\n",
    "\n",
    "    # Test the Bert model with multiple files per question\n",
    "    print(\"Multiple Inputs Answer: \" + str(multipleQuestionAnswering(bertModel, tokenizer, question[1], multipleAnswerFileArray[question[0]])))\n",
    "\n",
    "    # Test the fine-tuned distilbert\n",
    "    print(\"Distilbert Answer: \" + str(multipleQuestionAnswering(distilBertModel, tokenizer, question[1], multipleAnswerFileArray[question[0]])))\n",
    "\n",
    "    print(\"Correct Answer: \" + str(answerArray[question[0]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uNjVPxYnmPs"
   },
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1623666659281,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "NRHLcJcOspDg"
   },
   "outputs": [],
   "source": [
    "def evaluateAnswers(correctAnswer, givenAnswer, counterCorrect, counterPartlyCorrect, counterWrong):\n",
    "  if givenAnswer == correctAnswer:\n",
    "    counterCorrect += 1\n",
    "  elif len(str(givenAnswer)) > 50:\n",
    "    counterWrong += 1\n",
    "  else:\n",
    "\n",
    "    # Only if all strings in the correct answer are found in the given answer\n",
    "    # the answer is viewed as correct\n",
    "    found = True\n",
    "    for correct in str(correctAnswer).split():\n",
    "      if not correct in str(givenAnswer):\n",
    "        found = False\n",
    "\n",
    "    if found == True:\n",
    "      counterPartlyCorrect += 1\n",
    "    else:\n",
    "    # Same with the all the strings in the given answer  \n",
    "      found = True  \n",
    "      for given in str(givenAnswer).split():\n",
    "        if not given in str(correctAnswer):\n",
    "          found = False     \n",
    "      if found == True:\n",
    "        counterPartlyCorrect += 1\n",
    "      else:\n",
    "        counterWrong += 1        \n",
    "\n",
    "  return (counterCorrect, counterPartlyCorrect, counterWrong)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTDOcSJ0eyix"
   },
   "source": [
    "**Evaluate different models on test Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykKUYa_7XiIW"
   },
   "outputs": [],
   "source": [
    "# 3 models:\n",
    "# Bert with 1 text input\n",
    "# Bert with multiple (max 5) text inputs\n",
    "# Fine-tuned DistilBert (only tested with multiple inputs [sigle input would also be possilbe])\n",
    "\n",
    "# get the 2 models\n",
    "bertModel = getModel()[0]\n",
    "distilBertModel, tokenizer = getDistilBertModel()\n",
    "\n",
    "# specify how many paragraphs should be respected for each question\n",
    "# higher: takes longer but respects more text per question \n",
    "# (answer might else be truncated)\n",
    "numberParagraphs = 3\n",
    "counterQuestions = 0\n",
    "\n",
    "\n",
    "# make counters for each of them\n",
    "counterCorrectOneInput = 0\n",
    "counterPartlyCorrectOneInput = 0\n",
    "counterWrongOneInput = 0\n",
    "\n",
    "counterCorrectMultipleInput = 0\n",
    "counterPartlyCorrectMultipleInput = 0\n",
    "counterWrongMultipleInput = 0\n",
    "\n",
    "counterCorrectDistilBert = 0\n",
    "counterPartlyCorrectDistilBert = 0\n",
    "counterWrongDistilBert = 0\n",
    "\n",
    "for i in range(len(test_Question[:300])):\n",
    "  question = test_Question[i]\n",
    "  paragraphArray = multiple_Test_Paragraph[i]\n",
    "  correctAnswer = test_Answer[i][0]\n",
    "  #print(str(i) + \" out of \" + str(len(test_Question)))\n",
    "  #print(correctAnswer)\n",
    "\n",
    "  # Bert with 1 text input\n",
    "  #givenAnswer = questionAnswering(bertModel, tokenizer, question, paragraphArray[0], numberParagraphs)\n",
    "  #counterCorrectOneInput, counterPartlyCorrectOneInput, counterWrongOneInput = evaluateAnswers(correctAnswer, givenAnswer, counterCorrectOneInput, counterPartlyCorrectOneInput, counterWrongOneInput)\n",
    "  #print(givenAnswer)\n",
    "\n",
    "  # Bert with multiple text inputs\n",
    "  #givenAnswer = multipleQuestionAnswering(bertModel, tokenizer, question, paragraphArray, numberParagraphs)\n",
    "  #counterCorrectMultipleInput, counterPartlyCorrectMultipleInput, counterWrongMultipleInput = evaluateAnswers(correctAnswer, givenAnswer, counterCorrectMultipleInput, counterPartlyCorrectMultipleInput, counterWrongMultipleInput)\n",
    "\n",
    "  # DistilBert (multiple text inputs always seem to work better)\n",
    "  givenAnswer = multipleQuestionAnswering(distilBertModel, tokenizer, question, paragraphArray, numberParagraphs)\n",
    "  counterCorrectDistilBert, counterPartlyCorrectDistilBert, counterWrongDistilBert = evaluateAnswers(correctAnswer, givenAnswer, counterCorrectDistilBert, counterPartlyCorrectDistilBert, counterWrongDistilBert)   \n",
    "\n",
    "  counterQuestions += 1\n",
    "\n",
    "#print(\"Correct answers 1 Input: \" + str(counterCorrectOneInput))\n",
    "#print(\"Partly correct answers 1 Input: \" + str(counterPartlyCorrectOneInput))\n",
    "#print(\"Wrong answers 1 Input: \" + str(counterWrongOneInput))\n",
    "#print()\n",
    "\n",
    "#print(\"Correct answers multiple Inputs: \" + str(counterCorrectMultipleInput))\n",
    "#print(\"Partly correct answers multiple Inputs: \" + str(counterPartlyCorrectMultipleInput))\n",
    "#print(\"Wrong answers multiple Inputs: \" + str(counterWrongMultipleInput))\n",
    "#print()\n",
    "\n",
    "print(\"Correct answers Distilbert: \" + str(counterCorrectDistilBert))\n",
    "print(\"Partly correct answers Distilbert: \" + str(counterPartlyCorrectDistilBert))\n",
    "print(\"Wrong answers Distilbert: \" + str(counterWrongDistilBert))\n",
    "print()\n",
    "\n",
    "print(\"Total number of questions: \" + str(counterQuestions))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyZ_M5d8LyQF"
   },
   "source": [
    "**Evaluate each Epoch of the Distilbert model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KzehhKW6Lxx7"
   },
   "outputs": [],
   "source": [
    "numberParagraphs = 3\n",
    "\n",
    "# create counters\n",
    "counterCorrect = 0\n",
    "counterPartlyCorrect = 0\n",
    "counterWrong = 0\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "  counterCorrect = 0\n",
    "  counterPartlyCorrect = 0\n",
    "  counterWrong = 0\n",
    "\n",
    "  #the time colab provides is not enough to run through all of them at once (comment the model to be used out)\n",
    "  #and change the number of range above depending on the model used\n",
    "  if i == 0:\n",
    "    continue\n",
    "    #model, tokenizer = getModel()\n",
    "    #model, tokenizer = getDistilBertModel()\n",
    "  else:  \n",
    "    model = DistilBertForQuestionAnswering.from_pretrained('./gdrive/MyDrive/Information_Retrieval_Project/bertQAEpochs/Epoch ' + str(i) + '/', local_files_only = True, torchscript=True)\n",
    "  \n",
    "  for j in range(len(test_Question[:250])):\n",
    "    question = test_Question[j]\n",
    "    paragraphArray = multiple_Test_Paragraph[j]\n",
    "    correctAnswer = test_Answer[j][0]\n",
    "\n",
    "    # DistilBert\n",
    "    givenAnswer = multipleQuestionAnswering(model, tokenizer, question, paragraphArray, numberParagraphs)\n",
    "    counterCorrect, counterPartlyCorrect, counterWrong = evaluateAnswers(correctAnswer, givenAnswer, counterCorrect, counterPartlyCorrect, counterWrong)   \n",
    "\n",
    "  print(str(i) + \". Epoch\")\n",
    "  #print(\"Pre-Trained Bert\")\n",
    "  print(\"Correct answers: \" + str(counterCorrect))\n",
    "  print(\"Partly correct answers: \" + str(counterPartlyCorrect))\n",
    "  print(\"Wrong answers: \" + str(counterWrong))\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATKNoyG6b7Bt"
   },
   "source": [
    "Results from the test set:\n",
    "\n",
    "Pre-Trained Bert:\n",
    "0. \n",
    "Correct answers: 113,\n",
    "Partly correct answers: 50,\n",
    "Wrong answers: 87\n",
    "\n",
    "Pre-Trained DistilBert:\n",
    "0. Epoch\n",
    "Correct answers: 80,\n",
    "Partly correct answers: 43,\n",
    "Wrong answers: 127\n",
    "\n",
    "Trained DistilBert:\n",
    "1. Epoch\n",
    "Correct answers: 108,\n",
    "Partly correct answers: 50,\n",
    "Wrong answers: 92\n",
    "\n",
    "2. Epoch\n",
    "Correct answers: 109,\n",
    "Partly correct answers: 35,\n",
    "Wrong answers: 106\n",
    "\n",
    "3. Epoch\n",
    "Correct answers: 104,\n",
    "Partly correct answers: 32,\n",
    "Wrong answers: 114\n",
    "\n",
    "4. Epoch\n",
    "Correct answers: 105,\n",
    "Partly correct answers: 29,\n",
    "Wrong answers: 116\n",
    "\n",
    "5. Epoch\n",
    "Correct answers: 100,\n",
    "Partly correct answers: 31,\n",
    "Wrong answers: 119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhVeRmsumbZA"
   },
   "source": [
    "**Evaluate different models on the validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jKgAw7FmlJQ"
   },
   "outputs": [],
   "source": [
    "# Open the training file\n",
    "with open(verifiedPath, 'r', encoding='utf-8') as jsonFile:\n",
    "    verifiedData = json.load(jsonFile)\n",
    "archive = zipfile.ZipFile(evidencePath, 'r')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIyCQ0wtnONR"
   },
   "outputs": [],
   "source": [
    "verifiedDataArray = np.array(verifiedData[\"Data\"])\n",
    "verifiedMaxParagraphs = 5\n",
    "\n",
    "verifiedQuestionArray = np.zeros(len(verifiedDataArray), dtype='object')\n",
    "verifiedAnswerArray = np.zeros(len(verifiedDataArray), dtype='object')\n",
    "verifiedAnswerTextArray = np.zeros((len(verifiedDataArray), verifiedMaxParagraphs), dtype='object')\n",
    "\n",
    "\n",
    "i = 0\n",
    "# Read the Question, Answers + Paragraphs and store them in an array each\n",
    "for item in verifiedDataArray:\n",
    "    verifiedQuestionArray[i] = item[\"Question\"]\n",
    "    verifiedAnswerArray[i] = item[\"Answer\"][\"Value\"]\n",
    "\n",
    "    j = 0\n",
    "    for file in item[\"EntityPages\"]:\n",
    "      try:\n",
    "        verifiedAnswerTextArray[i][j] = archive.read('wikipedia/' + file[\"Filename\"]).decode(\"utf-8\")\n",
    "      except KeyError:\n",
    "        verifiedAnswerTextArray[i][j] = \"NAN\"\n",
    "      j += 1\n",
    "      # if maximum no of paragraphs is reached:\n",
    "      # do not continue inner for loop\n",
    "      if j == verifiedMaxParagraphs:\n",
    "        break\n",
    "\n",
    "    i += 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxP-7D2rqw5s"
   },
   "outputs": [],
   "source": [
    "# Verify on validation data set\n",
    "# 1. on the standard DistilBert\n",
    "# 2. on the trained DistilBert\n",
    "# 3. on the standard Bert\n",
    "\n",
    "\n",
    "# specify how many paragraphs should be respected for each question\n",
    "# higher: takes longer but respects more text per question \n",
    "# (answer might else be truncated)\n",
    "numberParagraphs = 5\n",
    "\n",
    "for j in range(5):\n",
    "\n",
    "  # create counters\n",
    "  counterCorrect = 0\n",
    "  counterPartlyCorrect = 0\n",
    "  counterWrong = 0\n",
    "  counterQuestions = 0\n",
    "  \n",
    "  #the time colab provides is not enough to run through all of them at once (comment the model to be used out)\n",
    "  #and change the number of range above depending on the model\n",
    "  if j == 0:\n",
    "    model, tokenizer = getDistilBertModel()\n",
    "    text = \"Standard DistilBert\"\n",
    "  elif j < 4:\n",
    "    model = DistilBertForQuestionAnswering.from_pretrained('./gdrive/MyDrive/Information_Retrieval_Project/bertQAEpochs/Epoch ' + str(j) + '/', local_files_only = True, torchscript=True)\n",
    "    text = \"Epoch: \" + str(j)\n",
    "  elif j == 4:\n",
    "    model, tokenizer = getModel()\n",
    "    text = \"Standard Bert\"\n",
    "\n",
    "\n",
    "  for i in range(len(verifiedQuestionArray)):\n",
    "      counterQuestions += 1\n",
    "      question = verifiedQuestionArray[i]\n",
    "      paragraphArray = verifiedAnswerTextArray[i]\n",
    "      correctAnswer = verifiedAnswerArray[i]\n",
    "      \n",
    "      givenAnswer = multipleQuestionAnswering(model, tokenizer, question, paragraphArray, numberParagraphs)\n",
    "      counterCorrect, counterPartlyCorrect, counterWrong = evaluateAnswers(correctAnswer, givenAnswer, counterCorrect, counterPartlyCorrect, counterWrong)   \n",
    "\n",
    "  print(text)\n",
    "  print(\"Correct answers: \" + str(counterCorrect))\n",
    "  print(\"Partly correct answers: \" + str(counterPartlyCorrect))\n",
    "  print(\"Wrong answers: \" + str(counterWrong))\n",
    "  print(\"Number Questions: \" + str(counterQuestions))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDDbf9XzbZ9c"
   },
   "source": [
    "Results from the Validation Set: \n",
    "\n",
    "Standard Bert:\n",
    "Correct answers: 6,\n",
    "Partly correct answers: 8,\n",
    "Wrong answers: 304\n",
    "\n",
    "Standard DistilBert:\n",
    "Correct answers: 4, \n",
    "Partly correct answers: 15, \n",
    "Wrong answers: 299\n",
    "\n",
    "Epoch 1:\n",
    "Correct answers: 6,\n",
    "Partly correct answers: 31,\n",
    "Wrong answers: 281\n",
    "\n",
    "Epoch 2:\n",
    "Correct answers: 5,\n",
    "Partly correct answers: 24,\n",
    "Wrong answers: 289\n",
    "\n",
    "Epoch 3:\n",
    "Correct answers: 5,\n",
    "Partly correct answers: 26,\n",
    "Wrong answers: 287"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOVUSTigq2U-"
   },
   "source": [
    "**See the time difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17302,
     "status": "ok",
     "timestamp": 1623660159189,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "AZNc8MPTq1qj",
    "outputId": "ec4790ad-7804-4aa8-a173-7d7e6477dc89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Bert: --- 6.701009273529053 seconds ---\n",
      "Distil Bert: --- 4.129925727844238 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Normal Bert\n",
    "model, tokenizer = getModel()\n",
    "start = time.time()\n",
    "multipleQuestionAnswering(model, tokenizer, questionArray[0], answerFileArray[0:1])\n",
    "print(\"Standard Bert: --- %s seconds ---\" % (time.time() - start))\n",
    "\n",
    "# Distil Bert\n",
    "model, tokenizer = getDistilBertModel()\n",
    "start = time.time()\n",
    "multipleQuestionAnswering(model, tokenizer, questionArray[0], answerFileArray[0:1])\n",
    "print(\"Distil Bert: --- %s seconds ---\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQYZOiMpeaUz"
   },
   "source": [
    "**Make the pipeline work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1623666668372,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "WBeR-pkPz6xn"
   },
   "outputs": [],
   "source": [
    "# Open the training file\n",
    "import pandas as pd\n",
    "\n",
    "def answerFromCSV (path):\n",
    "  df = pd.read_csv(path, sep=',')\n",
    "  model, tokenizer = getDistilBertModel()\n",
    "  model = DistilBertForQuestionAnswering.from_pretrained('./gdrive/MyDrive/Information_Retrieval_Project/bertQAEpochs/Epoch 1/', local_files_only = True, torchscript=True)\n",
    "  question = df.iloc[0]['full_question']\n",
    "  textArray = np.asarray(df.iloc[0:5]['full_doc'])\n",
    "\n",
    "  answer = multipleQuestionAnswering(model, tokenizer, question, textArray)\n",
    "  return answer, df['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44352,
     "status": "ok",
     "timestamp": 1623667296362,
     "user": {
      "displayName": "Mar",
      "photoUrl": "",
      "userId": "10246906369909496791"
     },
     "user_tz": -120
    },
    "id": "s0tSEtA_0mqa",
    "outputId": "6a423637-0a6d-4342-838e-ba1f31255866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: dukan diet\n",
      "Predicted Answer: dukan diet\n",
      "Correct Answer: the daleks\n",
      "Predicted Answer: 42\n"
     ]
    }
   ],
   "source": [
    "predicted, correct = answerFromCSV('./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/finaltest.csv')\n",
    "print(\"Correct Answer: \" + str(correct).lower())\n",
    "print(\"Predicted Answer: \" + str(predicted))\n",
    "\n",
    "predicted, correct = answerFromCSV('./gdrive/MyDrive/Information_Retrieval_Project/duoBERT/finaltest2.csv')\n",
    "print(\"Correct Answer: \" + str(correct).lower())\n",
    "print(\"Predicted Answer: \" + str(predicted))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Bert QA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08d85022435f4567845c2e864e6df42c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0acbc1b390e54d1a9160ce23b7a13280": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f951b3beeb07474caf59515937cf0546",
      "max": 451,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c58f6219e5234ae880e24f307027e6c5",
      "value": 451
     }
    },
    "0f2e06f7a54f4eba99d237b15928e24a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1c7876b377c34776a8cbc4ee50ececf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "21f008faac4f460d909e5ed966ae68b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8998977b272a444b9adafaef60bcaee0",
      "placeholder": "​",
      "style": "IPY_MODEL_b707499dac294f58947c24ab63a878c3",
      "value": " 28.0/28.0 [00:00&lt;00:00, 194B/s]"
     }
    },
    "22e60c8cd21642ccaa67ac72aff5dc23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26a9aea9f6d04642b8de0bae16a435cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2acd78c35ba348d38df4c0797334ad62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f26fa2677f04776b407b3dfde4164fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ba28ac44234dc6aa14d57bf7242165",
      "placeholder": "​",
      "style": "IPY_MODEL_c369d6836a6f4f568944f253dc4414b0",
      "value": " 232k/232k [00:01&lt;00:00, 219kB/s]"
     }
    },
    "32e1208d843241c88cc294d9b33c7b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c7461492a6c46d4ba01a43a9e604eed",
       "IPY_MODEL_f251cba1350842a0b27b1c4f41e5e5b7"
      ],
      "layout": "IPY_MODEL_98ba678642da4b649acdc42b5e155bf3"
     }
    },
    "33913cb896ad4c2cbfc8fabd2a7c9540": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3733d7f65639420588250531f49f7df6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3b28e538e9624d51824420c1b92c6c05": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4321b91e13bd4072b5348131f0a22804": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59ffaef46ca8499d9957e85c27fb3bfb",
       "IPY_MODEL_a481053d79a54f5a81f2cc5bfdb46abf"
      ],
      "layout": "IPY_MODEL_3b28e538e9624d51824420c1b92c6c05"
     }
    },
    "4edf2d70f11347b9a8d71da86f36d395": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1f28081e5e43849feacbd359954d4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08d85022435f4567845c2e864e6df42c",
      "placeholder": "​",
      "style": "IPY_MODEL_b9ec5ddb87204626bb994ce17c35ef7c",
      "value": " 265M/265M [00:06&lt;00:00, 44.0MB/s]"
     }
    },
    "547a22665d9b4bc4af47fab0572c8d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55fdaa97509f474e8d6e596105c3addc",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_707a4f70f375442eb7b4fe977d14c49b",
      "value": 28
     }
    },
    "55fdaa97509f474e8d6e596105c3addc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59ffaef46ca8499d9957e85c27fb3bfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9037eb92b01445d4a2d72362fffbbefd",
      "max": 443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3733d7f65639420588250531f49f7df6",
      "value": 443
     }
    },
    "60ba28ac44234dc6aa14d57bf7242165": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "627d151b53ad45e2b717a3ec7e05fdce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c7461492a6c46d4ba01a43a9e604eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4edf2d70f11347b9a8d71da86f36d395",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f2e06f7a54f4eba99d237b15928e24a",
      "value": 466062
     }
    },
    "707a4f70f375442eb7b4fe977d14c49b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "707f8697fddb41dba20756484247012d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "794dda0c64f349e4b7ac7a49b4f5b9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "822c4c8b61de4b6588591c0f9938bcc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e59e184146114c0c8fe048f397c24b76",
       "IPY_MODEL_9ebe5efc1de04370ba7253a4b2b85c97"
      ],
      "layout": "IPY_MODEL_f03e74d228294767abaaf8708844dc7b"
     }
    },
    "8458fb10ca3145758b0ceff71add1858": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c6ff3617de44b3b1b916debf2de2c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89731e5e10134c498d366cdaf7cfd4b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8998977b272a444b9adafaef60bcaee0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9037eb92b01445d4a2d72362fffbbefd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ba678642da4b649acdc42b5e155bf3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1437bbca934f78b2bd09f673b1d96f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89731e5e10134c498d366cdaf7cfd4b0",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33913cb896ad4c2cbfc8fabd2a7c9540",
      "value": 231508
     }
    },
    "9ebe5efc1de04370ba7253a4b2b85c97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_707f8697fddb41dba20756484247012d",
      "placeholder": "​",
      "style": "IPY_MODEL_c64baac2b3194c63bfccdd0d8f24d965",
      "value": " 1.34G/1.34G [00:24&lt;00:00, 53.9MB/s]"
     }
    },
    "a44aadba618c4869905ed836708c33e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a481053d79a54f5a81f2cc5bfdb46abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8458fb10ca3145758b0ceff71add1858",
      "placeholder": "​",
      "style": "IPY_MODEL_2acd78c35ba348d38df4c0797334ad62",
      "value": " 443/443 [00:26&lt;00:00, 16.7B/s]"
     }
    },
    "a5b644c4f6204bf6ae396940996dacfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0acbc1b390e54d1a9160ce23b7a13280",
       "IPY_MODEL_f2015d2652d446b3a814827194c8d4f7"
      ],
      "layout": "IPY_MODEL_627d151b53ad45e2b717a3ec7e05fdce"
     }
    },
    "b3e1e8955523470d829b4ae175a34c28": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b707499dac294f58947c24ab63a878c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9ec5ddb87204626bb994ce17c35ef7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb3c30655b4645b593910942cb10a9c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c369d6836a6f4f568944f253dc4414b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c58f6219e5234ae880e24f307027e6c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c64baac2b3194c63bfccdd0d8f24d965": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb2f2003cc4248abb0d9a3c6d0cd0136": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_547a22665d9b4bc4af47fab0572c8d8c",
       "IPY_MODEL_21f008faac4f460d909e5ed966ae68b9"
      ],
      "layout": "IPY_MODEL_794dda0c64f349e4b7ac7a49b4f5b9ac"
     }
    },
    "d60a1a8e29a54803a6ac752400708397": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e166f74d0d914944b80499ef1b942991": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26a9aea9f6d04642b8de0bae16a435cf",
      "max": 265481570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c7876b377c34776a8cbc4ee50ececf6",
      "value": 265481570
     }
    },
    "e59e184146114c0c8fe048f397c24b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1984461492849cc9ce8c00b7e54ae07",
      "max": 1340675298,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a44aadba618c4869905ed836708c33e5",
      "value": 1340675298
     }
    },
    "eb77933723584f648b507eab6a8c5d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e166f74d0d914944b80499ef1b942991",
       "IPY_MODEL_4f1f28081e5e43849feacbd359954d4c"
      ],
      "layout": "IPY_MODEL_22e60c8cd21642ccaa67ac72aff5dc23"
     }
    },
    "ed07fa2a2a654f388937c879e0b546ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e1437bbca934f78b2bd09f673b1d96f",
       "IPY_MODEL_2f26fa2677f04776b407b3dfde4164fa"
      ],
      "layout": "IPY_MODEL_f7fb0f8c87d14271bf0b5787f6486f11"
     }
    },
    "f03e74d228294767abaaf8708844dc7b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1984461492849cc9ce8c00b7e54ae07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2015d2652d446b3a814827194c8d4f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3e1e8955523470d829b4ae175a34c28",
      "placeholder": "​",
      "style": "IPY_MODEL_bb3c30655b4645b593910942cb10a9c6",
      "value": " 451/451 [00:00&lt;00:00, 2.75kB/s]"
     }
    },
    "f251cba1350842a0b27b1c4f41e5e5b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d60a1a8e29a54803a6ac752400708397",
      "placeholder": "​",
      "style": "IPY_MODEL_87c6ff3617de44b3b1b916debf2de2c6",
      "value": " 466k/466k [00:00&lt;00:00, 750kB/s]"
     }
    },
    "f7fb0f8c87d14271bf0b5787f6486f11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f951b3beeb07474caf59515937cf0546": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
